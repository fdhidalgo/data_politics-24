{
  "hash": "9ff2128cfc79914d80e0d53c931aa837",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Surveys in Politics\"\nsubtitle: \"Lecture 13\"\ndate: last-modified\nauthor: \n  - name: F. Daniel Hidalgo\n    email: dhidalgo@mit.edu\n    affiliations: MIT\nformat: \n  clean-revealjs:\n    incremental: true\nengine: knitr\nexecute: \n  cache: true\nwebr:\n  packages: ['tidyverse'] # Install R packages on document open\n  show-startup-message: false\nfilters: \n  - timer\n  - webr\nbibliography: ../data_politics_2024.bib\neditor:\n  render-on-save: true\n---\n\n::: {.cell}\n\n:::\n\n\n## Non-Response Over Time\n\n![](images/pew_nonresponse_time.png)\n\n## A Crisis in Traditional Telephone Surveys\n\n- Basic sampling theory predicated on no non-response.\n- Violated in the extreme with contemporary samples.\n- Extreme non-response raises the spectre of pervasive .red[bias] in our sampliing estimates.\n- But the possibility of bias, does not necessarily mean that surveys will be biased!\n- Bias is a function of:\n  1. Level of nonresponse\n  2. Correlation between propensity to respond and the variable of interest.\n\n\n## Demographics: How Severe is the Problem?\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/non-response_edu.png)\n:::\n\n::: {.column .fragment width=\"50%\"}\n![](images/non-response_race.png)\n:::\n:::\n\n## Partisanship: How Severe is the Problem?\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/non-response_partisanship.png)\n\nFrom [Pew Research Center](https://www.pewresearch.org/fact-tank/2019/02/27/response-rates-in-telephone-surveys-have-resumed-their-decline/)\n\n:::\n\n::: {.column .fragment width=\"50%\"}\n\nWithout adjustment, bias in:\n\n::: {.nonincremental}\n\n- Levels of educational attainment\n- Race (though varies across time)\n- Propensity to participate.\n:::\n\nLess bias in partisanship.\n\nWeighting can remove these *observed* biases, as we know the extent of the bias using other data sources.\n\n**Key question**: But what about unobserved gaps where don't have external data?\n\n\n:::\n:::\n\n## 2012 US Presidential Election\n\n- In 2012, exit-poll indicated Obama won with **39%** of white voters.\n- Spurred GOP to:\n  - Move towards center on immigration\n  - Convene task force to address non-white voters.\n\n. . .  \n\nBut better data revealed:\n  \n| Group | Exit Poll | CPS\n|-------|-----------|----\n| White, non-Hispanic | 72% | 74%\n| No bachelor's degree | 53% | 63%\n| Age 45+ | 54% | 61%\n| White, non-college, 45+ | 23 | 30\n\n## 2012 US Presidential Election\n\n![](images/upshot_obama_white_voters.png)\n\n## 2016 Presidential Election\n\n![](images/upshot_prob.png)\n\n## 2016 Presidential Election\n\n![](images/edu_weighting_nytimes.png)\n\n## Polling Bias Across Time\n\n![](images/average_poll_bias_year.png)\n\n## 2020 Polling Bias\n\n[**AAPOR Report**](https://aapor.org/wp-content/uploads/2022/11/Task-Force-on-2020-Pre-Election-Polling_Executive-Summary.pdf):\n\n- 2020 Polling error was highest in 40 years \n- Not caused by: \n  - Late deciding voters\n  - Failing to weight by education\n  - Assumptions about demographic composition of electorate\n- Some possibilities:\n  - Social trust among Trump voters\n  - Covid\n  - Great \"awokening\" \n\n## Partisanship and Non-Response\n\n![](images/2020_dem_survey_response.png)\n\n## A Model of Non-Response\n\n- Assume all respondents $k$ have a .red[unknown] response probability $\\rho_k$ and some value of $Y_k$. We want to esitmate $\\bar Y = \\frac{Y}{N}$ (our **estimand**)\n- When a respondent is selected into the sample, they respond or do not respond and these responses are collected in the vector:\n$R_1, R_2, \\ldots, R_N$ where $R_k = 1$ if respondent $k$ would answer the survey and $R_k=0$ if she would not.\n- Now suppose we conduct a simple random sample of size $n$, where whether or not one is selected is denoted by the vector of indicators $a_1, a_2, \\ldots, a_N$ where $a_k$ is a 1 if respondent $k$ is selected to be surveyed. We only observe a response if **both** $a_k=1$ and $R_k=1$.\n- The number of respondents successfully recruited into the sample is:\n$n_{R}=\\sum_{k=1}^{N} a_{k} R_{k}$\n\n## A Model of Non-Response\n\n- Our **estimator** of public opinion is\n$$\\bar{y}_{R}=\\frac{1}{n_{R}} \\sum_{k=1}^{N} a_{k} R_{k} Y_{k}$$\n\n- One can show that\n$$\\mathbb{E}[\\bar y_R] = \\tilde{Y}=\\frac{1}{N} \\sum_{k=1}^{N} \\frac{\\rho_{k} Y_{k}}{\\bar{\\rho}}$$\nwhere $\\bar{\\rho}$ is the average response probability in the population.\n\n- The expectation of our estimator does not equal the population mean. This is **bias**.\n\n## Non-Response Bias\n\n## Non-Response Bias\n\nGiven the above model, the nonresponse bias is approximately:\n$$\\tilde{Y}-\\bar{Y}=\\frac{R_{\\rho Y} S_{\\rho} S_{Y}}{\\bar{\\rho}}$$\nwhere $R_{\\rho Y}$ is the **correlation** the target variable and the response variable, $S_{Y}$ is the standard deviation of $Y$, and $S_{\\rho}$ is the standard deviation of the response probability.\n\nSo this expression shows that:\n\n1. Bias ↓ as the correlation between the target variable and response variable ↓.\n2. Bias ↓ as the response probabilities get more equal.\n3. Bias ↓ as the mean response probability ↓ (non-response is decreasing)\n\n# Weighting for Non-Response\n\n## Weighting Workflow\n\n![](images/workflow_survey_inference.png)\n\n## Weighting for Non-Response\n\n One can use survey weights to estimate sample means:\n$$\\bar{y}_{H T}=\\frac{1}{N} \\sum_{i=1}^{n} \\frac{y_{i}}{\\pi_{i}} = \\frac{1}{N} \\sum_{i=1}^{n} d_{i} y_{i}$$\nwhere $\\pi$ is the probability of being included in the sample. Inverse probabily weights are $d_i = \\frac{1}{\\pi_i}$.\n\nWe can use **adjustment weights** in a new estimator:\n$$\\bar{y}_{W}=\\frac{1}{N} \\sum_{i=1}^{n} w_{i} y_{i}$$\nwhere $w_{i}=g_{i} \\times d_{i}$ and $g_i$ is a **correction weight** produced by a weighting adjustment technique.\n\n## Constructing Weights\n\nWeights are constructed such that:\n$$\\frac{1}{N} \\sum_{i=1}^{n} w_{i} x_{i}=\\bar{X}$$\n\nwhere $X$ is some auxiliary variable known for the population (like region or education or race) and $\\bar X$ is the population average\n\n## Post-Stratification Weights\n\nThe most common form of weighting is **post-stratification**. The basic idea is to create representative samples by stratifying respondents into *cells* or bins and adjusting the weights such that $w_i$ match the probability from being from each group.\n\nSuppose the population can be divided into $L$ stratum, where the proportion of respondents in stratum $h$ should be equal to $\\frac{N_h}{N}$ for all stratum. However, in your sample, you have $\\frac{n_h}{n}$. To correct for the fact that these may not be equal, assign a correction weight\n$$g_{i}=\\frac{N_{b} / N}{n_{b} / n}$$.\n\n## Post-Stratification Weights\n\nSubstituting into the expression from the earlier slide, the post-stratification estimator is:\n$$\\bar{y}_{P S}=\\frac{1}{N} \\sum_{h=1}^{L} N_{h} \\bar{y}^{(h)}$$\n\nwhere $\\bar{y}^{(h)}$ is the sample mean in strata $h$.  So the poststratification estimator is equal to a weighted sum of sample stratum means.\n\n## Bias in Post-Stratification Weights\n\nOne can show that the bias in the post-stratification estimator is\n\n$$B\\left(\\bar{y}_{P S, R}\\right)=\\frac{1}{N} \\sum_{b=1}^{L} N_{b} \\frac{R_{\\rho Y}^{(h)} S_{\\rho}^{(h)} S_{Y}^{(h)}}{\\bar{\\rho}^{(b)}}$$\n\nwhere $R_{\\rho Y}^{(h)}$ is correlation between $Y$ and the response probability ( $\\rho$ ) on stratum $h$, and $S_{\\rho}^{(h)}$ and $S_{Y}^{(h)}$ are the standard errors of the response probabilities and $Y$.\n\n## Bias in Post-Stratification Weights\n\nSo bias is small if:\n\n- There is little or no relationship between the target variable and response behavior within all strata. So their correlations are small.\n- All response probabilities within a stratum are more or less equal. So their standard errors are small.\n- All values of the target variable within a stratum are more or less equal. So their standard errors are small.\n\n## Wang, Rothschild, Goel, and Gelman 2015\n\n![](images/xbox.png)\n\n~750k interviews\n\n## X-Box Demographics\n\n![](images/xbox_demo_diff.png)\n\n## X-Box Poll Results\n\n![](images/xbox_intent.png)\n\n## Citations\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}