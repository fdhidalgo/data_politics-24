{
  "hash": "16b6893b8c3fafd5ffbf08f93ae8853a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"More on Inference in Experiments\"\nsubtitle: \"Lecture 8\"\ndate: last-modified\nauthor: \n  - name: F. Daniel Hidalgo\n    email: dhidalgo@mit.edu\n    affiliations: MIT\nformat: \n  clean-revealjs:\n    incremental: true\nengine: knitr\nwebr:\n  packages: ['tidyverse'] # Install R packages on document open\n  show-startup-message: false\nfilters: \n  - timer\n  - webr\nbibliography: ../data_politics_2024.bib\neditor:\n  render-on-save: true\n---\n\n::: {.cell}\n\n:::\n\n\n```{webr-r}\n#| context: setup\n\n# Download a dataset\ndownload.file(\n        url = \"https://raw.githubusercontent.com/fdhidalgo/data_politics-24/main/lectures/08-ci/race_list.csv\",\n        destfile = \"race.csv\"\n)\n\nrace <- read.csv(\"race.csv\") |>\n        as_tibble() |>\n        na.omit()\n```\n\n# The Bootstrap\n\n## Where are we? \n\n- In experiments, the population is the full set of [potential]{.alert} or counterfactual outcomes. \n\n- The sample are the outcomes we actually observe after treatment assignment. \n\n- Random assignment introduces variation in the sample, but the population is fixed.\n\n- The variation is called sampling variation and creates a [sampling distribution]{.alert}.\n\n\n## Inference\n\n::: {.callout-important title=\"Hypothesis Testing\"}\nUnder our maintained assumptions, how likely is it that we would observe the data we have if the (sharp) null hypothesis were true?\n:::\n\n- *Hypothesis testing* is a useful beginning point for inference, but sometimes we want to characterize other aspects of the sampling distribution. \n\n- We will use a tool called the [**bootstrap**]{.alert} to do this.\n\n##  The Bootstrap\n\n![[Source](https://online.stat.psu.edu/stat555/node/119/)](images/bootstrap.png)\n\n**Sample** from the sample *with replacement* many times to estimate the sampling distribution. \n\n## Survey\n\n1991 Survey:\n\n> Now I’m going to read you three things that sometimes make people\n    angry or upset. After I read all three, just tell me HOW MANY of\n    them upset you. (I don’t want to know which ones, just how many.)\n\n. . .\n\n> (1) the federal government increasing the tax on gasoline\n> (2) professional athletes getting million-dollar-plus salaries\n> (3) large corporations polluting the environment\n\n. . .\n\n> (4) a black family moving next door to you\n\n> How many, if any, of these things upset you?\n\n## Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrace <- read_csv(\"race_list.csv\")\n\nrace |> \n  slice_sample(prop = 1, replace = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,213 × 7\n       y treat   age south  male college state\n   <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>\n 1     3     1   3       0     0       0 NJ   \n 2     2     0   4.2     1     0       1 TX   \n 3     2     1   4.6     0     0       1 CA   \n 4     4     1   4.7     0     1       0 NE   \n 5     1     0   6       0     1       1 PA   \n 6     0     0   6.4     1     1       0 FL   \n 7     2     1   3.2     0     0       1 CO   \n 8     3     0   3.7     0     1       1 KY   \n 9     3     0   2.6     0     0       1 CA   \n10     3     1   3       0     0       0 OH   \n# ℹ 1,203 more rows\n```\n\n\n:::\n:::\n\n\n\n## Many Boostrap Samples\n\n```{webr-r}\n#| label: bootstrap_samples\n#| echo: true\n\nbs_samples <- map(1:1000, ~ slice_sample(race, prop = 1, replace = TRUE))\n\nclass(bs_samples)\n\nlength(bs_samples)\n\nclass(bs_samples[[1]])\n\nglimpse(bs_samples[[1]])\n\n```\n## Bootstrap Estimates\n\n```{webr-r}\n#| label: bootstrap_estimates\n#| echo: true\n\nbs_ests <-  map(bs_samples, \n                ~ summarise(.x, mean_college = mean(college))) |>\n  bind_rows()\n\nbs_ests\n\n\n```\n\n## Visualizing the Bootstrap Distribution\n\n::: {.cell}\n\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nbs_ests |> \n  ggplot(aes(x = mean_college)) +\n  geom_histogram(bins = 30, \n                 fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Bootstrap Distribution of Estimates\", \n       x = \"Mean College\", \n       y = \"Frequency\") \n```\n\n::: {.cell-output-display}\n![](inference_ci_files/figure-revealjs/bootstrap_plot-1.png){width=960}\n:::\n:::\n\n\n## Boostrap Distribution\n\n![](images/bootstrap_blackwell.png)\n\n- Bootstrap distribution **approximates** the sampling distribution of the estimator.\n\n- Both should have a similar shape and spread if sampling from the distribution ≈ bootstrap resampling.\n\n- Approximation gets better as sample gets bigger. \n\n\n# Confidence Intervals\n\n## What is a confidence interval?\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/bullseye.png)\n**Point Estimate**: best single guess about the population parameter. Unlikely to be exactly correct.\n:::\n\n::: {.column .fragment width=\"50%\"}\n\n![](images/ring.png)\n**Confidence Intervals**: a range of plausible values of the population parameter.\n:::\n:::\n\n## Confidence Intervals\n\n![](images/ring.png){height=200px}\n\n- Each sample gives a different CI or toss of the ring\n\n- Some samples will contain the target (the CI will contain the truth), other times it won't. \n  - Unlike the picture, we don't know where the target is, so we don't know if our CI contains the truth! \n  \n- **Confidence level**: the percentage of time the CI will contain the truth.\n  - We get to choose this level, but typical values are 90%, 95%, 99%.\n  \n  \n## Confidence Intervals as Occasional Liars\n\n- The **confidence level** of a CI tells us how often it will contain the truth.\n\n- A 95% CI will:\n  - Contain the truth 95% of the time (contain the true parameter or estimand 95% of the time).\n  - Lie to you 5% of the time (not contain the true parameter or estimand 5% of the time). See [link](https://rpsychologist.com/d3/ci/)\n\n. . . \n\n::: {.callout-caution}\nCan you tell if your particular CI is telling the truth?\n\n:::\n\n\n## Percentile Method\n\n- The **percentile method** is a simple way to construct a CI from the bootstrap distribution.\n\n- The 95% CI is the interval between the 2.5th and 97.5th percentiles of the bootstrap distribution.\n\n. . .\n\n```{webr-r}\n\nperc_ci95 <- quantile(bs_ests$mean_college, c(0.025, 0.975))\nperc_ci95\n\n```\n\n## Visualizing the Confidence Interval\n\n\n::: {.cell}\n\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nbs_ests |> \n  ggplot(aes(x = mean_college)) +\n  geom_histogram(bins = 30, \n                 fill = \"lightblue\", color = \"black\") +\n  geom_vline(xintercept = perc_ci95, color = \"red\", size = 1) +\n  labs(title = \"Bootstrap Distribution of Estimates\", \n       x = \"Mean College\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](inference_ci_files/figure-revealjs/ci_plot-1.png){width=960}\n:::\n:::\n\n\n## 99% Confidence Interval\n\nWhat happens if we want the CI to be right more often? Will the width of a 99% confidence interval be wider or narrower?\n\n. . . \n\n\n::: {.cell}\n\n```{.r .cell-code}\nperc_ci99 <- quantile(bs_ests$mean_college, c(0.005, 0.995))\n\nperc_ci99\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     0.5%     99.5% \n0.5482193 0.6166529 \n```\n\n\n:::\n:::\n\n\n## Visualizing the 99% Confidence Interval\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nbs_ests |> \n  ggplot(aes(x = mean_college)) +\n  geom_histogram(bins = 30, \n                 fill = \"lightblue\", color = \"black\") +\n    geom_vline(xintercept = perc_ci95, color = \"red\", size = 1) +\n  geom_vline(xintercept = perc_ci99, color = \"blue\", size = 1) +\n  labs(title = \"Bootstrap Distribution of Estimates\", \n       x = \"Mean College\", \n       y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](inference_ci_files/figure-revealjs/ci_plot_99-1.png){width=960}\n:::\n:::\n\n\n\n## 1991 List Experiment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist_est <- race |>\n  summarise(list_est = mean(y[treat == 1]) - mean(y[treat == 0]),\n            list_est_south = mean(y[treat == 1 & south == 1]) -\n              mean(y[treat == 0 & south == 1]), \n            list_est_old = mean(y[treat == 1 & age > median(age)]) - \n              mean(y[treat == 0 & age > median(age)]))\n\nlist_est\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  list_est list_est_south list_est_old\n     <dbl>          <dbl>        <dbl>\n1   0.0678          0.259        0.135\n```\n\n\n:::\n:::\n\n\n## List Experiments Bootstrap\n\n\n::: {.cell}\n\n:::\n\n\n\n```{webr-r}\n\n#Use map to iterate over bootstrap samples\n\nlist_est_bs <- bs_samples |>\n  map(~ summarise(.x, list_est = mean(y[treat == 1]) - mean(y[treat == 0]),\n                  list_est_south = mean(y[treat == 1 & south == 1]) -\n                   mean(y[treat == 0 & south == 1]), \n                 list_est_old = mean(y[treat == 1 & age > median(age)]) - \n                   mean(y[treat == 0 & age > median(age)]))) |>\n  bind_rows()\n\nlist_est_bs\n\n```\n\n## List Experiments BS Sampling Distributions\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\n##Density Plot\nlist_est_bs |> \n  pivot_longer(cols = starts_with(\"list_est\"),\n               names_to = \"experiment\") |> \n  ggplot(aes(x = value, \n             fill = experiment)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Bootstrap Sampling Distributions\", \n       x = \"Difference in Means\", \n       y = \"Density\") + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](inference_ci_files/figure-revealjs/list_experiments_bs_plot-1.png){width=960}\n:::\n:::\n\n\n## List Experiments Confidence Intervals\n\n\n::: {.cell}\n\n:::\n\n\n\n```{webr-r}\nlist_ests_ci <- list_est_bs |> \n  pivot_longer(cols = starts_with(\"list_est\"),\n               names_to = \"sample\") |> \n  group_by(sample) |> \n  summarise(ci_low = quantile(value, 0.025),\n            ci_high = quantile(value, 0.975))\n\nlist_ests_ci$est <- c(list_est$list_est, \n                      list_est$list_est_old,\n                      list_est$list_est_south)\nlist_ests_ci\n```\n\n## Visualize List Experiments Confidence Intervals\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nlist_ests_ci |> \n  ggplot(aes(x = sample, y = est)) +\n  geom_point(size = 4) +\n  geom_errorbar(aes(ymin = ci_low, \n                    ymax = ci_high), \n                width = 0.2) +\n  labs(title = \"List Experiments Confidence Intervals\", \n       x = \"Sample\", \n       y = \"Difference in Means\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](inference_ci_files/figure-revealjs/list_experiments_ci_plot-1.png){width=960}\n:::\n:::\n",
    "supporting": [
      "inference_ci_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}