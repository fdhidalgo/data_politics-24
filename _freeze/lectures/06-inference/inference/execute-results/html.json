{
  "hash": "fdf7f178cfc48708fbfd6130cb693ae9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inference in Experiments\"\nsubtitle: \"Lecture 5\"\ndate: last-modified\nauthor: \n  - name: F. Daniel Hidalgo\n    email: dhidalgo@mit.edu\n    affiliations: MIT\nformat: \n  clean-revealjs:\n    incremental: true\nengine: knitr\nwebr:\n  packages: ['tidyverse'] # Install R packages on document open\n  show-startup-message: false\nfilters: \n  - timer\n  - webr\nbibliography: ../data_politics_2024.bib\neditor:\n  render-on-save: true\n---\n\n::: {.cell}\n\n:::\n\n\n# Inference: Hypothesis Testing\n\n## Hypothesis Testing {.center}\n\n::: columns\n::: {.column width=\"50%\"}\n-   We have discussed estimation of ATEs and how the difference-in-means is *over repeated randomizations* an unbiased estimator of the ATE.\n\n-   But any particular estimate may be close or far from the true ATE.\n\n-   How do we know if our finding is unlikely to have occurred by chance?\n:::\n\n::: {.column width=\"50%\"}\n![H/T [xkcd](https://xkcd.com/892/)](images/null_hypothesis.png)\n:::\n:::\n\n## Logic of Hypothesis Testing\n\n-   We start with an *imagined* world in which the treatment has a particular effect: [the **null hypothesis** ($H_0$)]{.alert}\n\n-   We ask: under our maintained assumptions, how likely is it that we would observe the data we have if the null hypothesis were true?\n\n    -   *Important*: It is not the probability that any partifcular hypothesis is true, but the probability of observing the data we have if the null hypothesis were true.\n\n-   If the probability is low, we [**reject**]{.alert} the null hypothesis in favor of the [**alternative hypothesis** ($H_1$)]{.alert}. ðŸ˜Ž\n\n-   If the probability is high, we [**fail to reject**]{.alert} the null hypothesis. ðŸ˜¢\n\n    -   We do not accept the null hypothesis, we just fail to reject it.\n\n## The Sharp Null\n\nIn experiments, we might be interested in the [**sharp null hypothesis**]{.alert}:\n\n. . .\n\n::: {.callout-note title=\"Sharp Null Hypotheis of No Effect\"}\nThe treatment effect is 0 for all units: $Y_i(1)=Y_i(0)$ for all $i$.\n:::\n\n**Key idea:** in the world where the sharp null hypothesis is true, we observe all the potential outcomes!\n\n::: columns\n::: {.column width=\"50%\"}\n**The Real World**\n\n| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |\n|-----|-------|----------|----------|\n| 1   | 1     | ?        | 1        |\n| 2   | 0     | -1       | ?        |\n| 3   | 1     | ?        | 0        |\n:::\n\n::: {.column .fragment width=\"50%\"}\n**The Sharp Null World**\n\n| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |\n|-----|-------|----------|----------|\n| 1   | 1     | 1        | 1        |\n| 2   | 0     | -1       | -1       |\n| 3   | 1     | 0        | 0        |\n:::\n:::\n\n## Sampling Distribution Under the Sharp Null\n\n-   To conduct a hypothesis test, we need to know the distribution of our estimator (the difference-in-means) under the sharp null hypothesis.\n-   We can do this by:\n    1.  Calculate the actual test statistic (i.e. difference-in-means) in our sample.\n    2.  Permute the treatment assignment the *same* way you originally assigned treatment and calculate the test statistic.\n    3.  Repeat step 2 many times.\n    4.  Compare the actual test-statistic to the distribution of differences-in-means under the sharp null.\n\n. . .\n\n::: {.callout-note title=\"Permutation Test *p*-value\"}\n   The p-value is the proportion of test-statistics from sampling distribution under the null that are as extreme or more extreme than the actual test-statistic.\n:::\n   \n\n## Barber and Pope Data \n\n\n```{webr-r}\n#| context: setup\n\n# Download a dataset\ndownload.file(\n        \"https://www.dropbox.com/scl/fi/qf65skwb9p9eq26cq1ejw/pope_barber.csv?rlkey=48i5am5r19oqjvvf80ighserh&dl=1\",\n        destfile = \"pope_barber.csv\"\n)\n\npb_data <- read_csv(\"pope_barber.csv\")\n```\n\n```{web-r}\npb_data\n\n```\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}