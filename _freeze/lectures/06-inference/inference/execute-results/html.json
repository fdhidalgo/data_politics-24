{
  "hash": "2e3ebad4df01a266955da2e0bc40bc1a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inference in Experiments\"\nsubtitle: \"Lecture 5\"\ndate: last-modified\nauthor: \n  - name: F. Daniel Hidalgo\n    email: dhidalgo@mit.edu\n    affiliations: MIT\nformat: \n  clean-revealjs:\n    incremental: true\nengine: knitr\nwebr:\n  packages: ['tidyverse'] # Install R packages on document open\n  show-startup-message: false\nfilters: \n  - timer\n  - webr\nbibliography: ../data_politics_2024.bib\neditor:\n  render-on-save: true\n---\n\n::: {.cell}\n\n:::\n\n\n# Inference: Hypothesis Testing\n\n## Hypothesis Testing {.center}\n\n::: columns\n::: {.column width=\"50%\"}\n-   We have discussed estimation of ATEs and how the difference-in-means is *over repeated randomizations* an unbiased estimator of the ATE.\n\n-   But any particular estimate may be close or far from the true ATE.\n\n-   How do we know if our finding is unlikely to have occurred by chance?\n:::\n\n::: {.column width=\"50%\"}\n![H/T [xkcd](https://xkcd.com/892/)](images/null_hypothesis.png)\n:::\n:::\n\n## Logic of Hypothesis Testing\n\n-   We start with an *imagined* world in which the treatment has a particular effect: [the **null hypothesis** ($H_0$)]{.alert}\n\n-   We ask: under our maintained assumptions, how likely is it that we would observe the data we have if the null hypothesis were true?\n\n    -   *Important*: It is not the probability that any partifcular hypothesis is true, but the probability of observing the data we have if the null hypothesis were true.\n\n-   If the probability is low, we [**reject**]{.alert} the null hypothesis in favor of the [**alternative hypothesis** ($H_1$)]{.alert}. ðŸ˜Ž\n\n-   If the probability is high, we [**fail to reject**]{.alert} the null hypothesis. ðŸ˜¢\n\n    -   We do not accept the null hypothesis, we just fail to reject it.\n\n## The Sharp Null\n\nIn experiments, we might be interested in the [**sharp null hypothesis**]{.alert}:\n\n. . .\n\n::: {.callout-note title=\"Sharp Null Hypotheis of No Effect\"}\nThe treatment effect is 0 for all units: $Y_i(1)=Y_i(0)$ for all $i$.\n:::\n\n**Key idea:** in the world where the sharp null hypothesis is true, we observe all the potential outcomes!\n\n::: columns\n::: {.column width=\"50%\"}\n**The Real World**\n\n| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |\n|-----|-------|----------|----------|\n| 1   | 1     | ?        | 1        |\n| 2   | 0     | -1       | ?        |\n| 3   | 1     | ?        | 0        |\n:::\n\n::: {.column .fragment width=\"50%\"}\n**The Sharp Null World**\n\n| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |\n|-----|-------|----------|----------|\n| 1   | 1     | 1        | 1        |\n| 2   | 0     | -1       | -1       |\n| 3   | 1     | 0        | 0        |\n:::\n:::\n\n## Sampling Distribution Under the Sharp Null\n\n-   To conduct a hypothesis test, we need to know the distribution of our estimator (the difference-in-means) under the sharp null hypothesis.\n-   We can do this by:\n    1.  Calculate the actual test statistic (i.e. difference-in-means) in our sample.\n    2.  Permute the treatment assignment the *same* way you originally assigned treatment and calculate the test statistic.\n    3.  Repeat step 2 many times.\n    4.  Compare the actual test-statistic to the distribution of differences-in-means under the sharp null.\n\n. . .\n\n::: {.callout-note title=\"Permutation Test *p*-value\"}\n   The p-value is the proportion of test-statistics from sampling distribution under the null that are as extreme or more extreme than the actual test-statistic.\n:::\n   \n\n## Barber and Pope Data \n\n\n```{webr-r}\n#| context: setup\n\n# Download a dataset\ndownload.file(\n        url = \"https://raw.githubusercontent.com/fdhidalgo/data_politics-24/main/lectures/06-inference/pope_barber.csv\",\n        destfile = \"pope_barber.csv\"\n)\n\npb_data <- read.csv(\"pope_barber.csv\") |>\n        as_tibble() |>\n        na.omit()\n```\n\n```{webr-r}\n#| autorun: true\npb_data\n\nestim_data <- pb_data |>\n        filter(republican == 1 & (libtrump == 1 | self == 1))\n```\n\n##  `sample`\n\nTo sample from a vector, we can use the `sample` function, where `size` is the number of samples, and `replace` is whether we want to sample with replacement.\n\n```{webr-r}\nsample(estim_data$libtrump,\n        size = 5,\n        replace = FALSE\n)\n```\n\n. . .\n\nTo permute an entire vector, you can use `sample`  where `size` is the length of the treatment vector.\n\n```{webr-r}\npermuted <- sample(estim_data$libtrump,\n        size = length(estim_data$libtrump),\n        replace = FALSE\n)\n\n## Or more concisely\npermuted <- sample(estim_data$libtrump)\n\n```\n\n## Test Statistic\n\nTo create the sampling distribution under the sharp null, we need to **permute** and then calculate the difference-in-means.\n\n```{webr-r}\n\nestim_data |>\n        mutate(permuted = sample(libtrump)) |>\n        summarise(permuted_diff = mean(Support[permuted == 1]) -\n                mean(Support[permuted == 0]))\n\n```\n\n## Create a function\n\n::: columns\n::: {.column width=\"50%\"}\n- We can create a function to permute and calculate the difference-in-means.\n\n- In general, if we need to do something more than once, we should create a **function**.\n\n- This will make our code more readable and easier to debug.\n\n::: {.fragment}\n\n```r\n\nfunc_name <- function(arg1, arg2, ...) {\n        # Do something\n        return(something)\n}\n\n```\n:::\n\n:::\n\n::: {.column .fragment width=\"50%\"}\n\nLet's wrap the code we just wrote into a function.\n\nWe use `pull` to extract the value from the tibble.\n\n```{webr-r}\n\npermute_diff <- function(data) {\n        mutate(data, \n          permuted = sample(libtrump)) |>\n          summarise(permuted_diff = mean(Support[permuted == 1]) -\n                    mean(Support[permuted == 0])) |>\n          pull(permuted_diff)\n}\n\npermute_diff(estim_data)\n```\n\n:::\n:::\n\n## Iterate \n\nWe can now use the function to iterate over many permutations. \n\nA useful function for this is the `replicate` function, which repeats a function a number of times.\n\n```{webr-r}\n\nperms <- replicate(1000, permute_diff(estim_data))\n\nhead(perms)\n```\n\nWe now have a distribution of differences-in-means under the sharp null hypothesis.\n\n## Visualize the Distribution\n\n::: columns\n::: {.column width=\"50%\"}\n```{webr-r}\nsamp_dist <- ggplot() +\n        geom_histogram(\n          aes(x = perms),\n          fill = \"lightblue\", \n          color = \"black\",\n          bins = 30\n        ) +\n        labs(\n            title = \n            \"Sampling Distribution\n            Under the Sharp Null\",\n            x = \"Difference-in-Means\",\n            y = \"Frequency\"\n        ) +\n        theme_minimal()\n```\n:::\n\n::: {.column  width=\"50%\"}\n\n```{webr-r}\nsamp_dist\n```\n\n:::\n:::\n\n## Compare to the Actual Test Statistic\n\n```{webr-r}\ndiff <- estim_data |>\n    summarise(actual_diff = \n                mean(Support[libtrump == 1]) - mean(Support[libtrump == 0])) |>\n        pull(actual_diff)\ndiff\nsamp_dist +  geom_vline(xintercept = diff, color = \"red\", linewidth = 1)\n```\n\n\n\n## Calculate the *p*-value\n\nCalculate the proportion of the sampling distribution that is as extreme or more extreme than the actual test statistic.\n\n\n```{webr-r}\np_value <- mean(perms >= diff)\np_value\n```\n\nIn this case, the p-value is small as there are few values in the sampling distribution that are as extreme or more extreme than the actual test statistic.\n\n## Rejecting the Null\n\n- Tests usually end with a decision to reject the null or not.\n\n- Choose a threshold below which we reject the null.\n  - [**Test level** \\alpha]{.alert}: the threshold for a test\n  - Decision rule: if the p-value is less than \\alpha, reject the null.\n  - Otherwise: fail to reject the null.\n\n- Common thresholds:\n  - $p\\geq .1$ (not statistically significant)\n  - $p < .05$ (statistically significant)\n  - $p < .01$ (highly statistically significant)\n\n## Testing errors\n\n- A $p$-value of .05 says that data as extreme or more extreme than the actual test statistic would occur 5% of the time if the null hypothesis were true.\n\n- Test errors: \n\n::: {.fragment}\n\n|   | $H_0$ True  | $H_0$ False |\n|---|---|---|\n|  Retain $H_0$| ðŸ˜€  | Type II Error: ðŸ˜ž |\n|  Reject $H_0$| Type I Error: ðŸ˜±  | ðŸ¥³ |\n\n:::\n. . .\n\n- Type 1 error is usually considered worse than Type II error.\n  - \"Convicting\" an innocent null hypothesis\n- Type 2 error is less serious \n  - \"Failing to convict\" a guilty null hypothesis\n\n# More on Iteration\n\n## More on Iteration {.center}\n\n- We used the `replicate` function to iterate over the permutations.\n\n- A useful package for iteration is the `purrr` package (part of the `tidyverse`).\n\n- The `map` function is a generalization of `replicate` that can be used to iterate over many things.\n  - Also has built in progress bars\n  - More flexible than `replicate`\n\n## Lists\n- Lists are a very flexible data structure in R.\n  - They can hold any type of data, including other lists.\n  - Can access elements by position:\n    - `list[1]` returns the first element of the list (which is a list)\n    - `list[[1]]` returns the content of first element of the list (not the list itself)\n    - `list[[1]][[1]]` returns the first element of the first element of the list.\n\n::: {.fragment}\n\n![Indexing Lists](images/lists.png){width=60%}\n\n:::\n\n## Checking Covariate Balance with `map`\n\nNow let's do a version of the permutation test using `map`. \n\n```{webr-r}\npermute_covar <- function(data) {\n        mutate(data, \n          permuted = sample(libtrump)) |>\n          summarise(permuted_diff = \n            mean(republican[permuted == 1]) -\n            mean(republican[permuted == 0]))\n                    }\n\nperm_list <- map(1:1000, \n  ~ permute_covar(pb_data),  \n  .progress = FALSE) # Progress bar\n\nperm_list[1:2]\n\n```\n\n## Covariate Balance\n\n```{webr-r}\n#To turn list of tibbles into a single tibble\nperm_df <- bind_rows(perm_list)\n\n## Actual estimate\nest <- mean(pb_data$republican[pb_data$libtrump == 1]) -\n        mean(pb_data$republican[pb_data$libtrump == 0])\nest\n\n## p-value\nmean(abs(perm_df$permuted_diff) >= abs(est))\n\ncovar_plot <- ggplot(perm_df, aes(x = permuted_diff)) +\n        geom_histogram(fill = \"lightblue\", color = \"black\", bins = 30) +\n        geom_vline(xintercept = est, color = \"red\", linewidth = 1) +\n        labs(title = \"Covariate Balance\",\n             x = \"Difference-in-Means\",\n             y = \"Frequency\") +\n        theme_minimal()\n\n```\n\n## Plot\n\n```{webr-r}\ncovar_plot\n```",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}