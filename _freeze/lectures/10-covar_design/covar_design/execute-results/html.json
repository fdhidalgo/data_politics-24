{
  "hash": "176d92f2faf4ec670cec1295379ad69f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using Covariates in Experimental Design\"\nsubtitle: \"Lecture 10\"\ndate: last-modified\nauthor: \n  - name: F. Daniel Hidalgo\n    email: dhidalgo@mit.edu\n    affiliations: MIT\nformat: \n  clean-revealjs:\n    incremental: true\nengine: knitr\nexecute: \n  cache: true\nwebr:\n  packages: ['tidyverse'] # Install R packages on document open\n  show-startup-message: false\nfilters: \n  - timer\n  - webr\nbibliography: ../data_politics_2024.bib\neditor:\n  render-on-save: true\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n# Covariates in Experimental Design\n\n## Randomization and Covariates\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/blocks_unlucky.png){width=\"100%\"}\n:::\n\n::: {.column width=\"50%\"}\n-   As discussed, while randomization gives us the right answer on average, we can still get unlucky.\n\n-   We detect bad luck typically by examining balance on pre-treatment covariates.\n\n-   For covariates that are [predictive]{.smallcaps} of the outcome, imbalance suggests we may be far off from the ATE.\n\n-   Rather than just hope for good luck, why not [**design**]{.smallcaps} for good luck?\n:::\n:::\n\n## Gabiras-Diáz and Montenegro\n\n> To increase the balance on potential confounders across treatment conditions, we conducted a stratified randomization. We defined strata by the intersection of bins partitioning the sample in three ways: **(i) by the fiftieth and eighty-fifth percentiles of the population over the age of 18, (ii) by the twentieth and eightieth percentiles of voter turnout in the first round of presidential elections in 2018, and (iii) by whether the municipalities filed reports through the MOE’s website around the congressional elections of 2018 above or below the median**\n\nStratify by:\n\n1.  Population size\n2.  Voter turnout\n3.  Reports in 2018\n\n## Population and Reports\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nggplot(col_data, aes(x = pop, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Population and Reports\",\n       x = \"Population\",\n       y = \"Reports\")\n```\n\n::: {.cell-output-display}\n![](covar_design_files/figure-revealjs/pop_outcome-1.png){width=960}\n:::\n:::\n\n\n## Voter Turnout and Reports\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nggplot(col_data, aes(x = turnout_pre, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Voter Turnout and Reports\",\n       x = \"Voter Turnout\",\n       y = \"Reports\")\n```\n\n::: {.cell-output-display}\n![](covar_design_files/figure-revealjs/turnout_outcome-1.png){width=960}\n:::\n:::\n\n\n## Baseline and Endline Reports\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nggplot(col_data, aes(x = reports_pre, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(method = \"lm\", \n              se = FALSE) +\n  labs(title = \"Baseline Reports and Reports\",\n       x = \"Baseline Reports\",\n       y = \"Reports\")\n```\n\n::: {.cell-output-display}\n![](covar_design_files/figure-revealjs/baseline_outcome-1.png){width=960}\n:::\n:::\n\n\n## Permute Treatment and Estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nra_permute <- function(data) {\n  N <- nrow(data)\n  m <- sum(data$treatment)\n  data$treatment <- complete_ra(N = N, m = m) # <1>\n  outcome_est <- difference_in_means(reports ~ treatment, data = data) # <2>\n  covar_est <- difference_in_means(log_pop ~ treatment, data = data) # <3>\n  tidied_outcome <- tidy(outcome_est) # <4>\n  tidied_covar <- tidy(covar_est) # <4>\n  \n  bind_rows(tidied_outcome, tidied_covar) # <5>\n} \n```\n:::\n\n\n1.  Permute treatment variable\n2.  Estimate treatment effect\n3.  Estimate covariate imbalance\n4.  Tidy the output. The `tidy` function is used to convert the output of the `difference_in_means` function into a data frame.\n5.  Combine the output into a single data frame.\n\n## Permute Treatment and Estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nra_permute(col_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       term    estimate  std.error  statistic   p.value    conf.low conf.high\n1 treatment -0.13377907 0.12971859 -1.0313022 0.3032509 -0.38907891 0.1215208\n2 treatment  0.02582991 0.06310037  0.4093465 0.6826049 -0.09839274 0.1500526\n        df outcome\n1 292.5771 reports\n2 274.2485 log_pop\n```\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\npermute_data <- map(1:1000, ~ ra_permute(col_data)) |>\n  bind_rows()\n## Add iteration number using rep function\npermute_data$iteration <- rep(1:1000, each = 2)\n\nhead(permute_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       term     estimate  std.error   statistic    p.value    conf.low\n1 treatment  0.175715569 0.14205152  1.23698481 0.21724053 -0.10403954\n2 treatment  0.048580089 0.06752630  0.71942474 0.47255788 -0.08441926\n3 treatment  0.053546633 0.14706103  0.36411163 0.71609348 -0.23614056\n4 treatment  0.001002501 0.06442137  0.01556162 0.98759582 -0.12583943\n5 treatment  0.297884505 0.17475687  1.70456535 0.08983542 -0.04672740\n6 treatment -0.034385952 0.06598719 -0.52110045 0.60274743 -0.16433302\n   conf.high       df outcome iteration\n1 0.45547068 252.8099 reports         1\n2 0.18157943 247.5474 log_pop         1\n3 0.34323382 241.3133 reports         2\n4 0.12784443 265.4207 log_pop         2\n5 0.64249641 199.0992 reports         3\n6 0.09556112 255.9038 log_pop         3\n```\n\n\n:::\n:::\n\n\n## Imbalance vs Treatment Effect\n\nTo visualize we need to use `pivot_wider` to reshape the data.\n\n`pivot_wider()` takes data from a single column and moves it into multiple columns based on a grouping variable (in this case, `iteration`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Use pivot_wider to reshape the data\npivoted <- permute_data |>\n  pivot_wider(id_cols = iteration, \n              names_from = outcome, values_from = estimate)\nhead(pivoted)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  iteration reports  log_pop\n      <int>   <dbl>    <dbl>\n1         1  0.176   0.0486 \n2         2  0.0535  0.00100\n3         3  0.298  -0.0344 \n4         4  0.127   0.0355 \n5         5 -0.150   0.0477 \n6         6 -0.0198 -0.0202 \n```\n\n\n:::\n:::\n\n\n## Imbalance vs Treatment Effect\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nggplot(pivoted, \n       aes(x = log_pop, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(se = FALSE) +\n  xlab(\"Imbalance in Log Population\") +\n  ylab(\"Estimated Treatment Effect\") +\n  geom_hline(yintercept = 0, \n             linetype = \"dashed\") +\n  ggtitle(\"Imbalance vs Treatment Effect\") \n```\n\n::: {.cell-output-display}\n![](covar_design_files/figure-revealjs/visualize_permute_plot-1.png){width=960}\n:::\n:::\n\n\n# `estimatr` and `randomizr` packages\n\n## `estimatr` Package\n\nUp until now, we have been calculating the difference in means between the treatment and control groups, but more complex designs require more complex estimators.\n\nThe `estimatr` package provides a number of functions to estimate treatment effects in experimental studies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(estimatr)\nestimate <- difference_in_means( # <1>\n                          formula = reports ~ treatment, # <2>\n                           data = col_data)\n```\n:::\n\n\n1.  The `difference_in_means` function is used to estimate the average treatment effect in a variety of experimental designs.\n2.  Use formula syntax to specify the outcome variable and the treatment variable: `outcome ~ treatment`.\n\n## `difference-in-means` output\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDesign:  Standard \n           Estimate Std. Error  t value   Pr(>|t|)    CI Lower  CI Upper\ntreatment 0.2653061  0.1540007 1.722759 0.08629406 -0.03814765 0.5687599\n               DF\ntreatment 226.997\n```\n\n\n:::\n:::\n\n\nOutput from the `difference_in_means` function:\n\n-   `Estimate` is the estimate of the ATE\n-   `Std. Error` is the standard error of the estimate (standard deviation of the sampling distribution)\n-   `Pr(>|t|)` is the p-value for the hypothesis test that the ATE is equal to zero\n-   `CI Lower` and `CI Upper` are the lower and upper bounds of the 95% confidence interval for the ATE\n\n## `randomizr` Package\n\nWe have been using `sample` to randomly assign treatment, but the `randomizr` package provides more complex randomization procedures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomizr)\n\nn_treatment <- 159\nn_muni <- 698\n\nassignment <- complete_ra(N = n_muni, # <1>\n                          m = n_treatment)\n```\n:::\n\n\n1.  The `complete_ra` function is used to randomly assign treatment to a specified number of units (`n_treatment`). Produces a vector of 1s and 0s, where 1 indicates treatment and 0 indicates control.\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(assignment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nassignment\n  0   1 \n539 159 \n```\n\n\n:::\n:::\n\n\n# Blocking\n\n## Blocking\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/blocks.png){width=\"100%\"}\n:::\n\n::: {.column width=\"50%\"}\n-   Rather than hoping for a balanced sample, we can ensure balance by **blocking** on important covariates.\n\n-   Basic idea:\n\n    -   Gather covariates predictive of the outcome\n    -   Group units into strata based on these covariates\n    -   Randomly assign treatment within each stratum\n\n-   If we block, we must change how we estimate the treatment effect.\\\n:::\n:::\n\n## Blocking in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Create equal sized strata based on log population\ncol_data$block <- cut_number(col_data$log_pop, 10) # <1>\n\ntreat_prob <- n_treatment / n_muni # <2>\n\nblock_assignment <- block_ra(blocks = col_data$block, # <3>\n                             prob = treat_prob) \n```\n:::\n\n\n1.  Use the `cut_number` function to create 10 equally sized strata based on the `log_pop` variable.\n2.  Calculate the probability of treatment within each stratum.\n3.  Use the `block_ra` function to randomly assign treatment within each stratum.\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(block_assignment, col_data$block)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                \nblock_assignment [8.13,8.64] (8.64,8.87] (8.87,9.05] (9.05,9.26] (9.26,9.41]\n               0          54          54          54          53          54\n               1          16          16          16          16          16\n                \nblock_assignment (9.41,9.63] (9.63,9.82] (9.82,10.1] (10.1,10.6] (10.6,11.6]\n               0          55          52          54          54          55\n               1          16          16          16          16          15\n```\n\n\n:::\n:::\n\n\n## Blocking and Analysis\n\nKey principle in analysis of experimental design:\n\n::: callout-important\n**Analyze as ye randomize**\n:::\n\n. . .\n\nWhen estimating treatment effects and uncertainty (e.g. p-values, confidence intervals), we must account for the randomization procedure used to assign treatment.\n\n. . .\n\nEach block can be considered a separate experiment, so for block $j$ with $N_J$ units, we can estimate the treatment effects in each block separately, and then average the estimates across blocks:\n\n$$\\widehat{\\textrm{ATE}} = \\sum_{j=1}^J \\frac{N_j}{N} \\widehat{\\textrm{ATE}_j}$$\n\n## Estimating Treatment Effects with Blocking\n\n\n::: {.cell}\n\n```{.r .cell-code}\nblock_estimate <- difference_in_means(\n  formula = reports ~ treatment,\n  blocks = block, # <1> \n  data = col_data)\n```\n:::\n\n\n1.  Use the `blocks` argument to specify the blocking variable.\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDesign:  Standard \n           Estimate Std. Error  t value   Pr(>|t|)    CI Lower  CI Upper\ntreatment 0.2653061  0.1540007 1.722759 0.08629406 -0.03814765 0.5687599\n               DF\ntreatment 226.997\n```\n\n\n:::\n\n```{.r .cell-code}\nblock_estimate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDesign:  Blocked \n           Estimate Std. Error  t value   Pr(>|t|)    CI Lower  CI Upper  DF\ntreatment 0.3057494  0.1662785 1.838779 0.06638493 -0.02073333 0.6322321 678\n```\n\n\n:::\n:::\n\n\n## Permutation Testing with Blocking\n\n\n::: {.cell}\n\n```{.r .cell-code}\nblock_permute <- function(data) { # <1>\n  N <- nrow(data)\n  m <- sum(data$treatment)\n  data$treatment <- block_ra(blocks = data$block, # <2>\n                             prob = m/N) \n  \n  outcome_est <- difference_in_means(reports ~ treatment,\n                                     block = block, # <3>\n                                     data = data) \n  tidied_outcome <- tidy(outcome_est) \n  tidied_outcome\n}\n\npermuted_block <- map(1:1000, ~ block_permute(col_data)) |> # <4>\n  bind_rows()\n```\n:::\n\n\n1.  Define a function `block_permute` that takes a dataset.\n2.  Use the `block_ra` function to randomly assign treatment **within each block**.\n3.  Estimate treatment effect accounting for blocking.\n4.  Use the `map` to generate the sampling distribution of the treatment effect (under the sharp null)\n\n## Sampling Distribution\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nperms <- bind_rows(tibble(Randomization = \"Blocked\", \n       Estimate = permuted_block$estimate), \n  tibble(Randomization = \"Simple\", \n         Estimate = pivoted$reports)) \n\nggplot(perms, aes(x = Estimate, \n                  color = Randomization)) +\n  geom_density(size = 3) +\n  labs(title = \"Sampling Distribution of ATE\",\n       subtitle = \"Blocked vs Simple Randomization\",\n       x = \"Estimate\",\n       y = \"Density\") +\n  geom_vline(xintercept = tidy(block_estimate)$estimate, \n             linetype = \"dashed\", \n             linewidth = 2,\n             color = \"red\")\n```\n\n::: {.cell-output-display}\n![](covar_design_files/figure-revealjs/blocking_permute_plot-1.png){width=960}\n:::\n:::\n\n\n## Inference\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Calculate p-value\n## Blocked\n mean(permuted_block$estimate > tidy(block_estimate)$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.011\n```\n\n\n:::\n\n```{.r .cell-code}\n## Simple\n mean(pivoted$reports > tidy(estimate)$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.036\n```\n\n\n:::\n:::\n\n\nBlocking:\n\n-   Ensures balance on important covariates\n-   Made our inferences more precise\n-   Changed how we estimate treatment effects and calculate p-values\n\n# Cluster Sampling\n\n## Cluster Randomization\n\n-   Sometimes the unit of randomization is not the same as the unit of analysis\n-   In Gabiras-Diáz and Montenegro, the unit of randomization is the municipality, but they also examine candidate-level outcomes.\n-   Following the principle of **analyze as ye randomize**, we need to account for the clustering of the treatment assignment when estimating treatment effects and uncertainty.\n\n## Cambridge\n\n![](images/cambridge_ward_precincts.png)\n\nImagine you are sampling 100 Cambridge voters and asking them about their turnout in the most recent local election. You have two options:\n\n1.  You can randomly sample 100 voters using simple random sampling.\n2.  You can first randomly sample 2 precincts and then interview 50 voters in each sampled precinct.\n\n\n## Voter File\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncambr_voter <- read_csv(\"cambridge_voter_history16_18.zip\", \n                        show_col_types = FALSE)\nfilter(cambr_voter, last_name == \"HIDALGO\" & middle_name == \"DANIEL\") |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1\nColumns: 16\n$ voter_id_number                   <chr> \"01HFO1280000\"\n$ last_name                         <chr> \"HIDALGO\"\n$ first_name                        <chr> \"FERNANDO\"\n$ middle_name                       <chr> \"DANIEL\"\n$ residential_address_street_number <dbl> 23\n$ residential_address_street_name   <chr> \"MURDOCK ST\"\n$ residential_address_zip_code      <chr> \"021391214\"\n$ party_affiliation                 <chr> \"D\"\n$ date_of_birth                     <date> 1980-01-12\n$ ward_number                       <chr> \"03\"\n$ precinct_number                   <chr> \"02\"\n$ turnout_110618                    <dbl> 1\n$ turnout_090418                    <dbl> 1\n$ turnout_110717                    <dbl> 1\n$ turnout_110816                    <dbl> 1\n$ turnout_090816                    <dbl> 0\n```\n\n\n:::\n:::\n\n\n## Turnout Heterogeneity\n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\ncambr_voter$prec_code <- paste(cambr_voter$ward_number, \n                               cambr_voter$precinct_number)\n\ncambr_voter |>\n  group_by(prec_code) |>\n  summarize(turnout = mean(turnout_110717, na.rm = TRUE)) |>\n## Order precinct by turnout\n  mutate(prec_code = fct_reorder(prec_code, turnout)) |>\n  ggplot(aes(x = prec_code, y = turnout)) +\n  geom_col() +\n  labs(title = \"Turnout by Precinct\",\n       x = \"Precinct\",\n       y = \"Turnout Rate\") +\n# Rotate x-axis labels\ntheme(axis.text.x = element_text(angle = 90, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](covar_design_files/figure-revealjs/cambridge_turnout-1.png){width=960}\n:::\n:::\n\n## Two Sampling Distributions\n\n![](images/cambridge_cluster_sampdist.png)\n\n## Accounting for Clustered Sampling\n\nFor estimation and inference, we need to account for the clustering of the treatment assignment. Otherwise, inferences can be very misleading!\n\n. . .\n\nEasiest and most direct way is to:\n\n  - Collapse the data to the cluster level by taking cluster-level averages \n  - Estimate  treatment effect and conduct inference using the cluster-level data using our usual methods. \n\n. . .\n\nLess direct way: \n\n - When using permutation inference or the bootstrap, **resample at the cluster level**.\n  - This will account for the clustering of the treatment assignment.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}