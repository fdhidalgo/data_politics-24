---
title: "Problem Set 4"
author: "Your Name"
format: html
---

------------------------------------------------------------------------

```{r, cache=T}
#| echo: FALSE
#| warning: FALSE

library(tidyverse)
set.seed(1234)
```

## Instructions

Please submit this assignment on Gradescope by April 11. The .qmd file can be submitted at the following link: https://www.dropbox.com/request/KQSmAJiTwmh5nijFo9Fk

You will need to submit the following two files:

1.  An .qmd file (or “Quarto file” when spoken) that is a plain-text file that contains the text of your write-up and the code used to do all of the calculations for the assignment. You can write directly into this file in RStudio.
2.  An output .pdf file that contains the compiled version of the qmd file. You can create this file by clicking the “Render” button in RStudio.

## Importing the data

```{r, tidy = TRUE}
#| label: import_data
#| warnings: FALSE
#| messages: FALSE



# Problem 1 Data
green_df <- readr::read_csv("https://www.dropbox.com/scl/fi/8hu4hb4l7qu85zj8soxp0/green_df.csv?rlkey=moi2dowgxazltngrawif87aza&dl=1", show_col_types = FALSE)

# Problem 2 Data
bias_df <- readr::read_csv("https://www.dropbox.com/scl/fi/munhzfvhmfry10wl8t7y5/bias_df.csv?rlkey=xtebs0iazk80lmaznkytb8dfg&dl=1", show_col_types = FALSE)



```

## Problem 1

In this first problem, we will analyze data from the following paper:

> Green, Donald P., Anna M. Wilke, and Jasper Cooper. "Countering Violence Against Women by Encouraging Disclosure: A Mass Media Experiment in Rural Uganda" *Comparative Political Studies* (2020): 2283-2320. [https://doi.org/10.1177/001041402091227](https://doi.org/10.1177/001041402091227){.url}

Green et al. (2020) conduct a field experiment in rural Uganda to test the effect of a media campaign on attitudes toward violence against women (VAW) and people's willingness to report these incidents to authorities. In this field experiment, the treatment involved exposing people in Uganda to video vignettes. The treatment group received an anti-VAW vignette, while the control received a placebo that was a Hollywood movie. The treatment and control conditions were administered through village-wide screenings of the videos.

The authors used both cluster randomization and blocking when designing the experiment. Due to the nature of the treatment (ie a village-wide screening), randomization was done at the village level. In total, the researchers selected 112 villages. Within each village, the researchers then randomly sampled individuals to participate in the study. Prior to randomization, the researchers split the villages up into 16 blocks of seven villages to minimize imbalance on geographic factors. We will explore the results of this study.

The `green_df` data includes the following variables:

-   `cluster_id`: A unique identifier for each cluster (village)
-   `block_id`: A unique identifier for each block
-   `treat`: A binary variable indicating treatment status (1 = treatment, 0 = control)
-   `intervene_index`: A continuous variable measuring the intervention's effect on willingness to report VAW incidents to authorities. Higher values indicate more willingness to report

For this problem set, the data is subset to only include female respondents.

### Problem 1(a)

To start, we are going to ignore the clustering in the data and only focus on the blocks. First, calculate the average treatment effect of the video vignette on willingness to report VAW incidents while incorporating the blocked randomization.

```{r}
# Your code here
```

Next, state the sharp null and alternative hypotheses. Conduct a permutation test and plot the null distribution with your observed estimate overlaid. Calculate a p-value for the test. When doing this, make sure to incorporate the blocks in the analysis. Does the intervention have a statistically significant effect on willingness to report VAW incidents?

```{r}
# Your code here
```

### Problem 1(b)

Now we are going to ignore the block randomization and only focus on the clusters in the data. First, calculate the average treatment effect of the video vignette on willingness to report VAW incidents while incorporating the clustered randomization.

```{r}
# Your code here
```

Next, conduct a permutation test and plot the null distribution with your observed estimate overlaid. Calculate a p-value for the test. When doing this, make sure to incorporate the clusters in the analysis. How does it compare to the p-value you calculated in Problem 1(a)?

```{r}
# Your code here
```

### Problem 1(c)

Finally, we are going to incorporate both the cluster and block randomization in the data. First, calculate the average treatment effect of the video vignette on willingness to report VAW incidents while incorporating the complete randomization scheme.

```{r}
# Your code here
```

Next, conduct a permutation test and plot the null distribution with your observed estimate overlaid. Calculate a p-value for the test. When doing this, make sure to incorporate both the clusters and blocks in the analysis. Interpret the results. What do these results tell us about the effectiveness of the experimental intervention?

```{r}
# Your code here
```

## Problem 2

In this second problem, we will analyze data from another paper:

> Yair, Omer and Gregory A. Huber. "How Robust is Evidence of Partisan Perceptual Bias in Survey Responses? A New Approach for Studying Expressive Responding" *Public Opinion Quarterly* (2020): 469-492. [https://doi:10.1093/poq/nfaa024](https://doi:10.1093/poq/nfaa024){.url}.

In this paper, the authors explore the extent to which partisan biases affect survey responses. Existing work on partisan biases finds evidence that these biases can impact seemingly unrelated evaluations. For example, the authors cite a study on the relationship between partisanship and perceptions of attractiveness. In the original study by Nicholson et al (2016), the authors find that partisanship impacts evaluations of physical attractiveness. Yair and Huber are skeptical of this finding, arguing that the results are likely evidence of expressive responding. In other words, people are not actually changing their evaluations of attractiveness based on partisanship, but instead are expressing their partisanship in their responses.

To get around this concern, Yair and Huber introduce a new measurement strategy that allows respondents to "blow off the steam" of their partisanship. They replicate the initial study on attractiveness but introduce new conditions. In this design, respondents are presented with an image of a person of the opposite sex. Below the image, there is basic non-political information about the person (control). In the treatment conditions, there is also information about whether the person is a Democrat or a Republican. Respondents are then asked to rate how attractive the person is. Yair and Huber add two additional treatment arms. In addition to the replication of the original study, they include a condition where respondents are asked a question about the values of the person shown to them ("blowing off steam") and a condition where respondents are told they they will evaluate both the person's attractiveness and values ("warning"). The goal of both of these treatment arms is to provide respondents with alternative pathways to express their partisanship other than the attractiveness rating.

In this question we will explore the results of Yair and Huber's study. We will use the `bias_df` data frame. The data includes the following variables:

-   `pid`: A binary variable indicating partisanship (1 = Democrat, 0 = Republican)
-   `pid_profile_match`: A binary variable indicating whether the respondent's partisanship matches the partisanship of the person in the image (1 = match, 0 = mismatch)
-   `pid_profile_mismatch`: A binary variable indicating whether the respondent's partisanship does not match the partisanship of the person in the image (1 = mismatch, 0 = match)
-   `treat`: A factor variable indicating the respondents' were in the control condition or received either the "blowing of steam" or "warning" treatment
-   `outcome_pooled`: A continuous variable measuring the attractiveness rating of the person in the image. The variable ranges from -3 to 3
-   `matchXtreat`: A binary variable indicating whether the respondent's partisanship matches the partisanship of the person in the image and they recieved either of the treatments
-   `mismatchXtreat`: A binary variable indicating whether the respondent's partisanship does not match the partisanship of the person in the image and they recieved either of the treatments

### Problem 2(a)

We are going to start by producing an estimate of partisan bias without accounting for expressive responding. To do this, Yair and Huber use the following linear model to estimate the effect of exposure to a matched and mismatched profile on attractiveness ratings:

```{=tex}
\begin{center}
$\text{Attractivness} = \beta_0 + \beta_1*\text{Match} + \beta_2\text{Mismatch}$
\end{center}
```
Yair and Huber state that the estimate of partisan bias is the difference between the coefficient for the mismatch condition ($\beta_2$) and the match condition ($\beta_1$). Use a linear model to estimate the effect of exposure to both a matched and mismatched profile on attractiveness ratings. Present your results clearly in a table. Using the results of the model, calculate the level of partisan bias in the evaluations. Make sure to subset the data so that you are only including respondents in the control condition as we are not yet incorporating the conditions to reduce expressive responding. What do the results tell us about partisan bias?

```{r}
# Your code here
```

Next, we want to evaluate whether this partisan bias is drive by either of the two parties. Subset the data by partisanship and run the regressions again. Present the results in a table. Do we see a difference in partisan bias between the parties?

```{r}
# Your code here
```

### Problem 2(b)

Now we want to evaluate whether the authors' proposed interventions work. Remember, the authors added two conditions that provided respondents with alternative pathways to express their partisanship. For this analysis, both conditions are combined. The authors use the following linear model to estimate the effect of the pooled treatment on perceptions of attractiveness:

```{=tex}
\begin{center}
$\text{Attractivness} = \beta_0 + \beta_1*\text{Match} + \beta_2\text{Mismatch} + \beta_3*\text{EitherXMatch} + \beta_4*\text{Either*XMismatch}$
\end{center}
```
Yair and Huber state that this model allows them to compare estimates of partisan bias in the control conditions and either treatment condition. The baseline estimate of partisan bias is calculated the same way as above ($\beta_2$ - $\beta_1$). This model also allows the authors to calculate partisan bias in either of the treatment conditions ($\beta_4$ - $\beta_3$). Run this model and present the results in a table. Compare the estimates of partisan bias between the baseline and the treatment conditions. What do the results tell us about the effectiveness of the interventions?

```{r}
# Your code here
```

Just as we saw that the partisan bias may be driven by a specific party, we may also want to evaluate the results of the intervention by party identification. Subset the data by partisanship and run the regressions again. Present the results in a table. Do we see a difference in the effect of the intervention between the parties?

```{r}
# Your code here
```
