---
title: "Inference in Experiments"
subtitle: "Lecture 5"
date: last-modified
author: 
  - name: F. Daniel Hidalgo
    email: dhidalgo@mit.edu
    affiliations: MIT
format: 
  clean-revealjs:
    incremental: true
engine: knitr
webr:
  packages: ['tidyverse'] # Install R packages on document open
  show-startup-message: false
filters: 
  - timer
  - webr
bibliography: ../data_politics_2024.bib
editor:
  render-on-save: true
---

```{r}
#| label: echo
#| echo: false
#| warning: false

library(tidyverse)
library(hrbrthemes)
library(gganimate)
theme_set(theme_ipsum())
```

# Inference: Hypothesis Testing

## Hypothesis Testing {.center}

::: columns
::: {.column width="50%"}
-   We have discussed estimation of ATEs and how the difference-in-means is *over repeated randomizations* an unbiased estimator of the ATE.

-   But any particular estimate may be close or far from the true ATE.

-   How do we know if our finding is unlikely to have occurred by chance?
:::

::: {.column width="50%"}
![H/T [xkcd](https://xkcd.com/892/)](images/null_hypothesis.png)
:::
:::

## Logic of Hypothesis Testing

-   We start with an *imagined* world in which the treatment has a particular effect: [the **null hypothesis** ($H_0$)]{.alert}

-   We ask: under our maintained assumptions, how likely is it that we would observe the data we have if the null hypothesis were true?

    -   *Important*: It is not the probability that any partifcular hypothesis is true, but the probability of observing the data we have if the null hypothesis were true.

-   If the probability is low, we [**reject**]{.alert} the null hypothesis in favor of the [**alternative hypothesis** ($H_1$)]{.alert}. ðŸ˜Ž

-   If the probability is high, we [**fail to reject**]{.alert} the null hypothesis. ðŸ˜¢

    -   We do not accept the null hypothesis, we just fail to reject it.

## The Sharp Null

In experiments, we might be interested in the [**sharp null hypothesis**]{.alert}:

. . .

::: {.callout-note title="Sharp Null Hypotheis of No Effect"}
The treatment effect is 0 for all units: $Y_i(1)=Y_i(0)$ for all $i$.
:::

**Key idea:** in the world where the sharp null hypothesis is true, we observe all the potential outcomes!

::: columns
::: {.column width="50%"}
**The Real World**

| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |
|-----|-------|----------|----------|
| 1   | 1     | ?        | 1        |
| 2   | 0     | -1       | ?        |
| 3   | 1     | ?        | 0        |
:::

::: {.column .fragment width="50%"}
**The Sharp Null World**

| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |
|-----|-------|----------|----------|
| 1   | 1     | 1        | 1        |
| 2   | 0     | -1       | -1       |
| 3   | 1     | 0        | 0        |
:::
:::

## Sampling Distribution Under the Sharp Null

-   To conduct a hypothesis test, we need to know the distribution of our estimator (the difference-in-means) under the sharp null hypothesis.
-   We can do this by:
    1.  Calculate the actual test statistic (i.e. difference-in-means) in our sample.
    2.  Permute the treatment assignment the *same* way you originally assigned treatment and calculate the test statistic.
    3.  Repeat step 2 many times.
    4.  Compare the actual test-statistic to the distribution of differences-in-means under the sharp null.

. . .

::: {.callout-note title="Permutation Test *p*-value"}
   The p-value is the proportion of test-statistics from sampling distribution under the null that are as extreme or more extreme than the actual test-statistic.
:::
   

## Barber and Pope Data 


```{webr-r}
#| context: setup

# Download a dataset
download.file(
        "https://github.com/fdhidalgo/data_politics-24/raw/main/lectures/06-inference/pope_barber.csv.gz",
        destfile = "pope_barber.csv.gz"
)

pb_data <- read_csv("pope_barber.csv.gz")
```

```{webr-r}
pb_data
```

