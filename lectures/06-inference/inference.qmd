---
title: "Inference in Experiments"
subtitle: "Lecture 5"
date: last-modified
author: 
  - name: F. Daniel Hidalgo
    email: dhidalgo@mit.edu
    affiliations: MIT
format: 
  clean-revealjs:
    incremental: true
engine: knitr
webr:
  packages: ['tidyverse'] # Install R packages on document open
  show-startup-message: false
filters: 
  - timer
  - webr
bibliography: ../data_politics_2024.bib
editor:
  render-on-save: true
---

```{r}
#| label: echo
#| echo: false
#| warning: false

library(tidyverse)
library(hrbrthemes)
library(gganimate)
theme_set(theme_ipsum())
```

# Inference: Hypothesis Testing

## Hypothesis Testing {.center}

::: columns
::: {.column width="50%"}
-   We have discussed estimation of ATEs and how the difference-in-means is *over repeated randomizations* an unbiased estimator of the ATE.

-   But any particular estimate may be close or far from the true ATE.

-   How do we know if our finding is unlikely to have occurred by chance?
:::

::: {.column width="50%"}
![H/T [xkcd](https://xkcd.com/892/)](images/null_hypothesis.png)
:::
:::

## Logic of Hypothesis Testing

-   We start with an *imagined* world in which the treatment has a particular effect: [the **null hypothesis** ($H_0$)]{.alert}

-   We ask: under our maintained assumptions, how likely is it that we would observe the data we have if the null hypothesis were true?

    -   *Important*: It is not the probability that any partifcular hypothesis is true, but the probability of observing the data we have if the null hypothesis were true.

-   If the probability is low, we [**reject**]{.alert} the null hypothesis in favor of the [**alternative hypothesis** ($H_1$)]{.alert}. ðŸ˜Ž

-   If the probability is high, we [**fail to reject**]{.alert} the null hypothesis. ðŸ˜¢

    -   We do not accept the null hypothesis, we just fail to reject it.

## The Sharp Null

In experiments, we might be interested in the [**sharp null hypothesis**]{.alert}:

. . .

::: {.callout-note title="Sharp Null Hypotheis of No Effect"}
The treatment effect is 0 for all units: $Y_i(1)=Y_i(0)$ for all $i$.
:::

**Key idea:** in the world where the sharp null hypothesis is true, we observe all the potential outcomes!

::: columns
::: {.column width="50%"}
**The Real World**

| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |
|-----|-------|----------|----------|
| 1   | 1     | ?        | 1        |
| 2   | 0     | -1       | ?        |
| 3   | 1     | ?        | 0        |
:::

::: {.column .fragment width="50%"}
**The Sharp Null World**

| $i$ | $D_i$ | $Y_i(0)$ | $Y_i(1)$ |
|-----|-------|----------|----------|
| 1   | 1     | 1        | 1        |
| 2   | 0     | -1       | -1       |
| 3   | 1     | 0        | 0        |
:::
:::

## Sampling Distribution Under the Sharp Null

-   To conduct a hypothesis test, we need to know the distribution of our estimator (the difference-in-means) under the sharp null hypothesis.
-   We can do this by:
    1.  Calculate the actual test statistic (i.e. difference-in-means) in our sample.
    2.  Permute the treatment assignment the *same* way you originally assigned treatment and calculate the test statistic.
    3.  Repeat step 2 many times.
    4.  Compare the actual test-statistic to the distribution of differences-in-means under the sharp null.

. . .

::: {.callout-note title="Permutation Test *p*-value"}
   The p-value is the proportion of test-statistics from sampling distribution under the null that are as extreme or more extreme than the actual test-statistic.
:::
   

## Barber and Pope Data 


```{webr-r}
#| context: setup

# Download a dataset
download.file(
        url = "https://raw.githubusercontent.com/fdhidalgo/data_politics-24/main/lectures/06-inference/pope_barber.csv",
        destfile = "pope_barber.csv"
)

pb_data <- read.csv("pope_barber.csv") |>
        as_tibble() |>
        na.omit()
```

```{webr-r}
#| autorun: true
pb_data

estim_data <- pb_data |>
        filter(republican == 1 & (libtrump == 1 | self == 1))
```

##  `sample`

To sample from a vector, we can use the `sample` function, where `size` is the number of samples, and `replace` is whether we want to sample with replacement.

```{webr-r}
sample(estim_data$libtrump,
        size = 5,
        replace = FALSE
)
```

. . .

To permute an entire vector, you can use `sample`  where `size` is the length of the treatment vector.

```{webr-r}
permuted <- sample(estim_data$libtrump,
        size = length(estim_data$libtrump),
        replace = FALSE
)

## Or more concisely
permuted <- sample(estim_data$libtrump)

```

## Test Statistic

To create the sampling distribution under the sharp null, we need to **permute** and then calculate the difference-in-means.

```{webr-r}

estim_data |>
        mutate(permuted = sample(libtrump)) |>
        summarise(permuted_diff = mean(Support[permuted == 1]) -
                mean(Support[permuted == 0]))

```

## Create a function

::: columns
::: {.column width="50%"}
- We can create a function to permute and calculate the difference-in-means.

- In general, if we need to do something more than once, we should create a **function**.

- This will make our code more readable and easier to debug.

::: {.fragment}

```r

func_name <- function(arg1, arg2, ...) {
        # Do something
        return(something)
}

```
:::

:::

::: {.column .fragment width="50%"}

Let's wrap the code we just wrote into a function.

We use `pull` to extract the value from the tibble.

```{webr-r}

permute_diff <- function(data) {
        mutate(data, 
          permuted = sample(libtrump)) |>
          summarise(permuted_diff = mean(Support[permuted == 1]) -
                    mean(Support[permuted == 0])) |>
          pull(permuted_diff)
}

permute_diff(estim_data)
```

:::
:::

## Iterate 

We can now use the function to iterate over many permutations. 

A useful function for this is the `replicate` function, which repeats a function a number of times.

```{webr-r}

perms <- replicate(1000, permute_diff(estim_data))

head(perms)
```

We now have a distribution of differences-in-means under the sharp null hypothesis.

## Visualize the Distribution

::: columns
::: {.column width="50%"}
```{webr-r}
samp_dist <- ggplot() +
        geom_histogram(
          aes(x = perms),
          fill = "lightblue", 
          color = "black",
          bins = 30
        ) +
        labs(
            title = 
            "Sampling Distribution
            Under the Sharp Null",
            x = "Difference-in-Means",
            y = "Frequency"
        ) +
        theme_minimal()
```
:::

::: {.column  width="50%"}

```{webr-r}
samp_dist
```

:::
:::

## Compare to the Actual Test Statistic

```{webr-r}
diff <- estim_data |>
    summarise(actual_diff = 
                mean(Support[libtrump == 1]) - mean(Support[libtrump == 0])) |>
        pull(actual_diff)
diff
samp_dist +  geom_vline(xintercept = diff, color = "red", linewidth = 1)
```



## Calculate the *p*-value

Calculate the proportion of the sampling distribution that is as extreme or more extreme than the actual test statistic.


```{webr-r}
p_value <- mean(perms >= diff)
p_value
```

In this case, the p-value is small as there are few values in the sampling distribution that are as extreme or more extreme than the actual test statistic.

## Rejecting the Null

- Tests usually end with a decision to reject the null or not.

- Choose a threshold below which we reject the null.
  - [**Test level** \alpha]{.alert}: the threshold for a test
  - Decision rule: if the p-value is less than \alpha, reject the null.
  - Otherwise: fail to reject the null.

- Common thresholds:
  - $p\geq .1$ (not statistically significant)
  - $p < .05$ (statistically significant)
  - $p < .01$ (highly statistically significant)

## Testing errors

- A $p$-value of .05 says that data as extreme or more extreme than the actual test statistic would occur 5% of the time if the null hypothesis were true.

- Test errors: 

::: {.fragment}

|   | $H_0$ True  | $H_0$ False |
|---|---|---|
|  Retain $H_0$| ðŸ˜€  | Type II Error: ðŸ˜ž |
|  Reject $H_0$| Type I Error: ðŸ˜±  | ðŸ¥³ |

:::
. . .

- Type 1 error is usually considered worse than Type II error.
  - "Convicting" an innocent null hypothesis
- Type 2 error is less serious 
  - "Failing to convict" a guilty null hypothesis

# More on Iteration

## More on Iteration {.center}

- We used the `replicate` function to iterate over the permutations.

- A useful package for iteration is the `purrr` package (part of the `tidyverse`).

- The `map` function is a generalization of `replicate` that can be used to iterate over many things.
  - Also has built in progress bars
  - More flexible than `replicate`

## Lists
- Lists are a very flexible data structure in R.
  - They can hold any type of data, including other lists.
  - Can access elements by position:
    - `list[1]` returns the first element of the list (which is a list)
    - `list[[1]]` returns the content of first element of the list (not the list itself)
    - `list[[1]][[1]]` returns the first element of the first element of the list.

::: {.fragment}

![Indexing Lists](images/lists.png){width=60%}

:::

## Checking Covariate Balance with `map`

Now let's do a version of the permutation test using `map`. 

```{webr-r}
permute_covar <- function(data) {
        mutate(data, 
          permuted = sample(libtrump)) |>
          summarise(permuted_diff = 
            mean(republican[permuted == 1]) -
            mean(republican[permuted == 0]))
                    }

perm_list <- map(1:1000, 
  ~ permute_covar(pb_data),  
  .progress = FALSE) # Progress bar

perm_list[1:2]

```

## Covariate Balance

```{webr-r}
#To turn list of tibbles into a single tibble
perm_df <- bind_rows(perm_list)

## Actual estimate
est <- mean(pb_data$republican[pb_data$libtrump == 1]) -
        mean(pb_data$republican[pb_data$libtrump == 0])
est

## p-value
mean(abs(perm_df$permuted_diff) >= abs(est))

covar_plot <- ggplot(perm_df, aes(x = permuted_diff)) +
        geom_histogram(fill = "lightblue", color = "black", bins = 30) +
        geom_vline(xintercept = est, color = "red", linewidth = 1) +
        labs(title = "Covariate Balance",
             x = "Difference-in-Means",
             y = "Frequency") +
        theme_minimal()

```

## Plot

```{webr-r}
covar_plot
```