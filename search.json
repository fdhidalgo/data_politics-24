[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Below are the Topics, Readings, and Assignment schedules for the course. Materials for each week will be posted on the course website, with links appearing in the Readings schedule below. In a few cases, PDFs will be uploaded to the course Canvas site.\nReadings, lecture slides, and related materials will be posted on each week’s page, which can be reached either by clicking on the week in the Topics schedule below or by clicking on the week on the Materials page."
  },
  {
    "objectID": "schedule.html#topics-overview",
    "href": "schedule.html#topics-overview",
    "title": "Schedule",
    "section": "Topics Overview",
    "text": "Topics Overview\n\n\nTopics ScheduleWeekDateMethods TopicApplied TopicComputing Topic12/6IntroductionIntroduction to `R`2/8Logic of Experiments`R` Basics32/22Data VisualizationIntergroup Prejudice`ggplot2` Basics42/27Estimation & Sampling DistributionsPartisanship vs IdeologyData Wrangling with `dplyr`2/29InferenceFunctions & Iteration53/5Measurement: Asking QuestionsChanging Political BeliefsData Types and Recoding Data3/7Measurement: Measurement Error63/12Experimental Design: StratificationCombatting Electoral Fraud`randomizr` package3/14Experimental Design: Clustering73/19Statistical PowerAuthoritarian CensorshipSimulations3/21Choosing Experimental Designs84/2Linear Models and ExperimentsMisinformationLinear Modeling with `lm`4/4Covariate Adjustment`estimatr` package94/9Public Opinion SurveysAffective Polarization`survyr` package4/11Survey Methodology104/16Survey Non-ResponseNon-Response Bias in Recent Elections 4/18Addressing Non-Response114/23Predictive ModelingPredicting Electoral Outcomes4/25Modeling and Surveys124/30Final Project  5/2Final Project135/7Final Project5/9Final Project145/14Final Project"
  },
  {
    "objectID": "schedule.html#readings-schedule",
    "href": "schedule.html#readings-schedule",
    "title": "Schedule",
    "section": "Readings Schedule",
    "text": "Readings Schedule\n\n\n\nWeek 1\nMethods\nApplied\nComputation\n\n\n\n\n1\nGG pgs 1-30\n\nRDS 2\n\n\n3\nGG pgs 30-45\nMousa (2020)\nRDS 1, 3\n\n\n4\nGG pgs 51-71\nBarber and Pope (2019)\nRDS 25.1-25.2, 26, 27.5\n\n\n5\nStantcheva (2023)\nBroockman and Kalla (2016)\nRDS 12, 13, 14\n\n\n6\nGG pgs. 71-80\nGarbiras-Díaz and Montenegro (2022)\nrandomizr vignette\n\n\n7\nGG pgs 80-85\nKing, Pan, and Roberts (2014)\n\n\n\n8\nGG pgs. 95-105\nArechar et al. (2023)\n\n\n\n9\nCh. 4 in Groves et al. (2009)\nAhler and Sood (2018)\nsrvyr vignette\n\n\n10\nCh. 6 in Groves et al. (2009)\nCohn, Nate (2023)\n\n\n\n11\n\nJennings and Wlezien (2018)"
  },
  {
    "objectID": "schedule.html#assignments-schedule",
    "href": "schedule.html#assignments-schedule",
    "title": "Schedule",
    "section": "Assignments Schedule",
    "text": "Assignments Schedule\n\n\nAssignments ScheduleWeekDue DateAssignment22/12Reading Quiz2/14Tutorial42/26Reading Quiz2/28Tutorial2/29*Problem Set 1*53/4Reading Quiz3/8*Problem Set 2*73/18Reading Quiz3/21Tutorial3/22*Problem Set 3*84/2Reading Quiz4/3Tutorial94/9Reading Quiz4/10Tutorial4/11*Problem Set 4*104/16Reading Quiz114/25*Problem Set 5*135/9*Problem Set 6*145/14*Class Project Writeup*"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#what-works-to-reduce-prejudice",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#what-works-to-reduce-prejudice",
    "title": "Contact Theory and Data Visualization in R",
    "section": "What works to reduce prejudice?",
    "text": "What works to reduce prejudice?\n\nInter-group animus or prejudice can be enduring and pervasive\n\nEthnic\nSexual identity\nAge\nPartisanship\n\n\n\n\nHow can we reduce prejudice?\n\nMedia campaigns?\nSensitivity trainings?\nMulticultural education?\nInter-group contact\n\n\n\n\nMany possible interventions, but most have poor evidence of effectiveness."
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#what-types-of-interventions-are-studied",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#what-types-of-interventions-are-studied",
    "title": "Contact Theory and Data Visualization in R",
    "section": "What Types of Interventions are Studied?",
    "text": "What Types of Interventions are Studied?\n\n\n\n\n\n\n\n\n\nPaluck et al. (2021)"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#inter-group-contact",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#inter-group-contact",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Inter-group Contact",
    "text": "Inter-group Contact\n\n\n Segregation in the Boston Area (Source: NY Times)\n\nContact Theory (Allport 1954):\n\nPositive contact between members of different groups can reduce prejudice\nConditions:\n\nEqual status\nCommon goals\nIntergroup cooperation\nSupport of authorities, law, or custom"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#research-design",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#research-design",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Research Design",
    "text": "Research Design\n\n\nMost common study ask if attitudes or behavior (less common) is correlated with contact\n\nSome include demographic or other controls\nConsistent evidence for contact theory\n\n\n\n\n\n\nSecond most common study uses “laboratory” experiments\n\nControlled (i.e. scripted) settings and random assignment\nIntergroup contact is brief\nMeasurement occurs shortly after contact\nExample: Pagtolun-an and Clair (1986) had a gay man answer questions about homosexuality for 90 minutes and then post-tested students"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#field-experiments",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#field-experiments",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Field Experiments",
    "text": "Field Experiments\n\n\n\n\n\nField experiments:\n\nRandom assignment to treatment and control\nReal-world (less controlled) settings\nShort and Long-term follow-up"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mousa-2020",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mousa-2020",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mousa (2020)",
    "text": "Mousa (2020)\n\n\n\n\n\n\nAftermath of genocide\nNaturalistic study\nMeasuring behavior and attitudes\nRandom assignment to treatment and control\n\nEnsures potential outcomes are independent of treatment assignment\nBackground characteristics (covariates) are balanced across treatment and control"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mousa-2020-1",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mousa-2020-1",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mousa (2020)",
    "text": "Mousa (2020)\n\n\n\n459 players, 42 Christian soccer teams\nOn the field outcomes:\n\nSign up for mixed team\nVote for Muslim for Sportsmanship prize\nTrain with Muslims\n\nOff the field outcomes:\n\nAttend mixed event\nPatronize Muslim events\nDonate to neutral NGO\n\n\n\n\nAttitudinal indexes:\n\nNational unity\nMuslim blame\nMuslim neighbor"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#ggplot2-in-tidyverse",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#ggplot2-in-tidyverse",
    "title": "Contact Theory and Data Visualization in R",
    "section": "ggplot2 \\(\\in\\) tidyverse",
    "text": "ggplot2 \\(\\in\\) tidyverse\n\n\n\n\n\nggplot2 is tidyverse’s data visualization package\nStructure of the code for plots can be summarized as\n\nggplot(data = [dataset], \n       mapping = aes(x = [x-variable], \n                     y = [y-variable])) +\n   geom_xxx() +\n   other options"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#midwest-data",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#midwest-data",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Midwest data",
    "text": "Midwest data\n\nlibrary(ggplot2)\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\n\n\nThis section draws heavily on slides prepared by Matt Blackwell."
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#building-up-a-graph-in-pieces",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#building-up-a-graph-in-pieces",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Building up a graph in pieces",
    "text": "Building up a graph in pieces\nCreate ggplot object and direct it to the correct data:\n\np &lt;- ggplot(data = midwest)\n\nMapping: tell ggplot what visual aesthetics correspond to which variables\n\np &lt;- ggplot(data = midwest,\n            mapping = aes(x = popdensity,\n                          y = percbelowpoverty))\n\nOther aesthetic mappings: color, shape, size, etc."
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#adding-a-geom-layer",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#adding-a-geom-layer",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Adding a geom layer",
    "text": "Adding a geom layer\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty)) + \n  geom_point()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#adding-a-geom-layer-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#adding-a-geom-layer-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Adding a geom layer",
    "text": "Adding a geom layer"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#trying-a-new-geom",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#trying-a-new-geom",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Trying a new geom",
    "text": "Trying a new geom\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty)) + \n  geom_smooth()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#trying-a-new-geom-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#trying-a-new-geom-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Trying a new geom",
    "text": "Trying a new geom\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#layering-geoms-is-additive",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#layering-geoms-is-additive",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Layering geoms is additive",
    "text": "Layering geoms is additive\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty)) + \n  geom_point() + \n  geom_smooth() +\n  scale_x_log10()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#layering-geoms-is-additive-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#layering-geoms-is-additive-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Layering geoms is additive",
    "text": "Layering geoms is additive\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#geoms-are-functions",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#geoms-are-functions",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Geoms are functions",
    "text": "Geoms are functions\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_x_log10()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#geoms-are-functions-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#geoms-are-functions-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Geoms are functions",
    "text": "Geoms are functions\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#adding-informative-labels",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#adding-informative-labels",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Adding Informative Labels",
    "text": "Adding Informative Labels\n\np2 &lt;- ggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_x_log10() +\n  labs(\n    x = \"Population Density\",\n    y = \"Percent of County Below Poverty Line\", \n    title = \"Poverty and Population Density\",\n    subtitle = \"Among US Midwestern Counties\", \n    caption = \"US Census, 2000\"\n  )\np2"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#adding-informative-labels-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#adding-informative-labels-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Adding Informative Labels",
    "text": "Adding Informative Labels\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-vs-setting-aesthetics",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-vs-setting-aesthetics",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mapping vs setting aesthetics",
    "text": "Mapping vs setting aesthetics\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty,\n                    color = \"purple\")) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_x_log10()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-vs-setting-aesthetics-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-vs-setting-aesthetics-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mapping vs setting aesthetics",
    "text": "Mapping vs setting aesthetics\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-always-refers-to-variables",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-always-refers-to-variables",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mapping always refers to variables",
    "text": "Mapping always refers to variables\nIf passed a value other than a variable name, ggplot will implicitly create a variable with that value (in this case “purple” that is constant)\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty,\n                    color = \"purple\")) + \n  geom_point() + \n  geom_smooth() +\n  scale_x_log10()\n\n\nSet the color outside the mapping = aes() format.\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, y = percbelowpoverty)) + \n  geom_point(color = \"purple\") + \n  geom_smooth() +\n  scale_x_log10()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-always-refers-to-variables-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-always-refers-to-variables-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mapping always refers to variables",
    "text": "Mapping always refers to variables\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-more-aesthetics",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-more-aesthetics",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mapping more aesthetics",
    "text": "Mapping more aesthetics\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, \n                    y = percbelowpoverty,\n                    color = state, \n                    fill= state)) + \n  geom_point() + \n  geom_smooth() +\n  scale_x_log10()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-more-aesthetics-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mapping-more-aesthetics-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mapping more aesthetics",
    "text": "Mapping more aesthetics\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mappings-can-be-done-on-a-per-geom-basis",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mappings-can-be-done-on-a-per-geom-basis",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mappings can be done on a per geom basis",
    "text": "Mappings can be done on a per geom basis\n\nggplot(data = midwest, \n      mapping = aes(x = popdensity, \n                    y = percbelowpoverty)) + \n  geom_point(mapping = aes(color = state)) + \n  geom_smooth(color = \"black\") +\n  scale_x_log10()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#mappings-can-be-done-on-a-per-geom-basis-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#mappings-can-be-done-on-a-per-geom-basis-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Mappings can be done on a per geom basis",
    "text": "Mappings can be done on a per geom basis\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#histograms",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#histograms",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Histograms",
    "text": "Histograms\nHistograms show where there are more or fewer observations of a numeric variable.\n\nggplot(data = midwest,\n       mapping = aes(x = percbelowpoverty)) +\n  geom_histogram()\n\n\nSplit up range of variable into bins, count how many are in each bin.\ny aesthetic calculated automatically."
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#histograms-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#histograms-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Histograms",
    "text": "Histograms\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#creating-small-multiples-with-facets",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#creating-small-multiples-with-facets",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Creating small multiples with facets",
    "text": "Creating small multiples with facets\nSmall multiples: a series of similar graphs with the same scale/axes to help with comparing different partitions of a dataset.\n\nggplot(data = midwest,\n       mapping = aes(x = percbelowpoverty)) +\n  geom_histogram() +\n  facet_wrap(~ state)\n\n\nWe’ll see more of the ~ variable syntax (called a formula)."
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#creating-small-multiples-with-facets-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#creating-small-multiples-with-facets-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Creating small multiples with facets",
    "text": "Creating small multiples with facets\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#density-as-alternative-to-histograms",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#density-as-alternative-to-histograms",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Density as alternative to histograms",
    "text": "Density as alternative to histograms\nA kernel density plot is a smoothed version of a histogram and slightly easier to overlay.\n\nggplot(data = midwest,\n       mapping = aes(x = percbelowpoverty,\n                     fill = state, color = state)) +\n  geom_density(alpha = .3)"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#density-as-alternative-to-histograms-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#density-as-alternative-to-histograms-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Density as alternative to histograms",
    "text": "Density as alternative to histograms"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#boxplots",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#boxplots",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Boxplots",
    "text": "Boxplots\nBoxplots are another way to compare distributions across discrete groups.\n\nggplot(data = midwest,\n       mapping = aes(x = state,\n                     y = percbelowpoverty)) +\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#boxplots-output",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#boxplots-output",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Boxplots",
    "text": "Boxplots"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#boxplots-in-r",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#boxplots-in-r",
    "title": "Contact Theory and Data Visualization in R",
    "section": "Boxplots in R",
    "text": "Boxplots in R\n\n\n“Box” represents middle 50% of the data.\n\n25% of the data is below the bottom of the box, 25% is above\nHeight of the box is the interquartile range (IQR)\n\nHorizontal line in the box is the median\n\n50% of the data is below the median, 50% is above\n\n“Whiskers” represent either:\n\n1.5 \\(\\times\\) IQR or max/min of the data, whichever is smaller\nPoints beyond the whiskers are considered outliers"
  },
  {
    "objectID": "lectures/03-contact_dataviz/contact_dataviz.html#references",
    "href": "lectures/03-contact_dataviz/contact_dataviz.html#references",
    "title": "Contact Theory and Data Visualization in R",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nPaluck, Elizabeth Levy, Roni Porat, Chelsey S. Clark, and Donald P. Green. 2021. “Prejudice Reduction: Progress and Challenges.” Annual Review of Psychology 72 (1): 533–60. https://doi.org/10.1146/annurev-psych-071620-030619."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#potential-outcomes",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#potential-outcomes",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Potential Outcomes",
    "text": "Potential Outcomes\n\n\n\n## Potential Outcomes\npo &lt;- tibble(\n  X = rnorm(n = 50, mean = 2, sd = 2),\n  Y0 = rnorm(50, 10, 5) +\n    5 * X,\n  Y1 = Y0 + 3\n)\n\nhead(po)\n\n# A tibble: 6 × 3\n      X    Y0    Y1\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1.18   18.8  21.8\n2 2.90   23.8  26.8\n3 0.928  12.4  15.4\n4 5.41   37.4  40.4\n5 2.32   23.7  26.7\n6 2.02   11.4  14.4\n\n\n\n\n\nCode\npivot_longer(po, cols = c(Y0, Y1), names_to = \"Y\") |&gt;\n  ggplot(aes(x = value, color = Y, fill = Y)) +\n  geom_density(alpha = .3) +\n#  theme_minimal() +\n  labs(title = \"Potential Outcomes\",\n       x = \"Outcome\",\n       y = \"Density\") +\n  theme(legend.position = \"bottom\") +\n  scale_fill_ipsum() +\n  scale_color_ipsum()"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#a-single-draw",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#a-single-draw",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "A Single Draw",
    "text": "A Single Draw\n\npo$D &lt;- sample(c(0, 1), 50, replace = TRUE)\npo$Y &lt;- po$D * po$Y1 + (1 - po$D) * po$Y0\n\nest_ate &lt;- mean(po$Y[po$D == 1]) -\n  mean(po$Y[po$D == 0])\n\nest_ate\n\n[1] 4.499472\n\n\n\n\nCode\ndraws &lt;- ggplot() +\n  xlim(-1,7) +\n  ylim(0,1) +\n  geom_point(aes(x = 3, y = .5), size = 5,  color = \"orange\") +\n  geom_point(aes(x = est_ate, y = .5), size = 5, color = \"darkgray\") +\n# remove y-axis \n  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) \n  \n\ndraws"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#another-draw",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#another-draw",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Another Draw",
    "text": "Another Draw\n\nestim_ate &lt;- function(data){\n  data$D &lt;- sample(c(0, 1), 50, replace = TRUE)\n  data$Y &lt;- data$D * data$Y1 + (1 - data$D) * data$Y0\n  mean(data$Y[data$D == 1]) -\n    mean(data$Y[data$D == 0])\n}\n\nanother_draw &lt;- estim_ate(po)\nanother_draw\n\n[1] 0.1618433\n\n\n\n\nCode\ndraws &lt;- draws +\n  geom_point(aes(x = another_draw, y = .5), size = 5, color = \"darkgray\")\n\ndraws"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#many-draws",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#many-draws",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Many Draws",
    "text": "Many Draws\n\nestimates &lt;- replicate(1000, estim_ate(po))\n\n\n\n\nCode\nests_df &lt;- tibble(draw = 1:1000, \n                  ests = estimates)\nests_df |&gt;\nggplot() +\n  xlim(min(ests_df$ests), max(ests_df$ests)) +\n  ylim(0,1) +\n  geom_point(aes(x = ests, y = .5, group = draw), size = 5, color = \"darkgray\") +\n  geom_point(aes(x = 3, y = .5), size = 10,  color = \"orange\") +\n# remove y-axis \n  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) +\n  transition_reveal(draw)\n\n\n\n\n\n\n\n\n\n\n\n\nmean(estimates)\n\n[1] 2.854207"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#expectations",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#expectations",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Expectations",
    "text": "Expectations\nThe expectation of a discrete random variable \\(Y\\) is given by: \\[E[Y] = \\sum y \\Pr[Y=y]\\]\n\nThe conditional expectation of \\(Y\\) given \\(X\\) is given by: \\[E[Y|X] = \\sum y \\Pr[Y=y|X=x] \\]"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#estimand",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#estimand",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Estimand",
    "text": "Estimand\nThe average treatment effect (ATE) is given by: \\[\n\\begin{align*}\n\\tau &= E[Y(1) - Y(0)] = E[Y(1)] - E[Y(0)]  \\\\\n&= \\frac{1}{N} \\sum_{i=1}^N (Y_i(1) - Y_i(0)) \\equiv \\textrm{ATE}\n\\end{align*}\n\\]\nThis is the number we want to estimate."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#random-assignment-and-unbiased-inference",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#random-assignment-and-unbiased-inference",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Random Assignment and Unbiased Inference",
    "text": "Random Assignment and Unbiased Inference\nBecause random assignment ensures that potential outcomes are independent of treatment assignment, we have that:\n\\[E[Y(1)|D=1] = E[Y(1)|D=0] = E[Y(1)]\\]\n\\[E[Y(0)|D=1] = E[Y(0)|D=0] = E[Y(0)]\\]\n\nAs a result: \\[\\textrm{ATE} = E[Y(1)] - E[Y(0)] = E[Y(1)|D=1] - E[Y(0)|D=0]\\]"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#estimation",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#estimation",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Estimation",
    "text": "Estimation\nWe need to estimate \\(E[Y(1)|D=1]\\) and \\(E[Y(0)|D=0]\\).\nUnder simple random assignment, we can estimate these quantities using the sample means of the treated and control groups:\n\n\\[\n\\begin{align}\nE\\left[\\frac{\\sum_{i=1}^{m} Y_i}{m} - \\frac{\\sum_{i=m+1}^{N} Y_i}{N - m}\\right] &= E\\left[\\frac{\\sum_{i=1}^{m} Y_i}{m}\\right] - E\\left[\\frac{\\sum_{i=m+1}^{N} Y_i}{N - m}\\right] \\\\\n&= E[Y_i(1) | D_i = 1] - E[Y_i(0) | D_i = 0] \\\\\n&= E[Y_i(1)] - E[Y_i(0)] \\\\\n&= E[\\tau_i] = \\text{ATE}.\n\\end{align}\n\\]"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#unbiased-estimation",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#unbiased-estimation",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Unbiased Estimation",
    "text": "Unbiased Estimation\n\n\nOur estimator is the difference-in-means.\nOur estimator is unbiased if over repeated randomization, the expected value of the estimator is equal to the true value of the estimand.\n\n\n\nCode\nests_df |&gt;\n  ggplot() +\n  geom_histogram(aes(x = ests), bins = 30, fill = \"lightblue\", color = \"black\") +\n  geom_vline(aes(xintercept = 3), color = \"orange\", linewidth = 2) +\n  labs(title = \"Distribution of Estimates\",\n       x = \"Estimate\",\n       y = \"Frequency\")"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#covariate-balance",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#covariate-balance",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Covariate Balance",
    "text": "Covariate Balance\n\n\nWe can use pre-treatment covariates \\(X\\) to identify bad draws.\nIf \\(X\\) is predictive of outcomes and we find that \\(X\\) is not balanced across treatment and control groups, then our estimate might be far from our estimand.\n\n\n\nCode\nestim_ate_bal &lt;- function(data){\n  data$D &lt;- sample(c(0, 1), 50, replace = TRUE)\n  data$Y &lt;- data$D * data$Y1 + (1 - data$D) * data$Y0\n  tibble(est_y = mean(data$Y[data$D == 1]) - mean(data$Y[data$D == 0]),\n         est_x = mean(data$X[data$D == 1]) - mean(data$X[data$D == 0]))\n}\n\nests &lt;- map(1:1000, ~estim_ate_bal(po)) |&gt;\n  bind_rows()\n\nests |&gt;\n  ggplot() +\n  geom_point(aes(x = est_x, y = est_y), color = \"lightblue\") +\n  geom_smooth(aes(x = est_x, y = est_y), method = \"lm\", color = \"red\",\n              se = FALSE) +\n  geom_hline(yintercept = 3, color = \"orange\", linetype = \"dashed\", size = 3) +\n  labs(title = \"ATE Estimates and Covariate Balance\",\n       x = \"Covariate Balance\",\n       y = \"Estimate\",\n       caption = \"Orange line is the true ATE\")"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#messy-data",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#messy-data",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Messy Data",
    "text": "Messy Data\n\nData almost never comes in the form we need\nThe potential problems are endless:\n\nMissing values\nNeed to transform the variable in some way\nNeed to summarize within groups\nNeed to rename the variables\nNeed to reorder the data\n\nToday we will learn how to use the dplyr package to solve these problems"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#the-dplyr-package",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#the-dplyr-package",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "The dplyr Package",
    "text": "The dplyr Package\n\n\n\n\n\ndplyr is a set of functions for data manipulation. These functions:\n\nTake a dataset as their input\nManipulate the dataset in some way\nReturn a new dataset as their output"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#the-pipe",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#the-pipe",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "The Pipe",
    "text": "The Pipe\nNested calls can be hard to read:\nmean(sd(log(x)))\nThe pipe operator (|&gt;) allows us to write this as:\nx |&gt; \n  log() |&gt; \n  sd() |&gt; \n  mean()"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#operating-on-rows",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#operating-on-rows",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Operating on Rows",
    "text": "Operating on Rows\nfilter(): subset rows based on a condition"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#filter",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#filter",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "filter",
    "text": "filter\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#logicals",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#logicals",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Logicals",
    "text": "Logicals\n\nComparing two values/vectors:\n\n&gt; or &gt;=: greater than or equal to\n&lt; or &lt;=: less than or equal to\n== or !=: equal to or not equal to\n\nCombining multiple logical conditions:\n\n&: and\n|: or\n!: not"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#multiple-conditions",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#multiple-conditions",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Multiple Conditions",
    "text": "Multiple Conditions\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#combining-in",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#combining-in",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Combining %in%",
    "text": "Combining %in%\nWhen combining | and ==, useful to use %in%:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#arrange",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#arrange",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Arrange",
    "text": "Arrange\narrange(): reorder rows based on a variable.\nWith multiple variables, arrange() will sort by the first variable, then the second, and so on.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#rich-and-poor-countries",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#rich-and-poor-countries",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Rich and Poor Countries",
    "text": "Rich and Poor Countries\nWhich country years have the highest and lowest GDP per capita?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nUse desc() to sort in descending order:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#operating-on-columns",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#operating-on-columns",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "Operating on columns",
    "text": "Operating on columns\nselect(): subset columns based on their names\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#rename",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#rename",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "rename",
    "text": "rename\nrename(): rename columns\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#mutate",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#mutate",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "mutate",
    "text": "mutate"
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#mutate-1",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#mutate-1",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "mutate",
    "text": "mutate\nmutate(): add new variables or modify existing ones\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#ifelse",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#ifelse",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "ifelse",
    "text": "ifelse\nifelse(test, yes, no): a vectorized if-else statement\nNew vector is yes where test is TRUE, and no where test is FALSE\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#group_by",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#group_by",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "group_by",
    "text": "group_by\ngroup_by(): group the data by one or more variables\nDoesn’t change the data, but tells dplyr that you want to operate on the data in groups\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#summarize",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#summarize",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "summarize",
    "text": "summarize\nsummarize(): collapse each group into a single row\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/04-estimation_dplyr/estimation_dplyr.html#mutate-and-group_by",
    "href": "lectures/04-estimation_dplyr/estimation_dplyr.html#mutate-and-group_by",
    "title": "Estimation of Causal Effectsand Data Manipulation in R",
    "section": "mutate and group_by",
    "text": "mutate and group_by\nmutate() and group_by() can be used together to create new variables that are calculated within groups\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#randomization-and-covariates",
    "href": "lectures/10-covar_design/covar_design.html#randomization-and-covariates",
    "title": "Using Covariates in Experimental Design",
    "section": "Randomization and Covariates",
    "text": "Randomization and Covariates\n\n\n\n\n\nAs discussed, while randomization gives us the right answer on average, we can still get unlucky.\nWe detect bad luck typically by examining balance on pre-treatment covariates.\nFor covariates that are predictive of the outcome, imbalance suggests we may be far off from the ATE.\nRather than just hope for good luck, why not design for good luck?"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#gabiras-diáz-and-montenegro",
    "href": "lectures/10-covar_design/covar_design.html#gabiras-diáz-and-montenegro",
    "title": "Using Covariates in Experimental Design",
    "section": "Gabiras-Diáz and Montenegro",
    "text": "Gabiras-Diáz and Montenegro\n\nTo increase the balance on potential confounders across treatment conditions, we conducted a stratified randomization. We defined strata by the intersection of bins partitioning the sample in three ways: (i) by the fiftieth and eighty-fifth percentiles of the population over the age of 18, (ii) by the twentieth and eightieth percentiles of voter turnout in the first round of presidential elections in 2018, and (iii) by whether the municipalities filed reports through the MOE’s website around the congressional elections of 2018 above or below the median\n\nStratify by:\n\nPopulation size\nVoter turnout\nReports in 2018"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#population-and-reports",
    "href": "lectures/10-covar_design/covar_design.html#population-and-reports",
    "title": "Using Covariates in Experimental Design",
    "section": "Population and Reports",
    "text": "Population and Reports\n\n\nggplot(col_data, aes(x = pop, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Population and Reports\",\n       x = \"Population\",\n       y = \"Reports\")"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#voter-turnout-and-reports",
    "href": "lectures/10-covar_design/covar_design.html#voter-turnout-and-reports",
    "title": "Using Covariates in Experimental Design",
    "section": "Voter Turnout and Reports",
    "text": "Voter Turnout and Reports\n\n\nggplot(col_data, aes(x = turnout_pre, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Voter Turnout and Reports\",\n       x = \"Voter Turnout\",\n       y = \"Reports\")"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#baseline-and-endline-reports",
    "href": "lectures/10-covar_design/covar_design.html#baseline-and-endline-reports",
    "title": "Using Covariates in Experimental Design",
    "section": "Baseline and Endline Reports",
    "text": "Baseline and Endline Reports\n\n\nggplot(col_data, aes(x = reports_pre, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(method = \"lm\", \n              se = FALSE) +\n  labs(title = \"Baseline Reports and Reports\",\n       x = \"Baseline Reports\",\n       y = \"Reports\")"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#permute-treatment-and-estimate",
    "href": "lectures/10-covar_design/covar_design.html#permute-treatment-and-estimate",
    "title": "Using Covariates in Experimental Design",
    "section": "Permute Treatment and Estimate",
    "text": "Permute Treatment and Estimate\n\nra_permute &lt;- function(data) {\n  N &lt;- nrow(data)\n  m &lt;- sum(data$treatment)\n1  data$treatment &lt;- complete_ra(N = N, m = m)\n2  outcome_est &lt;- difference_in_means(reports ~ treatment, data = data)\n3  covar_est &lt;- difference_in_means(log_pop ~ treatment, data = data)\n4  tidied_outcome &lt;- tidy(outcome_est)\n  tidied_covar &lt;- tidy(covar_est)\n  \n5  bind_rows(tidied_outcome, tidied_covar)\n} \n\n\n1\n\nPermute treatment variable\n\n2\n\nEstimate treatment effect\n\n3\n\nEstimate covariate imbalance\n\n4\n\nTidy the output. The tidy function is used to convert the output of the difference_in_means function into a data frame.\n\n5\n\nCombine the output into a single data frame."
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#permute-treatment-and-estimate-1",
    "href": "lectures/10-covar_design/covar_design.html#permute-treatment-and-estimate-1",
    "title": "Using Covariates in Experimental Design",
    "section": "Permute Treatment and Estimate",
    "text": "Permute Treatment and Estimate\n\nra_permute(col_data)\n\n       term    estimate  std.error  statistic   p.value    conf.low conf.high\n1 treatment -0.13377907 0.12971859 -1.0313022 0.3032509 -0.38907891 0.1215208\n2 treatment  0.02582991 0.06310037  0.4093465 0.6826049 -0.09839274 0.1500526\n        df outcome\n1 292.5771 reports\n2 274.2485 log_pop\n\n\n\n\npermute_data &lt;- map(1:1000, ~ ra_permute(col_data)) |&gt;\n  bind_rows()\n## Add iteration number using rep function\npermute_data$iteration &lt;- rep(1:1000, each = 2)\n\nhead(permute_data)\n\n       term     estimate  std.error   statistic    p.value    conf.low\n1 treatment  0.175715569 0.14205152  1.23698481 0.21724053 -0.10403954\n2 treatment  0.048580089 0.06752630  0.71942474 0.47255788 -0.08441926\n3 treatment  0.053546633 0.14706103  0.36411163 0.71609348 -0.23614056\n4 treatment  0.001002501 0.06442137  0.01556162 0.98759582 -0.12583943\n5 treatment  0.297884505 0.17475687  1.70456535 0.08983542 -0.04672740\n6 treatment -0.034385952 0.06598719 -0.52110045 0.60274743 -0.16433302\n   conf.high       df outcome iteration\n1 0.45547068 252.8099 reports         1\n2 0.18157943 247.5474 log_pop         1\n3 0.34323382 241.3133 reports         2\n4 0.12784443 265.4207 log_pop         2\n5 0.64249641 199.0992 reports         3\n6 0.09556112 255.9038 log_pop         3"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#imbalance-vs-treatment-effect",
    "href": "lectures/10-covar_design/covar_design.html#imbalance-vs-treatment-effect",
    "title": "Using Covariates in Experimental Design",
    "section": "Imbalance vs Treatment Effect",
    "text": "Imbalance vs Treatment Effect\nTo visualize we need to use pivot_wider to reshape the data.\npivot_wider() takes data from a single column and moves it into multiple columns based on a grouping variable (in this case, iteration).\n\n##Use pivot_wider to reshape the data\npivoted &lt;- permute_data |&gt;\n  pivot_wider(id_cols = iteration, \n              names_from = outcome, values_from = estimate)\nhead(pivoted)\n\n# A tibble: 6 × 3\n  iteration reports  log_pop\n      &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1         1  0.176   0.0486 \n2         2  0.0535  0.00100\n3         3  0.298  -0.0344 \n4         4  0.127   0.0355 \n5         5 -0.150   0.0477 \n6         6 -0.0198 -0.0202"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#imbalance-vs-treatment-effect-1",
    "href": "lectures/10-covar_design/covar_design.html#imbalance-vs-treatment-effect-1",
    "title": "Using Covariates in Experimental Design",
    "section": "Imbalance vs Treatment Effect",
    "text": "Imbalance vs Treatment Effect\n\n\nggplot(pivoted, \n       aes(x = log_pop, y = reports)) +\n  geom_point(size = .5) +\n  geom_smooth(se = FALSE) +\n  xlab(\"Imbalance in Log Population\") +\n  ylab(\"Estimated Treatment Effect\") +\n  geom_hline(yintercept = 0, \n             linetype = \"dashed\") +\n  ggtitle(\"Imbalance vs Treatment Effect\")"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#estimatr-package",
    "href": "lectures/10-covar_design/covar_design.html#estimatr-package",
    "title": "Using Covariates in Experimental Design",
    "section": "estimatr Package",
    "text": "estimatr Package\nUp until now, we have been calculating the difference in means between the treatment and control groups, but more complex designs require more complex estimators.\nThe estimatr package provides a number of functions to estimate treatment effects in experimental studies.\n\nlibrary(estimatr)\n1estimate &lt;- difference_in_means(\n2                          formula = reports ~ treatment,\n                           data = col_data)\n\n\n1\n\nThe difference_in_means function is used to estimate the average treatment effect in a variety of experimental designs.\n\n2\n\nUse formula syntax to specify the outcome variable and the treatment variable: outcome ~ treatment."
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#difference-in-means-output",
    "href": "lectures/10-covar_design/covar_design.html#difference-in-means-output",
    "title": "Using Covariates in Experimental Design",
    "section": "difference-in-means output",
    "text": "difference-in-means output\n\nestimate\n\nDesign:  Standard \n           Estimate Std. Error  t value   Pr(&gt;|t|)    CI Lower  CI Upper\ntreatment 0.2653061  0.1540007 1.722759 0.08629406 -0.03814765 0.5687599\n               DF\ntreatment 226.997\n\n\nOutput from the difference_in_means function:\n\nEstimate is the estimate of the ATE\nStd. Error is the standard error of the estimate (standard deviation of the sampling distribution)\nPr(&gt;|t|) is the p-value for the hypothesis test that the ATE is equal to zero\nCI Lower and CI Upper are the lower and upper bounds of the 95% confidence interval for the ATE"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#randomizr-package",
    "href": "lectures/10-covar_design/covar_design.html#randomizr-package",
    "title": "Using Covariates in Experimental Design",
    "section": "randomizr Package",
    "text": "randomizr Package\nWe have been using sample to randomly assign treatment, but the randomizr package provides more complex randomization procedures.\n\nlibrary(randomizr)\n\nn_treatment &lt;- 159\nn_muni &lt;- 698\n\n1assignment &lt;- complete_ra(N = n_muni,\n                          m = n_treatment)\n\n\n1\n\nThe complete_ra function is used to randomly assign treatment to a specified number of units (n_treatment). Produces a vector of 1s and 0s, where 1 indicates treatment and 0 indicates control.\n\n\n\n\n\n\ntable(assignment)\n\nassignment\n  0   1 \n539 159"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#blocking-1",
    "href": "lectures/10-covar_design/covar_design.html#blocking-1",
    "title": "Using Covariates in Experimental Design",
    "section": "Blocking",
    "text": "Blocking\n\n\n\n\n\nRather than hoping for a balanced sample, we can ensure balance by blocking on important covariates.\nBasic idea:\n\nGather covariates predictive of the outcome\nGroup units into strata based on these covariates\nRandomly assign treatment within each stratum\n\nIf we block, we must change how we estimate the treatment effect."
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#blocking-in-r",
    "href": "lectures/10-covar_design/covar_design.html#blocking-in-r",
    "title": "Using Covariates in Experimental Design",
    "section": "Blocking in R",
    "text": "Blocking in R\n\n## Create equal sized strata based on log population\n1col_data$block &lt;- cut_number(col_data$log_pop, 10)\n\n2treat_prob &lt;- n_treatment / n_muni\n\n3block_assignment &lt;- block_ra(blocks = col_data$block,\n                             prob = treat_prob) \n\n\n1\n\nUse the cut_number function to create 10 equally sized strata based on the log_pop variable.\n\n2\n\nCalculate the probability of treatment within each stratum.\n\n3\n\nUse the block_ra function to randomly assign treatment within each stratum.\n\n\n\n\n\n\ntable(block_assignment, col_data$block)\n\n                \nblock_assignment [8.13,8.64] (8.64,8.87] (8.87,9.05] (9.05,9.26] (9.26,9.41]\n               0          54          54          54          53          54\n               1          16          16          16          16          16\n                \nblock_assignment (9.41,9.63] (9.63,9.82] (9.82,10.1] (10.1,10.6] (10.6,11.6]\n               0          55          52          54          54          55\n               1          16          16          16          16          15"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#blocking-and-analysis",
    "href": "lectures/10-covar_design/covar_design.html#blocking-and-analysis",
    "title": "Using Covariates in Experimental Design",
    "section": "Blocking and Analysis",
    "text": "Blocking and Analysis\nKey principle in analysis of experimental design:\n\n\n\n\n\n\nImportant\n\n\nAnalyze as ye randomize\n\n\n\n\nWhen estimating treatment effects and uncertainty (e.g. p-values, confidence intervals), we must account for the randomization procedure used to assign treatment.\n\n\nEach block can be considered a separate experiment, so for block \\(j\\) with \\(N_J\\) units, we can estimate the treatment effects in each block separately, and then average the estimates across blocks:\n\\[\\widehat{\\textrm{ATE}} = \\sum_{j=1}^J \\frac{N_j}{N} \\widehat{\\textrm{ATE}_j}\\]"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#estimating-treatment-effects-with-blocking",
    "href": "lectures/10-covar_design/covar_design.html#estimating-treatment-effects-with-blocking",
    "title": "Using Covariates in Experimental Design",
    "section": "Estimating Treatment Effects with Blocking",
    "text": "Estimating Treatment Effects with Blocking\n\nblock_estimate &lt;- difference_in_means(\n  formula = reports ~ treatment,\n1  blocks = block,\n  data = col_data)\n\n\n1\n\nUse the blocks argument to specify the blocking variable.\n\n\n\n\n\n\nestimate\n\nDesign:  Standard \n           Estimate Std. Error  t value   Pr(&gt;|t|)    CI Lower  CI Upper\ntreatment 0.2653061  0.1540007 1.722759 0.08629406 -0.03814765 0.5687599\n               DF\ntreatment 226.997\n\nblock_estimate\n\nDesign:  Blocked \n           Estimate Std. Error  t value   Pr(&gt;|t|)    CI Lower  CI Upper  DF\ntreatment 0.3057494  0.1662785 1.838779 0.06638493 -0.02073333 0.6322321 678"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#permutation-testing-with-blocking",
    "href": "lectures/10-covar_design/covar_design.html#permutation-testing-with-blocking",
    "title": "Using Covariates in Experimental Design",
    "section": "Permutation Testing with Blocking",
    "text": "Permutation Testing with Blocking\n\n1block_permute &lt;- function(data) {\n  N &lt;- nrow(data)\n  m &lt;- sum(data$treatment)\n2  data$treatment &lt;- block_ra(blocks = data$block,\n                             prob = m/N) \n  \n  outcome_est &lt;- difference_in_means(reports ~ treatment,\n3                                     block = block,\n                                     data = data) \n  tidied_outcome &lt;- tidy(outcome_est) \n  tidied_outcome\n}\n\n4permuted_block &lt;- map(1:1000, ~ block_permute(col_data)) |&gt;\n  bind_rows()\n\n\n1\n\nDefine a function block_permute that takes a dataset.\n\n2\n\nUse the block_ra function to randomly assign treatment within each block.\n\n3\n\nEstimate treatment effect accounting for blocking.\n\n4\n\nUse the map to generate the sampling distribution of the treatment effect (under the sharp null)"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#sampling-distribution",
    "href": "lectures/10-covar_design/covar_design.html#sampling-distribution",
    "title": "Using Covariates in Experimental Design",
    "section": "Sampling Distribution",
    "text": "Sampling Distribution\n\n\nperms &lt;- bind_rows(tibble(Randomization = \"Blocked\", \n       Estimate = permuted_block$estimate), \n  tibble(Randomization = \"Simple\", \n         Estimate = pivoted$reports)) \n\nggplot(perms, aes(x = Estimate, \n                  color = Randomization)) +\n  geom_density(size = 3) +\n  labs(title = \"Sampling Distribution of ATE\",\n       subtitle = \"Blocked vs Simple Randomization\",\n       x = \"Estimate\",\n       y = \"Density\") +\n  geom_vline(xintercept = tidy(block_estimate)$estimate, \n             linetype = \"dashed\", \n             linewidth = 2,\n             color = \"red\")"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#inference",
    "href": "lectures/10-covar_design/covar_design.html#inference",
    "title": "Using Covariates in Experimental Design",
    "section": "Inference",
    "text": "Inference\n\n## Calculate p-value\n## Blocked\n mean(permuted_block$estimate &gt; tidy(block_estimate)$estimate)\n\n[1] 0.011\n\n## Simple\n mean(pivoted$reports &gt; tidy(estimate)$estimate)\n\n[1] 0.036\n\n\nBlocking:\n\nEnsures balance on important covariates\nMade our inferences more precise\nChanged how we estimate treatment effects and calculate p-values"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#cluster-randomization",
    "href": "lectures/10-covar_design/covar_design.html#cluster-randomization",
    "title": "Using Covariates in Experimental Design",
    "section": "Cluster Randomization",
    "text": "Cluster Randomization\n\nSometimes the unit of randomization is not the same as the unit of analysis\nIn Gabiras-Diáz and Montenegro, the unit of randomization is the municipality, but they also examine candidate-level outcomes.\nFollowing the principle of analyze as ye randomize, we need to account for the clustering of the treatment assignment when estimating treatment effects and uncertainty."
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#cambridge",
    "href": "lectures/10-covar_design/covar_design.html#cambridge",
    "title": "Using Covariates in Experimental Design",
    "section": "Cambridge",
    "text": "Cambridge\n\nImagine you are sampling 100 Cambridge voters and asking them about their turnout in the most recent local election. You have two options:\n\nYou can randomly sample 100 voters using simple random sampling.\nYou can first randomly sample 2 precincts and then interview 50 voters in each sampled precinct."
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#voter-file",
    "href": "lectures/10-covar_design/covar_design.html#voter-file",
    "title": "Using Covariates in Experimental Design",
    "section": "Voter File",
    "text": "Voter File\n\ncambr_voter &lt;- read_csv(\"cambridge_voter_history16_18.zip\", \n                        show_col_types = FALSE)\nfilter(cambr_voter, last_name == \"HIDALGO\" & middle_name == \"DANIEL\") |&gt;\n  glimpse()\n\nRows: 1\nColumns: 16\n$ voter_id_number                   &lt;chr&gt; \"01HFO1280000\"\n$ last_name                         &lt;chr&gt; \"HIDALGO\"\n$ first_name                        &lt;chr&gt; \"FERNANDO\"\n$ middle_name                       &lt;chr&gt; \"DANIEL\"\n$ residential_address_street_number &lt;dbl&gt; 23\n$ residential_address_street_name   &lt;chr&gt; \"MURDOCK ST\"\n$ residential_address_zip_code      &lt;chr&gt; \"021391214\"\n$ party_affiliation                 &lt;chr&gt; \"D\"\n$ date_of_birth                     &lt;date&gt; 1980-01-12\n$ ward_number                       &lt;chr&gt; \"03\"\n$ precinct_number                   &lt;chr&gt; \"02\"\n$ turnout_110618                    &lt;dbl&gt; 1\n$ turnout_090418                    &lt;dbl&gt; 1\n$ turnout_110717                    &lt;dbl&gt; 1\n$ turnout_110816                    &lt;dbl&gt; 1\n$ turnout_090816                    &lt;dbl&gt; 0"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#turnout-heterogeneity",
    "href": "lectures/10-covar_design/covar_design.html#turnout-heterogeneity",
    "title": "Using Covariates in Experimental Design",
    "section": "Turnout Heterogeneity",
    "text": "Turnout Heterogeneity\n\ncambr_voter$prec_code &lt;- paste(cambr_voter$ward_number, \n                               cambr_voter$precinct_number)\n\ncambr_voter |&gt;\n  group_by(prec_code) |&gt;\n  summarize(turnout = mean(turnout_110717, na.rm = TRUE)) |&gt;\n## Order precinct by turnout\n  mutate(prec_code = fct_reorder(prec_code, turnout)) |&gt;\n  ggplot(aes(x = prec_code, y = turnout)) +\n  geom_col() +\n  labs(title = \"Turnout by Precinct\",\n       x = \"Precinct\",\n       y = \"Turnout Rate\") +\n# Rotate x-axis labels\ntheme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#turnout-heterogeneity-output",
    "href": "lectures/10-covar_design/covar_design.html#turnout-heterogeneity-output",
    "title": "Using Covariates in Experimental Design",
    "section": "Turnout Heterogeneity",
    "text": "Turnout Heterogeneity"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#two-sampling-distributions",
    "href": "lectures/10-covar_design/covar_design.html#two-sampling-distributions",
    "title": "Using Covariates in Experimental Design",
    "section": "Two Sampling Distributions",
    "text": "Two Sampling Distributions"
  },
  {
    "objectID": "lectures/10-covar_design/covar_design.html#accounting-for-clustered-sampling",
    "href": "lectures/10-covar_design/covar_design.html#accounting-for-clustered-sampling",
    "title": "Using Covariates in Experimental Design",
    "section": "Accounting for Clustered Sampling",
    "text": "Accounting for Clustered Sampling\nFor estimation and inference, we need to account for the clustering of the treatment assignment. Otherwise, inferences can be very misleading!\n\nEasiest and most direct way is to:\n\nCollapse the data to the cluster level by taking cluster-level averages\nEstimate treatment effect and conduct inference using the cluster-level data using our usual methods.\n\n\n\nLess direct way:\n\nWhen using permutation inference or the bootstrap, resample at the cluster level.\nThis will account for the clustering of the treatment assignment."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#where-are-we",
    "href": "lectures/08-ci/inference_ci.html#where-are-we",
    "title": "More on Inference in Experiments",
    "section": "Where are we?",
    "text": "Where are we?\n\nIn experiments, the population is the full set of potential or counterfactual outcomes.\nThe sample are the outcomes we actually observe after treatment assignment.\nRandom assignment introduces variation in the sample, but the population is fixed.\nThe variation is called sampling variation and creates a sampling distribution."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#inference",
    "href": "lectures/08-ci/inference_ci.html#inference",
    "title": "More on Inference in Experiments",
    "section": "Inference",
    "text": "Inference\n\n\n\n\n\n\n\nHypothesis Testing\n\n\nUnder our maintained assumptions, how likely is it that we would observe the data we have if the (sharp) null hypothesis were true?\n\n\n\n\n\nHypothesis testing is a useful beginning point for inference, but sometimes we want to characterize other aspects of the sampling distribution.\nWe will use a tool called the bootstrap to do this."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#the-bootstrap-1",
    "href": "lectures/08-ci/inference_ci.html#the-bootstrap-1",
    "title": "More on Inference in Experiments",
    "section": "The Bootstrap",
    "text": "The Bootstrap\n\nSourceSample from the sample with replacement many times to estimate the sampling distribution."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#survey",
    "href": "lectures/08-ci/inference_ci.html#survey",
    "title": "More on Inference in Experiments",
    "section": "Survey",
    "text": "Survey\n1991 Survey:\n\nNow I’m going to read you three things that sometimes make people angry or upset. After I read all three, just tell me HOW MANY of them upset you. (I don’t want to know which ones, just how many.)\n\n\n\nthe federal government increasing the tax on gasoline\nprofessional athletes getting million-dollar-plus salaries\nlarge corporations polluting the environment\n\n\n\n\na black family moving next door to you\n\n\nHow many, if any, of these things upset you?"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#data",
    "href": "lectures/08-ci/inference_ci.html#data",
    "title": "More on Inference in Experiments",
    "section": "Data",
    "text": "Data\n\nrace &lt;- read_csv(\"race_list.csv\")\n\nrace |&gt; \n  slice_sample(prop = 1, replace = TRUE)\n\n# A tibble: 1,213 × 7\n       y treat   age south  male college state\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;\n 1     3     1   3       0     0       0 NJ   \n 2     2     0   4.2     1     0       1 TX   \n 3     2     1   4.6     0     0       1 CA   \n 4     4     1   4.7     0     1       0 NE   \n 5     1     0   6       0     1       1 PA   \n 6     0     0   6.4     1     1       0 FL   \n 7     2     1   3.2     0     0       1 CO   \n 8     3     0   3.7     0     1       1 KY   \n 9     3     0   2.6     0     0       1 CA   \n10     3     1   3       0     0       0 OH   \n# ℹ 1,203 more rows"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#many-boostrap-samples",
    "href": "lectures/08-ci/inference_ci.html#many-boostrap-samples",
    "title": "More on Inference in Experiments",
    "section": "Many Boostrap Samples",
    "text": "Many Boostrap Samples\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#bootstrap-estimates",
    "href": "lectures/08-ci/inference_ci.html#bootstrap-estimates",
    "title": "More on Inference in Experiments",
    "section": "Bootstrap Estimates",
    "text": "Bootstrap Estimates\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#visualizing-the-bootstrap-distribution",
    "href": "lectures/08-ci/inference_ci.html#visualizing-the-bootstrap-distribution",
    "title": "More on Inference in Experiments",
    "section": "Visualizing the Bootstrap Distribution",
    "text": "Visualizing the Bootstrap Distribution\n\n\nbs_ests |&gt; \n  ggplot(aes(x = mean_college)) +\n  geom_histogram(bins = 30, \n                 fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Bootstrap Distribution of Estimates\", \n       x = \"Mean College\", \n       y = \"Frequency\")"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#boostrap-distribution",
    "href": "lectures/08-ci/inference_ci.html#boostrap-distribution",
    "title": "More on Inference in Experiments",
    "section": "Boostrap Distribution",
    "text": "Boostrap Distribution\n\n\nBootstrap distribution approximates the sampling distribution of the estimator.\nBoth should have a similar shape and spread if sampling from the distribution ≈ bootstrap resampling.\nApproximation gets better as sample gets bigger."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#what-is-a-confidence-interval",
    "href": "lectures/08-ci/inference_ci.html#what-is-a-confidence-interval",
    "title": "More on Inference in Experiments",
    "section": "What is a confidence interval?",
    "text": "What is a confidence interval?\n\n\n Point Estimate: best single guess about the population parameter. Unlikely to be exactly correct.\n\n Confidence Intervals: a range of plausible values of the population parameter."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#confidence-intervals-1",
    "href": "lectures/08-ci/inference_ci.html#confidence-intervals-1",
    "title": "More on Inference in Experiments",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\n\nEach sample gives a different CI or toss of the ring\nSome samples will contain the target (the CI will contain the truth), other times it won’t.\n\nUnlike the picture, we don’t know where the target is, so we don’t know if our CI contains the truth!\n\nConfidence level: the percentage of time the CI will contain the truth.\n\nWe get to choose this level, but typical values are 90%, 95%, 99%."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#confidence-intervals-as-occasional-liars",
    "href": "lectures/08-ci/inference_ci.html#confidence-intervals-as-occasional-liars",
    "title": "More on Inference in Experiments",
    "section": "Confidence Intervals as Occasional Liars",
    "text": "Confidence Intervals as Occasional Liars\n\nThe confidence level of a CI tells us how often it will contain the truth.\nA 95% CI will:\n\nContain the truth 95% of the time (contain the true parameter or estimand 95% of the time).\nLie to you 5% of the time (not contain the true parameter or estimand 5% of the time). See link\n\n\n\n\n\n\n\n\n\nCaution\n\n\nCan you tell if your particular CI is telling the truth?"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#percentile-method",
    "href": "lectures/08-ci/inference_ci.html#percentile-method",
    "title": "More on Inference in Experiments",
    "section": "Percentile Method",
    "text": "Percentile Method\n\nThe percentile method is a simple way to construct a CI from the bootstrap distribution.\nThe 95% CI is the interval between the 2.5th and 97.5th percentiles of the bootstrap distribution.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#visualizing-the-confidence-interval",
    "href": "lectures/08-ci/inference_ci.html#visualizing-the-confidence-interval",
    "title": "More on Inference in Experiments",
    "section": "Visualizing the Confidence Interval",
    "text": "Visualizing the Confidence Interval\n\n\nbs_ests |&gt; \n  ggplot(aes(x = mean_college)) +\n  geom_histogram(bins = 30, \n                 fill = \"lightblue\", color = \"black\") +\n  geom_vline(xintercept = perc_ci95, color = \"red\", size = 1) +\n  labs(title = \"Bootstrap Distribution of Estimates\", \n       x = \"Mean College\", \n       y = \"Frequency\")"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#confidence-interval",
    "href": "lectures/08-ci/inference_ci.html#confidence-interval",
    "title": "More on Inference in Experiments",
    "section": "99% Confidence Interval",
    "text": "99% Confidence Interval\nWhat happens if we want the CI to be right more often? Will the width of a 99% confidence interval be wider or narrower?\n\n\nperc_ci99 &lt;- quantile(bs_ests$mean_college, c(0.005, 0.995))\n\nperc_ci99\n\n     0.5%     99.5% \n0.5482193 0.6166529"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#visualizing-the-99-confidence-interval",
    "href": "lectures/08-ci/inference_ci.html#visualizing-the-99-confidence-interval",
    "title": "More on Inference in Experiments",
    "section": "Visualizing the 99% Confidence Interval",
    "text": "Visualizing the 99% Confidence Interval\n\n\nbs_ests |&gt; \n  ggplot(aes(x = mean_college)) +\n  geom_histogram(bins = 30, \n                 fill = \"lightblue\", color = \"black\") +\n    geom_vline(xintercept = perc_ci95, color = \"red\", size = 1) +\n  geom_vline(xintercept = perc_ci99, color = \"blue\", size = 1) +\n  labs(title = \"Bootstrap Distribution of Estimates\", \n       x = \"Mean College\", \n       y = \"Frequency\")"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#list-experiment",
    "href": "lectures/08-ci/inference_ci.html#list-experiment",
    "title": "More on Inference in Experiments",
    "section": "1991 List Experiment",
    "text": "1991 List Experiment\n\nlist_est &lt;- race |&gt;\n  summarise(list_est = mean(y[treat == 1]) - mean(y[treat == 0]),\n            list_est_south = mean(y[treat == 1 & south == 1]) -\n              mean(y[treat == 0 & south == 1]), \n            list_est_old = mean(y[treat == 1 & age &gt; median(age)]) - \n              mean(y[treat == 0 & age &gt; median(age)]))\n\nlist_est\n\n# A tibble: 1 × 3\n  list_est list_est_south list_est_old\n     &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1   0.0678          0.259        0.135"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#list-experiments-bootstrap",
    "href": "lectures/08-ci/inference_ci.html#list-experiments-bootstrap",
    "title": "More on Inference in Experiments",
    "section": "List Experiments Bootstrap",
    "text": "List Experiments Bootstrap\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#list-experiments-bs-sampling-distributions",
    "href": "lectures/08-ci/inference_ci.html#list-experiments-bs-sampling-distributions",
    "title": "More on Inference in Experiments",
    "section": "List Experiments BS Sampling Distributions",
    "text": "List Experiments BS Sampling Distributions\n\n\n##Density Plot\nlist_est_bs |&gt; \n  pivot_longer(cols = starts_with(\"list_est\"),\n               names_to = \"experiment\") |&gt; \n  ggplot(aes(x = value, \n             fill = experiment)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Bootstrap Sampling Distributions\", \n       x = \"Difference in Means\", \n       y = \"Density\") + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#list-experiments-confidence-intervals",
    "href": "lectures/08-ci/inference_ci.html#list-experiments-confidence-intervals",
    "title": "More on Inference in Experiments",
    "section": "List Experiments Confidence Intervals",
    "text": "List Experiments Confidence Intervals\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/08-ci/inference_ci.html#visualize-list-experiments-confidence-intervals",
    "href": "lectures/08-ci/inference_ci.html#visualize-list-experiments-confidence-intervals",
    "title": "More on Inference in Experiments",
    "section": "Visualize List Experiments Confidence Intervals",
    "text": "Visualize List Experiments Confidence Intervals\n\n\nlist_ests_ci |&gt; \n  ggplot(aes(x = sample, y = est)) +\n  geom_point(size = 4) +\n  geom_errorbar(aes(ymin = ci_low, \n                    ymax = ci_high), \n                width = 0.2) +\n  labs(title = \"List Experiments Confidence Intervals\", \n       x = \"Sample\", \n       y = \"Difference in Means\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\")"
  },
  {
    "objectID": "lectures/02-causality/causality.html#section",
    "href": "lectures/02-causality/causality.html#section",
    "title": "Causality and Introduction to R",
    "section": "",
    "text": "The Road not Taken by Robert Frost\nTwo roads diverged in a yellow wood, And sorry I could not travel both And be one traveler, long I stood And looked down one as far as I could To where it bent in the undergrowth;"
  },
  {
    "objectID": "lectures/02-causality/causality.html#what-is-a-causal-effect",
    "href": "lectures/02-causality/causality.html#what-is-a-causal-effect",
    "title": "Causality and Introduction to R",
    "section": "What is a Causal Effect?",
    "text": "What is a Causal Effect?\n\nStudents with diverse friend groups express less discriminatory attitudes and are supportive of policies that promote diversity.\n\nWould these students be supportive of these policies if they did not have diverse friend groups?\n\n\n\n\nHeavy social media users are less happy on average than those who use social media less.\n\nIs this because social media use causes unhappiness, or are unhappy people more likely to use social media?\n\n\n\n\n\n\n\n\n\n\nFundamental Problem of Causal Inference\n\n\nWe never observe counterfactuals, they must be inferred"
  },
  {
    "objectID": "lectures/02-causality/causality.html#the-effect-of-social-media",
    "href": "lectures/02-causality/causality.html#the-effect-of-social-media",
    "title": "Causality and Introduction to R",
    "section": "The Effect of Social Media",
    "text": "The Effect of Social Media\n\n\n\n\n\nMuch concern about the effect of social media on:\n\nMental health\nPolitical polarization\nInteractions with friends and families\n\n\n\n\n\nImagine two respondents:\n\n\n\nRespondent\nSocial Media Use\nHappiness\n\n\n\n\n1\nHigh\nLow\n\n\n2\nLow\nHigh\n\n\n\n\n\nDid social media use cause the difference in happiness?"
  },
  {
    "objectID": "lectures/02-causality/causality.html#some-notation",
    "href": "lectures/02-causality/causality.html#some-notation",
    "title": "Causality and Introduction to R",
    "section": "Some notation",
    "text": "Some notation\nThe causal or treatment variable is:\n\\[\nT_i= \\begin{cases} 1 & \\text { if respondent } i \\text { used social media } \\\\ 0 & \\text { if respondent } i \\text { did not use social media }\\end{cases}\n\\]\nThe observed outcome variable is:\n\\[\nY_i= \\begin{cases} 1 & \\text { if respondent } i \\text { is happy } \\\\ 0 & \\text { if respondent } i \\text { is unhappy }\\end{cases}\n\\]\n\nSo now, are data becomes:\n\n\n\nRespondent\n\\(T_i\\)\n\\(Y_i\\)\n\n\n\n\n1\n1\n0\n\n\n2\n0\n1"
  },
  {
    "objectID": "lectures/02-causality/causality.html#causal-effects-counterfactuals",
    "href": "lectures/02-causality/causality.html#causal-effects-counterfactuals",
    "title": "Causality and Introduction to R",
    "section": "Causal Effects & Counterfactuals",
    "text": "Causal Effects & Counterfactuals\nHow do we translate “what if” questions into a mathematical language?\n\n\n\nTwo potential outcomes:\n\n\\(Y_i(1)\\): the outcome for respondent \\(i\\) if they used social media\n\\(Y_i(0)\\): the outcome for respondent \\(i\\) if they did not use social media\n\n\n\n\n\n\n\nCausal effect for person \\(i\\): \\(Y_i(1) - Y_i(0)\\)\n\n\\(Y_i(1) - Y_i(0) = 0\\) \\(\\rightarrow\\) no effect\n\\(Y_i(1) - Y_i(0) = 1\\) \\(\\rightarrow\\) Social media causes happiness\n\\(Y_i(1) - Y_i(0) = -1\\) \\(\\rightarrow\\) Social media causes unhappiness"
  },
  {
    "objectID": "lectures/02-causality/causality.html#potential-outcomes",
    "href": "lectures/02-causality/causality.html#potential-outcomes",
    "title": "Causality and Introduction to R",
    "section": "Potential Outcomes",
    "text": "Potential Outcomes\n\n\n\nRespondent\n\\(T_i\\)\n\\(Y_i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n1\n0\n?\n0\n\n\n2\n0\n1\n1\n?\n\n\n\nFundamental Problem of Causal Inference\n\nWe only observe one of the potential outcomes\nObserve \\(Y_i(1)\\) if \\(T_i=1\\) and \\(Y_i(0)\\) if \\(T_i=0\\)"
  },
  {
    "objectID": "lectures/02-causality/causality.html#average-treatment-effects",
    "href": "lectures/02-causality/causality.html#average-treatment-effects",
    "title": "Causality and Introduction to R",
    "section": "Average Treatment Effects",
    "text": "Average Treatment Effects\nBecause we cannot observe individual causal effects, we often focus on the Average Treatment Effect (ATE):\n\\[ \\text{ATE} = \\frac{1}{N} \\sum_{i=1}^N (Y_i(1) - Y_i(0)) \\]\n\nThe ATE compares the average outcome when everyone is treated to the average outcome when no one is treated.\n\n\nCan we observe the ATE?"
  },
  {
    "objectID": "lectures/02-causality/causality.html#comparing-groups",
    "href": "lectures/02-causality/causality.html#comparing-groups",
    "title": "Causality and Introduction to R",
    "section": "Comparing Groups",
    "text": "Comparing Groups\nImagine the following dataset:\n\n\n\nRespondent\n\\(T_i\\)\n\\(Y_i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n1\n0\n?\n0\n\n\n2\n0\n1\n1\n?\n\n\n3\n1\n0\n?\n0\n\n\n4\n0\n1\n1\n?\n\n\n\n\nWe might estimate the ATE from this data by comparing the average observed outcome for those who used social media to those who did not:\n\\[ \\textrm{Difference in Means} =  \\frac{\\sum_{i=1}^N Y_i \\cdot T_i}{ \\sum_{i=1}^N T_i} - \\frac{\\sum_{i=1}^N Y_i \\cdot (1-T_i)}{ \\sum_{i=1}^N 1-T_i} \\]\nIn our case, the estimated ATE would be: -1"
  },
  {
    "objectID": "lectures/02-causality/causality.html#counfounding",
    "href": "lectures/02-causality/causality.html#counfounding",
    "title": "Causality and Introduction to R",
    "section": "Counfounding",
    "text": "Counfounding\nNow imagine we could observe the potential outcomes for each respondent:\n\n\n\n\n\n\n\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n1\n0\n0\n0\n0\n\n\n2\n0\n1\n1\n1\n0\n\n\n3\n1\n0\n0\n0\n0\n\n\n4\n0\n1\n1\n1\n0\n\n\n\n\nEven though our estimated ATE is -1, the true ATE is 0. Why?\n\n\nThere is an association between the treatment variable and potential outcomes, but it is not causal.\nIn our example, social media users are less happy, but this is not because of social media use \\(\\rightarrow\\) the comparison across groups is confounded."
  },
  {
    "objectID": "lectures/02-causality/causality.html#randomization",
    "href": "lectures/02-causality/causality.html#randomization",
    "title": "Causality and Introduction to R",
    "section": "Randomization",
    "text": "Randomization\nWe will discuss in more detail later, but key idea is that random assignment of a treatment breaks the association between treatment and potential outcomes.\nThis allows for unconfounded comparisons across groups."
  },
  {
    "objectID": "lectures/02-causality/causality.html#facebook-cessation-experiment",
    "href": "lectures/02-causality/causality.html#facebook-cessation-experiment",
    "title": "Causality and Introduction to R",
    "section": "Facebook Cessation Experiment ",
    "text": "Facebook Cessation Experiment \nAllcott et al. (2020) presents a randomized experiment where half of around 2,800 Facebook users were paid about $100 to deactivate their accounts for a month.\nWhat do they find?\n\nFacebook cessation:\n\n\nFreed up on average of 60 minutes per day\nLed to spending less time online and more time with friends and family\nResulted in 15% decrease in news consumption; also decreased knowledge of politics\nResulted in less extreme political opinions\nCaused small improvements in subjective wellbeing"
  },
  {
    "objectID": "lectures/02-causality/causality.html#r-and-rstudio",
    "href": "lectures/02-causality/causality.html#r-and-rstudio",
    "title": "Causality and Introduction to R",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\n\n\n\n\n\n\nR is an open-source statistical programming language\nR is also an environment for statistical computing and graphics\nIt’s easily extensible with packages\n\n\n\n\nRStudio is a convenient interface for R called an IDE (integrated development environment), e.g. “I write R code in the RStudio IDE”\nRStudio is not a requirement for programming with R, but it’s very commonly used by R programmers and data scientists"
  },
  {
    "objectID": "lectures/02-causality/causality.html#r-vs.-rstudio",
    "href": "lectures/02-causality/causality.html#r-vs.-rstudio",
    "title": "Causality and Introduction to R",
    "section": "R vs. RStudio",
    "text": "R vs. RStudio\n\n\n\n\n\n\n\nSource: Modern Dive."
  },
  {
    "objectID": "lectures/02-causality/causality.html#r-packages",
    "href": "lectures/02-causality/causality.html#r-packages",
    "title": "Causality and Introduction to R",
    "section": "R packages",
    "text": "R packages\n\n\nPackages: Fundamental units of reproducible R code, including reusable R functions, the documentation that describes how to use them, and sample data.\nAs of 15 January 2023, there are 20,252 R packages available on CRAN (the Comprehensive R Archive Network).\nWe’re going to work with a small subset of these."
  },
  {
    "objectID": "lectures/02-causality/causality.html#tour-recap-r-rstudio",
    "href": "lectures/02-causality/causality.html#tour-recap-r-rstudio",
    "title": "Causality and Introduction to R",
    "section": "Tour recap: R + RStudio",
    "text": "Tour recap: R + RStudio"
  },
  {
    "objectID": "lectures/02-causality/causality.html#a-short-list-for-now-of-r-essentials",
    "href": "lectures/02-causality/causality.html#a-short-list-for-now-of-r-essentials",
    "title": "Causality and Introduction to R",
    "section": "A short list (for now) of R essentials",
    "text": "A short list (for now) of R essentials\n\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses:\n\n\ndo_this(to_this)\ndo_that(to_this, to_that, with_those)\n\n\n\nPackages are installed with the install.packages() function and loaded with the library function, once per session:\n\n\ninstall.packages(\"package_name\")\nlibrary(package_name)"
  },
  {
    "objectID": "lectures/02-causality/causality.html#r-essentials-continued",
    "href": "lectures/02-causality/causality.html#r-essentials-continued",
    "title": "Causality and Introduction to R",
    "section": "R essentials (continued)",
    "text": "R essentials (continued)\n\nColumns (variables) in data frames are accessed with $:\n\n\ndataframe$var_name\n\n\n\nObject documentation can be accessed with ?\n\n\n?mean"
  },
  {
    "objectID": "lectures/02-causality/causality.html#tidyverse",
    "href": "lectures/02-causality/causality.html#tidyverse",
    "title": "Causality and Introduction to R",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\n\ntidyverse.org\n\nThe tidyverse is an opinionated collection of R packages designed for data science\nAll packages share an underlying philosophy and a common grammar"
  },
  {
    "objectID": "lectures/02-causality/causality.html#quarto-1",
    "href": "lectures/02-causality/causality.html#quarto-1",
    "title": "Causality and Introduction to R",
    "section": "Quarto",
    "text": "Quarto\n\n\nFully reproducible reports – each time you render the analysis is ran from the beginning\nCode goes in chunks narrative goes outside of chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "lectures/02-causality/causality.html#tour-recap-quarto",
    "href": "lectures/02-causality/causality.html#tour-recap-quarto",
    "title": "Causality and Introduction to R",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "lectures/02-causality/causality.html#environments",
    "href": "lectures/02-causality/causality.html#environments",
    "title": "Causality and Introduction to R",
    "section": "Environments",
    "text": "Environments\n\n\n\n\n\n\nImportant\n\n\nThe environment of your Quarto document is separate from the Console!\n\n\n\nRemember this, and expect it to bite you a few times as you’re learning to work with Quarto!"
  },
  {
    "objectID": "lectures/02-causality/causality.html#environments-1",
    "href": "lectures/02-causality/causality.html#environments-1",
    "title": "Causality and Introduction to R",
    "section": "Environments",
    "text": "Environments\n\n\nFirst, run the following in the console:\n\nx &lt;- 2\nx * 3\n\n\n\nAll looks good?\n\n\nThen, add the following in an R chunk in your Quarto document\n\nx * 3\n\n\n\nWhat happens? Why the error?"
  },
  {
    "objectID": "lectures/02-causality/causality.html#how-will-we-use-quarto",
    "href": "lectures/02-causality/causality.html#how-will-we-use-quarto",
    "title": "Causality and Introduction to R",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery class activity, problem set, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "lectures/02-causality/causality.html#awknowledgements",
    "href": "lectures/02-causality/causality.html#awknowledgements",
    "title": "Causality and Introduction to R",
    "section": "Awknowledgements",
    "text": "Awknowledgements\n\nThis lecture draws partly from:\n\nGOV50 taught by Matt Blackwell at Harvard University\nSTA 199 taught by Mine Çetinkaya-Rundel at Duke University."
  },
  {
    "objectID": "lectures/02-causality/causality.html#references",
    "href": "lectures/02-causality/causality.html#references",
    "title": "Causality and Introduction to R",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAllcott, Hunt, Luca Braghieri, Sarah Eichmeyer, and Matthew Gentzkow. 2020. “The Welfare Effects of Social Media.” American Economic Review 110 (3): 629–76. https://doi.org/10.1257/aer.20190658."
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#misinformation-and-covid-19",
    "href": "lectures/12-linear_model/linear_model.html#misinformation-and-covid-19",
    "title": "Linear Regression",
    "section": "Misinformation and Covid-19",
    "text": "Misinformation and Covid-19\n\nArechar et al. (2023) study misinformation about Covid-19 in 16 countries, with a sample 34K respondents.\nAsk respondents to rate whether 20 headlines are true or false.\n\nAlso test interventions designed to increase discernment of misinformation:\n\nAccuracy: Just ask respondents to rate headlines on accuracy\nSharing: Ask respondents whether they would share the headline on social media\nPrompt: Ask respondents to rate 1 headline on accuracy before asking about sharing\nTips: Minimial digital literacy intervention, i.e. prompt respondents to think about accuracy before sharing (used by Facebook)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#dicernment-across-countries",
    "href": "lectures/12-linear_model/linear_model.html#dicernment-across-countries",
    "title": "Linear Regression",
    "section": "Dicernment Across Countries",
    "text": "Dicernment Across Countries"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#discerning-misinformation",
    "href": "lectures/12-linear_model/linear_model.html#discerning-misinformation",
    "title": "Linear Regression",
    "section": "Discerning Misinformation",
    "text": "Discerning Misinformation\nWe use the dataset from Arechar et al. (2023), which contains information on how people rate the credibility of headlines:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndiscernment\nStandardized difference between the mean rating of true and false headlines\n\n\ncountry\nCountry\n\n\nage\nAge\n\n\ngender\nGender\n\n\ndemo_impt\nHow important is it for you to live in a country that is governed democratically?"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#bivariate-prediction",
    "href": "lectures/12-linear_model/linear_model.html#bivariate-prediction",
    "title": "Linear Regression",
    "section": "Bivariate Prediction",
    "text": "Bivariate Prediction\n\nGoal: What’s our best guess for a respondent’s misinformation discernment given their age?\n\n\n\n\nmisinfo_age_plot &lt;- \n  filter(discernment, country == \"us\") |&gt;\n        ggplot(aes(\n                x = age,\n                y = discernment\n        )) +\n        geom_point() +\n        labs(\n                x = \"Age\",\n                y = \"Misinformation Discernment\"\n        )\nmisinfo_age_plot"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#bivariate-prediction-1",
    "href": "lectures/12-linear_model/linear_model.html#bivariate-prediction-1",
    "title": "Linear Regression",
    "section": "Bivariate Prediction",
    "text": "Bivariate Prediction\n\nFor a given value of X, what’s the best guess for Y?\n\nWe need a function that maps values of X predictions about Y.\n\nExample: what is the level of misinformation discernment for a 22-year-old?\n\n\nmisinfo_age22 &lt;- filter(discernment, country == \"us\") |&gt;\n  summarise(mean(discernment[age == 22])) |&gt;\n  pull()\nmisinfo_age22\n\n[1] 0.6042924"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#plot-the-prediction",
    "href": "lectures/12-linear_model/linear_model.html#plot-the-prediction",
    "title": "Linear Regression",
    "section": "Plot the Prediction",
    "text": "Plot the Prediction\n\n\nmisinfo_age_plot +\n  geom_point(aes(x = 22,\n                 y = misinfo_age22), \n             color = \"red\", size = 5)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#predictions-for-all-ages",
    "href": "lectures/12-linear_model/linear_model.html#predictions-for-all-ages",
    "title": "Linear Regression",
    "section": "Predictions for All Ages",
    "text": "Predictions for All Ages\nWe can use the stat_summary function to plot the mean misinformation discernment for each age.\n\n\nmisinfo_age_plot +\n  stat_summary(fun = mean, \n               geom = \"point\",\n               size = 5, \n               color = \"red\")"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#binned-means",
    "href": "lectures/12-linear_model/linear_model.html#binned-means",
    "title": "Linear Regression",
    "section": "Binned Means",
    "text": "Binned Means\n\nWhile age-specific means are informative, they are pretty noisy. Is it really the case that a 22-year-old is that different from a 23-year-old?\nWe might reduce noise by binning ages and calculating the mean misinformation discernment for each bin.\nWe can use the stat_summary_bin function to do this.\n\n\n\nmisinfo_age_plot +\n  stat_summary_bin(fun = mean, \n                   geom = \"point\",\n                   size = 5, \n                   color = \"red\",\n                   binwidth = 2)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#bigger-bins",
    "href": "lectures/12-linear_model/linear_model.html#bigger-bins",
    "title": "Linear Regression",
    "section": "Bigger Bins",
    "text": "Bigger Bins\n\n\nmisinfo_age_plot +\n  stat_summary_bin(fun = mean, \n                   geom = \"point\",\n                   size = 5, \n                   color = \"red\",\n                   binwidth = 5)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#using-a-line-to-predict",
    "href": "lectures/12-linear_model/linear_model.html#using-a-line-to-predict",
    "title": "Linear Regression",
    "section": "Using a line to predict",
    "text": "Using a line to predict\n\nRather than discrete bins, we can use a linear model to predict misinformation discernment from age.\nSimplest possible way to relate two variables: a line\n\n\\[ y = mx + b \\]\n\nProblem: for any line we draw, not all the data is on the line.\n\nSome points will be above the line, some below.\nNeed a way to account for chance variation away from the line."
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#linear-regression-model",
    "href": "lectures/12-linear_model/linear_model.html#linear-regression-model",
    "title": "Linear Regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\nModel for the line of best fit:\n\n\\[ Y_i = \\underbrace{\\alpha}_{\\text{intercept}} + \\underbrace{\\beta}_{\\text{slope}} \\cdot X_i + \\underbrace{\\epsilon_i}_{\\text{error term}} \\] - Coefficients/parameters (\\(\\alpha\\) and \\(\\beta\\)): true unknown intercept / slope of the line of best fit - “True” refers to the slopes we could estimate if we the slope on the full population.\n\nError term (\\(\\epsilon_i\\)): the difference between the predicted value and the true value of \\(Y_i\\).\n\nChance errors are 0 on average, and uncorrelated with \\(X_i\\)."
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#interpretation-of-the-regression-line",
    "href": "lectures/12-linear_model/linear_model.html#interpretation-of-the-regression-line",
    "title": "Linear Regression",
    "section": "Interpretation of the regression line",
    "text": "Interpretation of the regression line\n\\[ Y_i = \\alpha + \\beta \\cdot X_i + \\epsilon_i \\]\n\nIntercept (\\(\\alpha\\)): the value of \\(Y\\) when \\(X = 0\\).\n\nAverage misinformation discernment for a 0-year-old.\n\nSlope (\\(\\beta\\)): the change in \\(Y\\) for a one-unit change in \\(X\\).\n\nAverage change in misinformation discernment for a one-year change in age."
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#parameters-vs-estimates",
    "href": "lectures/12-linear_model/linear_model.html#parameters-vs-estimates",
    "title": "Linear Regression",
    "section": "Parameters vs Estimates",
    "text": "Parameters vs Estimates\n\nParameters (\\(\\alpha\\) and \\(\\beta\\)):\n\nThe values of \\(\\alpha\\) and \\(\\beta\\) if we could observe all the data.\nBecause we almost always only have a sample, we can only estimate these values.\n\nEstimates (\\(\\hat\\alpha\\) and \\(\\hat{\\beta}\\)):\n\nThe values of \\(\\alpha\\) and \\(\\beta\\) we calculate from the data.\nThese estimates are our best guess at the true values of \\(\\alpha\\) and \\(\\beta\\).\n\nRegression Line: \\(\\hat{Y} = \\hat\\alpha + \\hat\\beta \\cdot X\\)\n\nAccording to the model, average value of \\(Y\\) for a given \\(X\\) (predicted value)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#line-of-best-fit",
    "href": "lectures/12-linear_model/linear_model.html#line-of-best-fit",
    "title": "Linear Regression",
    "section": "Line of Best Fit",
    "text": "Line of Best Fit\n\n\nmisinfo_age_plot +\n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              color = \"red\",\n              size = 3)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#why-not-this-line",
    "href": "lectures/12-linear_model/linear_model.html#why-not-this-line",
    "title": "Linear Regression",
    "section": "Why not this line?",
    "text": "Why not this line?"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#prediction-error",
    "href": "lectures/12-linear_model/linear_model.html#prediction-error",
    "title": "Linear Regression",
    "section": "Prediction Error",
    "text": "Prediction Error\n\nPrediction Error: the difference between the predicted value and the true value of \\(Y_i\\): \\[Y_i - (\\hat \\alpha + \\hat \\beta X_i) \\]\nWe can’t predict the exact value of \\(Y_i\\) for a given \\(X_i\\) for two reasons:\n\nThe conditional average does not capture all the variation in \\(Y_i\\).\nThe true function is not linear.\n\nIn our sampled data, we call this difference the residual."
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#least-squares",
    "href": "lectures/12-linear_model/linear_model.html#least-squares",
    "title": "Linear Regression",
    "section": "Least Squares",
    "text": "Least Squares\nHow do we get the line of best fit?\n\nLeast Squares: the method of finding the line of best fit by minimizing the sum of the squared residuals (SSR) \\[\\text{SSR} = \\sum_{i=1}^n (\\text{prediction error}_i)^2 = \\sum_{i=1}^n (Y_i - \\hat \\alpha - \\hat \\beta \\cdot X_i)^2 \\]\nThe line of best fit is the one that minimizes the magnitude of prediction errors."
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#linear-regressionion-in-r",
    "href": "lectures/12-linear_model/linear_model.html#linear-regressionion-in-r",
    "title": "Linear Regression",
    "section": "Linear Regressionion in R",
    "text": "Linear Regressionion in R\n\nR will calculate the line of best fit for us using the lm function.\n\nSyntax is lm(y ~ x, data = data_frame)\ny is the outcome variable, x is the predictor variable.\ndata_frame is the data frame containing the variables.\n\n\n\nfit &lt;- lm(discernment ~ age, data = discernment)\nfit\n\n\nCall:\nlm(formula = discernment ~ age, data = discernment)\n\nCoefficients:\n(Intercept)          age  \n   0.530761     0.006866"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#extracting-coefficients",
    "href": "lectures/12-linear_model/linear_model.html#extracting-coefficients",
    "title": "Linear Regression",
    "section": "Extracting Coefficients",
    "text": "Extracting Coefficients\nUse the coef function to extract the coefficients from the model object.\n\ncoef(fit)\n\n(Intercept)         age \n0.530760580 0.006866304 \n\n\nA 1-unit increase in age (1 year) is associated with a .006 increase in the average level of discernment."
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#broom-package",
    "href": "lectures/12-linear_model/linear_model.html#broom-package",
    "title": "Linear Regression",
    "section": "broom package",
    "text": "broom package\n\nThe broom package provides a suite of functions for working with model objects.\nThe tidy function extracts the coefficients from a model object in a data frame.\n\n\nlibrary(broom)\ntidy(fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  0.531    0.0164        32.4 1.39e-216\n2 age          0.00687  0.000380      18.1 1.69e- 71"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#more-on-broom",
    "href": "lectures/12-linear_model/linear_model.html#more-on-broom",
    "title": "Linear Regression",
    "section": "More on broom",
    "text": "More on broom\nThe augment function adds the predicted values and residuals to the original data frame.\n\naugment(fit)\n\n# A tibble: 8,359 × 8\n   discernment   age .fitted .resid     .hat .sigma    .cooksd .std.resid\n         &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1       1.13     69   1.00   0.130 0.000512  0.556 0.0000139       0.233\n 2       1.43     68   0.998  0.433 0.000485  0.556 0.000147        0.778\n 3       1.26     25   0.702  0.561 0.000225  0.556 0.000115        1.01 \n 4       1.30     78   1.07   0.234 0.000793  0.556 0.0000700       0.420\n 5       1.74     55   0.908  0.835 0.000224  0.556 0.000253        1.50 \n 6       1.32     59   0.936  0.380 0.000288  0.556 0.0000672       0.683\n 7       1.66     80   1.08   0.585 0.000866  0.556 0.000479        1.05 \n 8       1.73     69   1.00   0.721 0.000512  0.556 0.000430        1.30 \n 9      -0.487    26   0.709 -1.20  0.000212  0.556 0.000490       -2.15 \n10       0.933    40   0.805  0.127 0.000120  0.556 0.00000314      0.229\n# ℹ 8,349 more rows"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#plotting-the-residuals",
    "href": "lectures/12-linear_model/linear_model.html#plotting-the-residuals",
    "title": "Linear Regression",
    "section": "Plotting the Residuals",
    "text": "Plotting the Residuals\n\n\naugment_out &lt;- augment(fit)\n\nggplot(augment_out, aes(x = age, y = .resid)) +\n  geom_point() +\n  labs(title = \"Residuals Plot\",\n       x = \"Age\",\n       y = \"Residuals\") +\n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              color = \"red\",\n              size = 3)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#prediction-with-the-model",
    "href": "lectures/12-linear_model/linear_model.html#prediction-with-the-model",
    "title": "Linear Regression",
    "section": "Prediction with the Model",
    "text": "Prediction with the Model\n\nWe can use the predict function to get the predicted values from the model.\nThe newdata argument is a data frame with the values of the predictor variable(s) we want to predict for.\n\n\npredict(fit, newdata = data.frame(age = c(20, 70)))\n\n        1         2 \n0.6680867 1.0114019"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#back-to-the-binned-means",
    "href": "lectures/12-linear_model/linear_model.html#back-to-the-binned-means",
    "title": "Linear Regression",
    "section": "Back to the Binned Means",
    "text": "Back to the Binned Means\n\n\nmisinfo_age_plot +\n  stat_summary(fun = mean, \n               geom = \"point\",\n               size = 5, \n               color = \"red\") + \n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"red\",\n              size = 3)"
  },
  {
    "objectID": "lectures/12-linear_model/linear_model.html#references",
    "href": "lectures/12-linear_model/linear_model.html#references",
    "title": "Linear Regression",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nArechar, Antonio A., Jennifer Allen, Adam J. Berinsky, Rocky Cole, Ziv Epstein, Kiran Garimella, Andrew Gully, et al. 2023. “Understanding and Combatting Misinformation Across 16 Countries on Six Continents.” Nature Human Behaviour 7 (9, 9): 1502–13. https://doi.org/10.1038/s41562-023-01641-6."
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#data-and-politics",
    "href": "lectures/01-introduction/introduction.html#data-and-politics",
    "title": "Data and Politics",
    "section": "Data and Politics",
    "text": "Data and Politics\nWelcome to 17.831!\n\nInstructor: F. Daniel Hidalgo\nSchedule: TR 9:30-11:00"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#what-is-this-course-about",
    "href": "lectures/01-introduction/introduction.html#what-is-this-course-about",
    "title": "Data and Politics",
    "section": "What is this course about?",
    "text": "What is this course about?\n\n\nThis course is about using data to answer social science questions.\nFocus on interventions to lead to change or to measure social facts.\n\n\n\n\nQuestion\nWhat interventions can solve pressing social and political problems?\n\n\n\nExamples\n\nReducing Intergroup prejudice\nIncreasing Political Participation\nMeasuring and Changing Discriminatory Attitudes\nFighting Electoral Fraud"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#example-can-conversations-change-attitudes",
    "href": "lectures/01-introduction/introduction.html#example-can-conversations-change-attitudes",
    "title": "Data and Politics",
    "section": "Example: Can Conversations Change Attitudes?",
    "text": "Example: Can Conversations Change Attitudes?\n\nCredit: New York Times"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#estimating-effects-of-canvassing",
    "href": "lectures/01-introduction/introduction.html#estimating-effects-of-canvassing",
    "title": "Data and Politics",
    "section": "Estimating Effects of Canvassing",
    "text": "Estimating Effects of Canvassing\n\nBroockman and Kalla (2016)"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#example-can-sustained-contact-reduce-prejudice",
    "href": "lectures/01-introduction/introduction.html#example-can-sustained-contact-reduce-prejudice",
    "title": "Data and Politics",
    "section": "Example: Can Sustained Contact Reduce Prejudice?",
    "text": "Example: Can Sustained Contact Reduce Prejudice?\n\nMousa (2020)"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#example-can-facebook-ads-help-combat-election-fraud",
    "href": "lectures/01-introduction/introduction.html#example-can-facebook-ads-help-combat-election-fraud",
    "title": "Data and Politics",
    "section": "Example: Can Facebook Ads Help Combat Election Fraud?",
    "text": "Example: Can Facebook Ads Help Combat Election Fraud?\n\nGarbiras-Díaz and Montenegro (2022)"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#how-do-we-measure-social-facts",
    "href": "lectures/01-introduction/introduction.html#how-do-we-measure-social-facts",
    "title": "Data and Politics",
    "section": "How do we measure social facts?",
    "text": "How do we measure social facts?\n\n\nQuestion\nHow do we measure attitudes and behaviors in the general population?\n\n\n\nExamples\n\nDiscriminatory Attitudes\nPartisan Animosity\nSupport for democratic institutions\nBeliefs in conspiracies"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#example-presidential-polling",
    "href": "lectures/01-introduction/introduction.html#example-presidential-polling",
    "title": "Data and Politics",
    "section": "Example: Presidential Polling",
    "text": "Example: Presidential Polling\n\n538"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#example-how-do-partisans-view-each-other",
    "href": "lectures/01-introduction/introduction.html#example-how-do-partisans-view-each-other",
    "title": "Data and Politics",
    "section": "Example: How Do Partisans View Each Other?",
    "text": "Example: How Do Partisans View Each Other?\n\nAhler and Sood (2018)"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#substantive-topics",
    "href": "lectures/01-introduction/introduction.html#substantive-topics",
    "title": "Data and Politics",
    "section": "Substantive Topics",
    "text": "Substantive Topics\n\n\nShow schedule\nAsk students about what they are interested in\n\n\n\n\nWeek 2: Combating Inter-Group Prejudice\nWeek 3: Increasing Political Participation\nWeek 4: The Role of Partisanship vs Ideology in Public Opinion\nWeek 5: Political Persuasion\nWeek 6: Combating Electoral Fraud\nWeek 7: Censorship in Authoritarian Regimes\nWeek 8: Fighting Misinformation\nWeek 9: Partisan Animosity and Polarization\nWeek 10: Polling and Election Forecasting"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#research-design",
    "href": "lectures/01-introduction/introduction.html#research-design",
    "title": "Data and Politics",
    "section": "Research Design",
    "text": "Research Design\nThis class is about research design, which is a blend of:\n\nTheory and substantive knowledge\nCraft\nStatistics\nComputation\n\n\nIn particular, we will focus on the design and analysis of randomized experiments and survey samples."
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#design-based-inference",
    "href": "lectures/01-introduction/introduction.html#design-based-inference",
    "title": "Data and Politics",
    "section": "Design Based Inference",
    "text": "Design Based Inference\nRandomized experiments and surveys are examples of design based inference.\n\nWe will learn to:\n\nRead and critique scientific papers that use these approaches\nUnderstand the statistical theory underpinning this mode of inference\nAnalyze experimental and survey data using modern statistical computing tools\nDesign and implement our own studies"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#experiments-and-surveys",
    "href": "lectures/01-introduction/introduction.html#experiments-and-surveys",
    "title": "Data and Politics",
    "section": "Experiments and Surveys",
    "text": "Experiments and Surveys\n\n\n\n\n\n\n\n\n\nExperiments\nSurveys\n\n\n\n\nTarget of Inference\nCounterfactuals\nOut of Sample Observations\n\n\nThreats to Internal Validity\nOmitted Variable Bias\nNon-Response\n\n\nSelection Mechanism\nRandom Assignment\nRandom Sampling\n\n\nThreats to External Validity\nLack of Realism\nMeasurement Error\n\n\nStatistical Analysis\nModeling\nWeighting"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#computation",
    "href": "lectures/01-introduction/introduction.html#computation",
    "title": "Data and Politics",
    "section": "Computation:  + ",
    "text": "Computation:  + \n\nWe will use the R statistical environment to analyze data.\n\nIt’s free.\nExcellent for data analysis and visualization.\nRich ecosystem of packages for social science and statistics.\nInfrastructure for inter-mingling code, data, and text.\n\nUsed extensively in Academia, media, and industry\nWe will use RStudio as our development environment."
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#should-i-take-this-course",
    "href": "lectures/01-introduction/introduction.html#should-i-take-this-course",
    "title": "Data and Politics",
    "section": "Should I take this course?",
    "text": "Should I take this course?\n\nPrerequisites: NONE\nInterest in using data to answer social science questions\nWilling to work consistently throughout semester and learn new tools\nMaterial useful to students interested in public policy, political science, economics, computational social science, etc"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#flow-of-the-course",
    "href": "lectures/01-introduction/introduction.html#flow-of-the-course",
    "title": "Data and Politics",
    "section": "Flow of the Course",
    "text": "Flow of the Course\n\n\nLectures\n\nClass sessions will be a mix of:\n\nLecture\nDiscussion\nLive coding\nClass activities\n\nBring laptop to class!\n\n\n\n\nHome\n\nRead assigned readings\nComplete:\n\nProblem Sets\nReading quizzes and coding tutorials\nFinal Project"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#assignments",
    "href": "lectures/01-introduction/introduction.html#assignments",
    "title": "Data and Politics",
    "section": "Assignments",
    "text": "Assignments\n\n\nProblem Sets\n\nFocused on data analysis and simulations\nRoughly every two weeks\nDrop lowest grade\n\n\n\nReading Quizzes and Coding Tutorials\n\nGenerally due weekly\n\nQuizzes due before Tuesday’s class\nCoding tutorials due before Thursday’s class\n\nGraded on completion\n\n\n\n\n\nClass Project\n\nWe will collectively design and implement an experiment embedded in a survey\nYou will:\n\nPropose ideas\nWrite a questionnaire\nWrite a pre-analysis plan\nAnalyze and write up the results\n\nMostly done in second half of semester"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#readings",
    "href": "lectures/01-introduction/introduction.html#readings",
    "title": "Data and Politics",
    "section": "Readings",
    "text": "Readings\n\n\n1 required book for purchase: \n\n\nAll other readings will be posted on Materials page of class website. Also see the schedule.\nWe will use Perusall to annotate and discuss readings.\n\nAsk questions so that classmates and I can help answer them.\nCounts for class participation"
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#grades-and-help",
    "href": "lectures/01-introduction/introduction.html#grades-and-help",
    "title": "Data and Politics",
    "section": "Grades and Help",
    "text": "Grades and Help\n\n\n\n\n\nCategory\n%\n\n\n\n\nCoding Tutorials\n5%\n\n\nReading Quizzes\n5%\n\n\nProblem Sets\n50%\n\n\nClass Participation\n25%\n\n\nClass Project Writeup\n15%\n\n\n\n\n\n\nAsk questions about readings on Perusall.\nAsk questions about coding or assignments on Piazza.\nOffice hours: Friday 12-2:30pm. Best if you sign up in advance."
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#what-you-should-do-today",
    "href": "lectures/01-introduction/introduction.html#what-you-should-do-today",
    "title": "Data and Politics",
    "section": "What You Should Do Today",
    "text": "What You Should Do Today\n\nGet R and RStudio setup on your computer. See instructions on Resources page.\n\nIf you have trouble with this, can also use Posit Cloud to run R and RStudio in your browser (details to follow)\n\nStart Tutorial 1 on basics of R and data visualization.\n\nCan be done on the web before installing R on your computer."
  },
  {
    "objectID": "lectures/01-introduction/introduction.html#references",
    "href": "lectures/01-introduction/introduction.html#references",
    "title": "Data and Politics",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAhler, Douglas J., and Gaurav Sood. 2018. “The Parties in Our Heads: Misperceptions about Party Composition and Their Consequences.” The Journal of Politics 80 (3): 964–81. https://doi.org/10.1086/697253.\n\n\nBroockman, David, and Joshua Kalla. 2016. “Durably Reducing Transphobia: A Field Experiment on Door-to-Door Canvassing.” Science 352 (6282): 220–24. https://doi.org/10.1126/science.aad9713.\n\n\nGarbiras-Díaz, Natalia, and Mateo Montenegro. 2022. “All Eyes on Them: A Field Experiment on Citizen Oversight and Electoral Integrity.” American Economic Review 112 (8): 2631–68. https://doi.org/10.1257/aer.20210778.\n\n\nMousa, Salma. 2020. “Building Social Cohesion Between Christians and Muslims Through Soccer in Post-ISIS Iraq.” Science 369 (6505): 866–70. https://doi.org/10.1126/science.abb3153."
  },
  {
    "objectID": "lectures/00-template/00-template.html#example-slide",
    "href": "lectures/00-template/00-template.html#example-slide",
    "title": "Quarto reveal.js clean",
    "section": "Example slide",
    "text": "Example slide\nThis is a subtitle\nBefore we dive a bit deeper, here is a simple example of the clean theme in action.\n\nNo pictures or anything fancy. Just text for the moment.\n\nNext, we’ll take a brief tour of some theme components.\n\nWe’ll use the same basic structure as the original LaTeX slides.\nNote that the full suite of Reveal.js features are available for this Quarto implementation, even if we don’t cover everything here."
  },
  {
    "objectID": "lectures/00-template/00-template.html#before-you-proceed",
    "href": "lectures/00-template/00-template.html#before-you-proceed",
    "title": "Quarto reveal.js clean",
    "section": "Before you proceed…",
    "text": "Before you proceed…\nRequirements for the coding examples in this demo\n\n\n\n\n\n\nR libraries\n\n\nWhile the clean theme is language agnostic, we will use several R coding examples in this demo to highlight some advanced theme features.\nYou will need the following libraries if you’d like to render the template “as-is”:\ninstall.packages(c(\"modelsummary\", \"gt\", \"fixest\", \"pdftools\", \"tinytex\", \"threejs\"))\n\n\n\n\n\n\n\n\n\nTinyTex\n\n\nWhile reveal.js presentations are HTML format, we will show an example of how to embed LaTeX tables as images. This requires a working Tex distribution, of which TinyTex provides by far the easiest and lightest integration with Quarto. More details here.\nquarto install tinytex"
  },
  {
    "objectID": "lectures/00-template/00-template.html#components-1",
    "href": "lectures/00-template/00-template.html#components-1",
    "title": "Quarto reveal.js clean",
    "section": "Components",
    "text": "Components\nOrdered and Unordered Lists\nHere we have an unordered list.\n\nfirst item\n\nsub-item\n\nsecond item\n\nAnd next we have an ordered one.\n\nfirst item\n\nsub-item\n\nsecond item"
  },
  {
    "objectID": "lectures/00-template/00-template.html#components-2",
    "href": "lectures/00-template/00-template.html#components-2",
    "title": "Quarto reveal.js clean",
    "section": "Components",
    "text": "Components\nAlerts & Cross-refs\nTo emphasize specific words or text, you can:\n\nUse the default .alert class, e.g. important note.\nUse the .fg class for custom colour, e.g. important note.\nUse the .bg class for custom background, e.g. important note.\n\nTo cross-reference, you have several options, for example:\n\nBeamer-like .button class provided by this theme, e.g. Appendix\nQuarto’s native cross-ref syntax, e.g., “See Section 4.3.”"
  },
  {
    "objectID": "lectures/00-template/00-template.html#components-3",
    "href": "lectures/00-template/00-template.html#components-3",
    "title": "Quarto reveal.js clean",
    "section": "Components",
    "text": "Components\nCitations\nCitations follow the standard Quarto format and be sourced from BibLaTex, BibTeX, or CLS files. For example:\n\nTopic 1: Spatial Frictions (Fajgelbaum et al. 2018; Hsieh and Moretti 2019; Moretti 2011)\nTopic 2: Blah (Suárez Serrato and Zidar 2016)"
  },
  {
    "objectID": "lectures/00-template/00-template.html#components-4",
    "href": "lectures/00-template/00-template.html#components-4",
    "title": "Quarto reveal.js clean",
    "section": "Components",
    "text": "Components\nBlocks\nQuarto provides dedicated environments for theorems, lemmas, and so forth.\nBut in presentation format, it’s arguably more effective just to use a Callout Block.\n\n\n\n\n\n\nRegression Specification\n\n\nThe main specification is as follows:\n\\[\ny_{it} = X_{it} \\beta + \\mu_i + \\varepsilon_{it}\n\\]"
  },
  {
    "objectID": "lectures/00-template/00-template.html#components-5",
    "href": "lectures/00-template/00-template.html#components-5",
    "title": "Quarto reveal.js clean",
    "section": "Components",
    "text": "Components\nMulticolumn I: Text only\n\n\nColumn 1\nHere is a long sentence that will wrap onto the next line as it hits the column width, and continue this way until it stops.\n\nColumn 2\nSome other text in another column.\nA second paragraph.\n\n\nMulticolumn support is very flexible and we can continue with a single full span column in the same slide."
  },
  {
    "objectID": "lectures/00-template/00-template.html#components-6",
    "href": "lectures/00-template/00-template.html#components-6",
    "title": "Quarto reveal.js clean",
    "section": "Components",
    "text": "Components\nMulticolumn II: Text and figures\n\n\n\n\n\nA point about the figure that is potentially important.\nAnother point about the figure that is also potentially important.\n\n\n\nNote that sub- and multi-panel figures are also natively supported by Quarto. See here."
  },
  {
    "objectID": "lectures/00-template/00-template.html#components-7",
    "href": "lectures/00-template/00-template.html#components-7",
    "title": "Quarto reveal.js clean",
    "section": "Components",
    "text": "Components\nMulticolumn III: Code and output\n\n\npalette(\"Classic Tableau\")\n\npar(\n        family = \"HersheySans\",\n        las = 1, pch = 19, cex = 1.5\n)\n\npairs(\n        iris[, 1:4],\n        col = iris$Species\n)\n\n\n\n\n\n\n\n\nFigure 1: Pairwise scatterplot"
  },
  {
    "objectID": "lectures/00-template/00-template.html#tables-1",
    "href": "lectures/00-template/00-template.html#tables-1",
    "title": "Quarto reveal.js clean",
    "section": "Tables",
    "text": "Tables\nRegression example\nQuarto offers excellent table support, with further customization via user libraries. Let’s illustrate with a regression example:\n\nlibrary(fixest)\n\nmods &lt;- feols(\n        rating ~ complaints + privileges + learning + csw0(raises + critical) + advance,\n        data = attitude\n)\n\ndict &lt;- c(\n        \"rating\" = \"Overall Rating\",\n        \"complaints\" = \"Handling of Complaints\",\n        \"privileges\" = \"No Special Priviledges\",\n        \"learning\" = \"Opportunity to Learn\",\n        \"raises\" = \"Performance-Based Raises\",\n        \"critical\" = \"Too Critical\",\n        \"advance\" = \"Advancement\"\n)"
  },
  {
    "objectID": "lectures/00-template/00-template.html#regression-table",
    "href": "lectures/00-template/00-template.html#regression-table",
    "title": "Quarto reveal.js clean",
    "section": "Regression table",
    "text": "Regression table\nmodelsummary\nIf you use modelsummary with this Quarto theme, we advise setting the gt backend for a cleaner aesthetic. More details here.\n\nlibrary(modelsummary)\noptions(modelsummary_factory_default = \"gt\")\n\nmodelsummary(\n        setNames(mods, c(\"(1)\", \"(2)\")),\n        coef_map = dict, stars = TRUE,\n        gof_omit = \"Adj|IC|F|Log|RMSE\"\n) |&gt;\n        gt::tab_spanner(\n                label = \"Dependent variable: Overall Rating\",\n                columns = 2:3\n        )"
  },
  {
    "objectID": "lectures/00-template/00-template.html#regression-table-output",
    "href": "lectures/00-template/00-template.html#regression-table-output",
    "title": "Quarto reveal.js clean",
    "section": "Regression table",
    "text": "Regression table\n\n\n\n\n\n\n\n\n\nDependent variable: Overall Rating\n\n\n(1)\n(2)\n\n\n\n\nHandling of Complaints\n0.653***\n0.613***\n\n\n\n(0.131)\n(0.161)\n\n\nNo Special Priviledges\n-0.077\n-0.073\n\n\n\n(0.131)\n(0.136)\n\n\nOpportunity to Learn\n0.324+\n0.320+\n\n\n\n(0.157)\n(0.169)\n\n\nPerformance-Based Raises\n\n0.082\n\n\n\n\n(0.221)\n\n\nToo Critical\n\n0.038\n\n\n\n\n(0.147)\n\n\nAdvancement\n-0.172\n-0.217\n\n\n\n(0.149)\n(0.178)\n\n\nNum.Obs.\n30\n30\n\n\nR2\n0.729\n0.733\n\n\nStd.Errors\nIID\nIID\n\n\n\n+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001"
  },
  {
    "objectID": "lectures/00-template/00-template.html#regression-table-1",
    "href": "lectures/00-template/00-template.html#regression-table-1",
    "title": "Quarto reveal.js clean",
    "section": "Regression table",
    "text": "Regression table\netable\nfixest’s powerful native tabling functions were designed for LaTeX output. But we can use the markdown = TRUE option to make them work with this theme too. (Details here.) Quick notes:\n\nInstall the tinytex & pdftools packages first.\nSet the R chunk option output: asis.\n\n```{{r}}\n#| output: asis\n\nsetFixest_etable(markdown = TRUE, drop = \"Constant\")\nsetFixest_dict(dict)\n\netable(mods, highlight = .(\"se\" = \"complaints\"))\n```"
  },
  {
    "objectID": "lectures/00-template/00-template.html#regression-table-2",
    "href": "lectures/00-template/00-template.html#regression-table-2",
    "title": "Quarto reveal.js clean",
    "section": "Regression table",
    "text": "Regression table\netable (cont.)"
  },
  {
    "objectID": "lectures/00-template/00-template.html#figure",
    "href": "lectures/00-template/00-template.html#figure",
    "title": "Quarto reveal.js clean",
    "section": "Figure",
    "text": "Figure"
  },
  {
    "objectID": "lectures/00-template/00-template.html#figure-1",
    "href": "lectures/00-template/00-template.html#figure-1",
    "title": "Quarto reveal.js clean",
    "section": "Figure",
    "text": "Figure\nFull-size Figures\nYou can use the {.background-image} container environment to completely fill the slide background with an image.\nIdeally, your figure will be the same aspect ratio as the screen that you’re presenting on.\n\nThis can be a bit tricky because of the dynamic nature of reveal.js / HTML. But it’s probably something close to 16:9.\nAspect ratio can also matter for a regular full-frame images (previous slide)."
  },
  {
    "objectID": "lectures/00-template/00-template.html#interactive-plots",
    "href": "lectures/00-template/00-template.html#interactive-plots",
    "title": "Quarto reveal.js clean",
    "section": "Interactive plots",
    "text": "Interactive plots\n\n\n\n\n\n\nNote: Simple flight data example using threejs. There are many interactive plotting options beyond this. (More details.)"
  },
  {
    "objectID": "lectures/00-template/00-template.html#summary-1",
    "href": "lectures/00-template/00-template.html#summary-1",
    "title": "Quarto reveal.js clean",
    "section": "Summary",
    "text": "Summary\nA minimal and elegant presentation theme\nThe Quarto reveal.js clean theme aims to be a minimal and elegant presention theme.\nWe have highlighted some theme-specific components. But all of the regular reveal.js functionality is supported (chalkboard, etc.)\nInstall the theme:\nquarto install extension grantmcdermott/quarto-revealjs-clean\nUse these demo slides as a template:\nquarto use template grantmcdermott/quarto-revealjs-clean-demo"
  },
  {
    "objectID": "lectures/00-template/00-template.html#references",
    "href": "lectures/00-template/00-template.html#references",
    "title": "Quarto reveal.js clean",
    "section": "References",
    "text": "References\n\n\nFajgelbaum, Pablo D, Eduardo Morales, Juan Carlos Suarez Serrato, and Owen Zidar. 2018. “State Taxes and Spatial Misallocation,” 90.\n\n\nHsieh, Chang-Tai, and Enrico Moretti. 2019. “Housing Constraints and Spatial Misallocation.” American Economic Journal: Macroeconomics 11 (2): 39.\n\n\nMoretti, Enrico. 2011. “Local Labor Markets.” In Handbook of Labor Economics. Vol. 4. Elsevier.\n\n\nSuárez Serrato, Juan Carlos, and Owen Zidar. 2016. “Who Benefits from State Corporate Tax Cuts? A Local Labor Markets Approach with Heterogeneous Firms.” American Economic Review 106 (9)."
  },
  {
    "objectID": "lectures/00-template/00-template.html#sec-appendix",
    "href": "lectures/00-template/00-template.html#sec-appendix",
    "title": "Quarto reveal.js clean",
    "section": "Appendix",
    "text": "Appendix\n\n\n\n\nTable 1: Summary of the base R attitude dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnique (#)\nMissing (%)\nMean\nSD\nMin\nMedian\nMax\n\n\n\n\n\nrating\n22\n0\n64.6\n12.2\n40.0\n65.5\n85.0\n\n\n\n   \n\n\n\ncomplaints\n23\n0\n66.6\n13.3\n37.0\n65.0\n90.0\n\n\n\n   \n\n\n\nprivileges\n24\n0\n53.1\n12.2\n30.0\n51.5\n83.0\n\n\n\n   \n\n\n\nlearning\n23\n0\n56.4\n11.7\n34.0\n56.5\n75.0\n\n\n\n   \n\n\n\nraises\n21\n0\n64.6\n10.4\n43.0\n63.5\n88.0\n\n\n\n   \n\n\n\ncritical\n21\n0\n74.8\n9.9\n49.0\n77.5\n92.0\n\n\n\n   \n\n\n\nadvance\n20\n0\n42.9\n10.3\n25.0\n41.0\n72.0\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\nBack to main"
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Materials",
    "section": "",
    "text": "Week 1: Course Introduction\nWeek 2: Intergroup Prejudice\nWeek 3: Intergroup Prejudice\nWeek 4: Partisanship vs Ideology\nWeek 5: Persuasion\nWeek 6: Combatting Electoral Fraud\nWeek 7: Censorship\nWeek 8: Misinformation\nWeek 9: Link"
  },
  {
    "objectID": "resources/r_setup.html",
    "href": "resources/r_setup.html",
    "title": "Setting up R and RStudio",
    "section": "",
    "text": "Go to the CRAN website and click on the download link for your operating system (Windows, Mac, or Linux).\n\n\nMacWindows\n\n\nClick on the R-X.X.X-arm64.pkg or R-X.X.X-x86_64.pkg link to download the installer. The precise file name depends on the latest version and whether you have an Intel processor or a newer ARM processor such as the M1, i.e. R-4.3.2-arm64.pkg. Once the download is complete, open the file and follow the installation instructions.\n\n\n\n\n\n\nTip\n\n\n\nTo determine whether you have an Intel or ARM processor, click on the Apple logo in the top left corner of your screen, select “About This Mac”, and look for the line that indicates “Chip” or “Processor”. If the line says something like “Apple M1” or “Apple M1 Pro”, you have an ARM processor. If it says something like “Intel Core i5” or “Intel Core i7”, you have an Intel processor.\n\n\n\n\nClick on the link that says base. Then click on the “Download R-X.X.X for Windows” link to download the installer. Once the download is complete, open the file and follow the installation instructions.\n\n\n\n\nOnce you have installed R, go to the download page for RStudio Desktop and click on the button that says “Download RStudio Desktop”. Once the download is complete, open the file and follow the installation instructions.\n\n\n\nThere are a few packages that we will use throughout the course. You can install them by starting RStudio and running the following commands in the console (lower left panel by default):\n\npackages &lt;- c(\n        \"tidyverse\", \"learnr\", \"estimatr\",\n        \"randomizr\", \"srvyr\"\n)\ninstall.packages(packages, repos = \"http://cran.rstudio.com\")\n\nFor assignments, we’ll need to produce PDFs from R and that requires a LaTeX distribution. We recommend using tinytex to install a minimal LaTeX distribution if you haven’t already installed LaTex on your system. You can install it by running the following command in the console:\n\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex() # install TinyTeX"
  },
  {
    "objectID": "resources/r_setup.html#installing-required-r-packages",
    "href": "resources/r_setup.html#installing-required-r-packages",
    "title": "Setting up R and RStudio",
    "section": "",
    "text": "There are a few packages that we will use throughout the course. You can install them by starting RStudio and running the following commands in the console (lower left panel by default):\n\npackages &lt;- c(\n        \"tidyverse\", \"learnr\", \"estimatr\",\n        \"randomizr\", \"srvyr\"\n)\ninstall.packages(packages, repos = \"http://cran.rstudio.com\")\n\nFor assignments, we’ll need to produce PDFs from R and that requires a LaTeX distribution. We recommend using tinytex to install a minimal LaTeX distribution if you haven’t already installed LaTex on your system. You can install it by running the following command in the console:\n\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex() # install TinyTeX"
  },
  {
    "objectID": "materials/week_8.html",
    "href": "materials/week_8.html",
    "title": "Week 8",
    "section": "",
    "text": "Arechar et al (2023): link\nGerber and Green, pgs. 95-105"
  },
  {
    "objectID": "materials/week_8.html#readings",
    "href": "materials/week_8.html#readings",
    "title": "Week 8",
    "section": "",
    "text": "Arechar et al (2023): link\nGerber and Green, pgs. 95-105"
  },
  {
    "objectID": "materials/week_8.html#slides",
    "href": "materials/week_8.html#slides",
    "title": "Week 8",
    "section": "Slides",
    "text": "Slides\n\nLecture 12 (4/4): Linear Models"
  },
  {
    "objectID": "materials/week_3.html",
    "href": "materials/week_3.html",
    "title": "Week 3: Intergroup Prejudice",
    "section": "",
    "text": "Mousa (2020): Perusall link, direct link\n\nOptional: Scope Conditions Podcast Episode - The Promise and Limits of Intergroup Contact, with Salma Mousa, link\n\nGreen and Gerber (2012), pgs. 30-45: Perusall link\nRDS: Chapter 1, Chapter 3"
  },
  {
    "objectID": "materials/week_3.html#readings",
    "href": "materials/week_3.html#readings",
    "title": "Week 3: Intergroup Prejudice",
    "section": "",
    "text": "Mousa (2020): Perusall link, direct link\n\nOptional: Scope Conditions Podcast Episode - The Promise and Limits of Intergroup Contact, with Salma Mousa, link\n\nGreen and Gerber (2012), pgs. 30-45: Perusall link\nRDS: Chapter 1, Chapter 3"
  },
  {
    "objectID": "materials/week_3.html#slides",
    "href": "materials/week_3.html#slides",
    "title": "Week 3: Intergroup Prejudice",
    "section": "Slides",
    "text": "Slides\n\nIntergroup Contact and Data Visualization"
  },
  {
    "objectID": "materials/week_3.html#class-exercises",
    "href": "materials/week_3.html#class-exercises",
    "title": "Week 3: Intergroup Prejudice",
    "section": "Class Exercises",
    "text": "Class Exercises\n\nIntergroup Contact"
  },
  {
    "objectID": "materials/week_3.html#assignments",
    "href": "materials/week_3.html#assignments",
    "title": "Week 3: Intergroup Prejudice",
    "section": "Assignments",
    "text": "Assignments\n\nProblem Set 1: qmd link\nTutorial 2"
  },
  {
    "objectID": "materials/week_6.html",
    "href": "materials/week_6.html",
    "title": "Week 6: Combatting Electoral Fraud",
    "section": "",
    "text": "Garbiras-Díaz and Montenegro (2016): link\nGerber and Green (2012), pgs 71-80"
  },
  {
    "objectID": "materials/week_6.html#readings",
    "href": "materials/week_6.html#readings",
    "title": "Week 6: Combatting Electoral Fraud",
    "section": "",
    "text": "Garbiras-Díaz and Montenegro (2016): link\nGerber and Green (2012), pgs 71-80"
  },
  {
    "objectID": "materials/week_6.html#slides",
    "href": "materials/week_6.html#slides",
    "title": "Week 6: Combatting Electoral Fraud",
    "section": "Slides",
    "text": "Slides\n\nLecture 7 (3/7): Measurement\nLecture 8 (3/12): More on Inference in Experiments\nLecture 9 (3/14): Electoral Malfeasance"
  },
  {
    "objectID": "materials/week_6.html#assignments",
    "href": "materials/week_6.html#assignments",
    "title": "Week 6: Combatting Electoral Fraud",
    "section": "Assignments",
    "text": "Assignments\n\nReading Quiz\nProblem Set 3: qmd link, html version\nTutorial 3: Pivoting and Logical Functions"
  },
  {
    "objectID": "materials/week_5.html",
    "href": "materials/week_5.html",
    "title": "Week 5: Persuasion and Measurement",
    "section": "",
    "text": "Broockman and Kalla (2016): link\nStantcheva (2023): link"
  },
  {
    "objectID": "materials/week_5.html#readings",
    "href": "materials/week_5.html#readings",
    "title": "Week 5: Persuasion and Measurement",
    "section": "",
    "text": "Broockman and Kalla (2016): link\nStantcheva (2023): link"
  },
  {
    "objectID": "materials/week_5.html#slides",
    "href": "materials/week_5.html#slides",
    "title": "Week 5: Persuasion and Measurement",
    "section": "Slides",
    "text": "Slides\n\nLecture 6 (3/5): Inference\nLecture 7 (3/7): Measurement"
  },
  {
    "objectID": "materials/week_5.html#assignments",
    "href": "materials/week_5.html#assignments",
    "title": "Week 5: Persuasion and Measurement",
    "section": "Assignments",
    "text": "Assignments\n\nProblem Set 2: qmd link\nReading Quiz"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Tutorial 1: Introduction to R and Data Visualization\nTutorial 2: Data Wrangling\nTutorial 3: Pivoting and Logical Functions\nTutorial 4: Tidying Data, Joining Data, and Linear Models"
  },
  {
    "objectID": "assignments.html#tutorials",
    "href": "assignments.html#tutorials",
    "title": "Assignments",
    "section": "",
    "text": "Tutorial 1: Introduction to R and Data Visualization\nTutorial 2: Data Wrangling\nTutorial 3: Pivoting and Logical Functions\nTutorial 4: Tidying Data, Joining Data, and Linear Models"
  },
  {
    "objectID": "assignments.html#problem-sets",
    "href": "assignments.html#problem-sets",
    "title": "Assignments",
    "section": "Problem Sets",
    "text": "Problem Sets\n\nProblem Set 1: qmd link\nProblem Set 2: qmd link\nProblem Set 3: qmd link, html version"
  },
  {
    "objectID": "psets/pset4.html#instructions",
    "href": "psets/pset4.html#instructions",
    "title": "Problem Set 4",
    "section": "Instructions",
    "text": "Instructions\nPlease submit this assignment on Gradescope by April 11. The .qmd file can be submitted at the following link: https://www.dropbox.com/request/KQSmAJiTwmh5nijFo9Fk\nYou will need to submit the following two files:\n\nAn .qmd file (or “Quarto file” when spoken) that is a plain-text file that contains the text of your write-up and the code used to do all of the calculations for the assignment. You can write directly into this file in RStudio.\nAn output .pdf file that contains the compiled version of the qmd file. You can create this file by clicking the “Render” button in RStudio."
  },
  {
    "objectID": "psets/pset4.html#importing-the-data",
    "href": "psets/pset4.html#importing-the-data",
    "title": "Problem Set 4",
    "section": "Importing the data",
    "text": "Importing the data\n\n# Problem 1 Data\ngreen_df &lt;- readr::read_csv(\"https://www.dropbox.com/scl/fi/8hu4hb4l7qu85zj8soxp0/green_df.csv?rlkey=moi2dowgxazltngrawif87aza&dl=1\",\n    show_col_types = FALSE)\n\n# Problem 2 Data\nbias_df &lt;- readr::read_csv(\"https://www.dropbox.com/scl/fi/munhzfvhmfry10wl8t7y5/bias_df.csv?rlkey=xtebs0iazk80lmaznkytb8dfg&dl=1\",\n    show_col_types = FALSE)"
  },
  {
    "objectID": "psets/pset4.html#problem-1",
    "href": "psets/pset4.html#problem-1",
    "title": "Problem Set 4",
    "section": "Problem 1",
    "text": "Problem 1\nIn this first problem, we will analyze data from the following paper:\n\nGreen, Donald P., Anna M. Wilke, and Jasper Cooper. “Countering Violence Against Women by Encouraging Disclosure: A Mass Media Experiment in Rural Uganda” Comparative Political Studies (2020): 2283-2320. https://doi.org/10.1177/001041402091227\n\nGreen et al. (2020) conduct a field experiment in rural Uganda to test the effect of a media campaign on attitudes toward violence against women (VAW) and people’s willingness to report these incidents to authorities. In this field experiment, the treatment involved exposing people in Uganda to video vignettes. The treatment group received an anti-VAW vignette, while the control received a placebo that was a Hollywood movie. The treatment and control conditions were administered through village-wide screenings of the videos.\nThe authors used both cluster randomization and blocking when designing the experiment. Due to the nature of the treatment (ie a village-wide screening), randomization was done at the village level. In total, the researchers selected 112 villages. Within each village, the researchers then randomly sampled individuals to participate in the study. Prior to randomization, the researchers split the villages up into 16 blocks of seven villages to minimize imbalance on geographic factors. We will explore the results of this study.\nThe green_df data includes the following variables:\n\ncluster_id: A unique identifier for each cluster (village)\nblock_id: A unique identifier for each block\ntreat: A binary variable indicating treatment status (1 = treatment, 0 = control)\nintervene_index: A continuous variable measuring the intervention’s effect on willingness to report VAW incidents to authorities. Higher values indicate more willingness to report\n\nFor this problem set, the data is subset to only include female respondents.\n\nProblem 1(a)\nTo start, we are going to ignore the clustering in the data and only focus on the blocks. First, calculate the average treatment effect of the video vignette on willingness to report VAW incidents while incorporating the blocked randomization.\n\n# Your code here\n\nNext, state the sharp null and alternative hypotheses. Conduct a permutation test and plot the null distribution with your observed estimate overlaid. Calculate a p-value for the test. When doing this, make sure to incorporate the blocks in the analysis. Does the intervention have a statistically significant effect on willingness to report VAW incidents?\n\n# Your code here\n\n\n\nProblem 1(b)\nNow we are going to ignore the block randomization and only focus on the clusters in the data. First, calculate the average treatment effect of the video vignette on willingness to report VAW incidents while incorporating the clustered randomization.\n\n# Your code here\n\nNext, conduct a permutation test and plot the null distribution with your observed estimate overlaid. Calculate a p-value for the test. When doing this, make sure to incorporate the clusters in the analysis. How does it compare to the p-value you calculated in Problem 1(a)?\n\n# Your code here\n\n\n\nProblem 1(c)\nFinally, we are going to incorporate both the cluster and block randomization in the data. First, calculate the average treatment effect of the video vignette on willingness to report VAW incidents while incorporating the complete randomization scheme.\n\n# Your code here\n\nNext, conduct a permutation test and plot the null distribution with your observed estimate overlaid. Calculate a p-value for the test. When doing this, make sure to incorporate both the clusters and blocks in the analysis. Interpret the results. What do these results tell us about the effectiveness of the experimental intervention?\n\n# Your code here"
  },
  {
    "objectID": "psets/pset4.html#problem-2",
    "href": "psets/pset4.html#problem-2",
    "title": "Problem Set 4",
    "section": "Problem 2",
    "text": "Problem 2\nIn this second problem, we will analyze data from another paper:\n\nYair, Omer and Gregory A. Huber. “How Robust is Evidence of Partisan Perceptual Bias in Survey Responses? A New Approach for Studying Expressive Responding” Public Opinion Quarterly (2020): 469-492. https://doi:10.1093/poq/nfaa024.\n\nIn this paper, the authors explore the extent to which partisan biases affect survey responses. Existing work on partisan biases finds evidence that these biases can impact seemingly unrelated evaluations. For example, the authors cite a study on the relationship between partisanship and perceptions of attractiveness. In the original study by Nicholson et al (2016), the authors find that partisanship impacts evaluations of physical attractiveness. Yair and Huber are skeptical of this finding, arguing that the results are likely evidence of expressive responding. In other words, people are not actually changing their evaluations of attractiveness based on partisanship, but instead are expressing their partisanship in their responses.\nTo get around this concern, Yair and Huber introduce a new measurement strategy that allows respondents to “blow off the steam” of their partisanship. They replicate the initial study on attractiveness but introduce new conditions. In this design, respondents are presented with an image of a person of the opposite sex. Below the image, there is basic non-political information about the person (control). In the treatment conditions, there is also information about whether the person is a Democrat or a Republican. Respondents are then asked to rate how attractive the person is. Yair and Huber add two additional treatment arms. In addition to the replication of the original study, they include a condition where respondents are asked a question about the values of the person shown to them (“blowing off steam”) and a condition where respondents are told they they will evaluate both the person’s attractiveness and values (“warning”). The goal of both of these treatment arms is to provide respondents with alternative pathways to express their partisanship other than the attractiveness rating.\nIn this question we will explore the results of Yair and Huber’s study. We will use the bias_df data frame. The data includes the following variables:\n\npid: A binary variable indicating partisanship (1 = Democrat, 0 = Republican)\npid_profile_match: A binary variable indicating whether the respondent’s partisanship matches the partisanship of the person in the image (1 = match, 0 = mismatch)\npid_profile_mismatch: A binary variable indicating whether the respondent’s partisanship does not match the partisanship of the person in the image (1 = mismatch, 0 = match)\ntreat: A factor variable indicating the respondents’ were in the control condition or received either the “blowing of steam” or “warning” treatment\noutcome_pooled: A continuous variable measuring the attractiveness rating of the person in the image. The variable ranges from -3 to 3\nmatchXtreat: A binary variable indicating whether the respondent’s partisanship matches the partisanship of the person in the image and they recieved either of the treatments\nmismatchXtreat: A binary variable indicating whether the respondent’s partisanship does not match the partisanship of the person in the image and they recieved either of the treatments\n\n\nProblem 2(a)\nWe are going to start by producing an estimate of partisan bias without accounting for expressive responding. To do this, Yair and Huber use the following linear model to estimate the effect of exposure to a matched and mismatched profile on attractiveness ratings:\nYair and Huber state that the estimate of partisan bias is the difference between the coefficient for the mismatch condition (\\(\\beta_2\\)) and the match condition (\\(\\beta_1\\)). Use a linear model to estimate the effect of exposure to both a matched and mismatched profile on attractiveness ratings. Present your results clearly in a table. Using the results of the model, calculate the level of partisan bias in the evaluations. Make sure to subset the data so that you are only including respondents in the control condition as we are not yet incorporating the conditions to reduce expressive responding. What do the results tell us about partisan bias?\n\n# Your code here\n\nNext, we want to evaluate whether this partisan bias is drive by either of the two parties. Subset the data by partisanship and run the regressions again. Present the results in a table. Do we see a difference in partisan bias between the parties?\n\n# Your code here\n\n\n\nProblem 2(b)\nNow we want to evaluate whether the authors’ proposed interventions work. Remember, the authors added two conditions that provided respondents with alternative pathways to express their partisanship. For this analysis, both conditions are combined. The authors use the following linear model to estimate the effect of the pooled treatment on perceptions of attractiveness:\nYair and Huber state that this model allows them to compare estimates of partisan bias in the control conditions and either treatment condition. The baseline estimate of partisan bias is calculated the same way as above (\\(\\beta_2\\) - \\(\\beta_1\\)). This model also allows the authors to calculate partisan bias in either of the treatment conditions (\\(\\beta_4\\) - \\(\\beta_3\\)). Run this model and present the results in a table. Compare the estimates of partisan bias between the baseline and the treatment conditions. What do the results tell us about the effectiveness of the interventions?\n\n# Your code here\n\nJust as we saw that the partisan bias may be driven by a specific party, we may also want to evaluate the results of the intervention by party identification. Subset the data by partisanship and run the regressions again. Present the results in a table. Do we see a difference in the effect of the intervention between the parties?\n\n# Your code here"
  },
  {
    "objectID": "psets/pset3.html#instructions",
    "href": "psets/pset3.html#instructions",
    "title": "Problem Set 3",
    "section": "Instructions",
    "text": "Instructions\nPlease submit this assignment on Gradescope by March 21. The qmd file can be submitted at the following link: https://www.dropbox.com/request/RUZLaoI90Au4X1PgZoke\nYou will need to submit the following two files:\n\nAn .qmd file (or “Quarto file” when spoken) that is a plain-text file that contains the text of your write-up and the code used to do all of the calculations for the assignment. You can write directly into this file in RStudio.\nAn output .pdf file that contains the compiled version of the qmd file. You can create this file by clicking the “Render” button in RStudio."
  },
  {
    "objectID": "psets/pset3.html#importing-the-data",
    "href": "psets/pset3.html#importing-the-data",
    "title": "Problem Set 3",
    "section": "Importing the data",
    "text": "Importing the data\n\n# List Experiment Data\nlist_df &lt;- read_csv(\"https://www.dropbox.com/scl/fi/4cvtv58iat4cxqhbzqer0/list_df.csv?rlkey=rlog3wltunaymbe64xry55w6t&dl=1\", show_col_types = FALSE)\n\n# Attitude Change Data\nattitude_df &lt;- read_csv(\"https://www.dropbox.com/scl/fi/6zvwstark6auyfhufpceu/attitude_df.csv?rlkey=hlre5njsc5jhifbgi2bpxlipj&dl=1\", show_col_types = FALSE)"
  },
  {
    "objectID": "psets/pset3.html#problem-1",
    "href": "psets/pset3.html#problem-1",
    "title": "Problem Set 3",
    "section": "Problem 1",
    "text": "Problem 1\nIn this first problem, we will analyze data from the following paper:\n\nAronow, Peter M. et al. “COMBINING LIST EXPERIMENTAND DIRECT QUESTION ESTIMATES OF SENSITIVE BEHAVIOR PREVALENCE” Journal of Survey Statistics and Methodology(2015): 43-66. https://doi:10.1093/jssam/smu023.\n\nAronow et al. (2015) explore the use of list experiments to estimate the prevalence of sensitive behaviors and compare those estimates to direct questions. In the paper, they compare estimates using these two measurement strategies for a variety of topics. We will look at the following two topics:\n\nOpposition to Muslim public school teachers\nWhether someone watches CNN\n\nThe list_df data includes the following variables:\n\nmuslim_list_treat and cnn_list_treat: treatment indicators for the two experiments\nmuslim_list_N and cnn_list_N: the number of items in the list counted by respondent\nmuslims_direct and cnn_direct: direct question responses where 1 = yes and 0 = no.\n\n\nProblem 1(a)\nExplain the intuition behind the list experiment design and how it can be used to estimate the prevalence of sensitive attitudes. What are the pros and cons of this approach? Think about the two issues we are focusing on here, why might the researchers have chosen to use a list experiment?\n\n\nProblem 1(b)\nUsing list_df, calculate the direct and indirect attitude estimates for each of the two behaviors. Additionally, calculate 95% confidence intervals for each of the estimates using a bootstrap. Plot your results.\n\n\n\n\n\n\nTip\n\n\n\nAt the start of your code chunk, please include set.seed(1234). This allows for the results that rely on random sampling (i.e.a bootstrap) to be reproducible.\n\n\n\n# Your code here\n\n\n\nProblem 1(c)\nNow interpret the results from your plot:\n\nHow do the estimates from the list experiment compare to the direct question estimates? What do you think might explain the differences between the two estimates?\nWhat about the uncertainty estimates? Interpret the confidence intervals and compare them between estimates.\n\n\n\nProblem 1(d)\nWhat might these results tell us about the trade-offs between the two measurement strategies? Think about both the point estimates and the uncertainty estimates."
  },
  {
    "objectID": "psets/pset3.html#problem-2",
    "href": "psets/pset3.html#problem-2",
    "title": "Problem Set 3",
    "section": "Problem 2",
    "text": "Problem 2\nIn this second problem, we will analyze data from another paper:\n\nGraham, Mathew H. and Alexander Coppock. “ASKING ABOUT ATTITUDE CHANGE” Public Opinion Quarterly(2021): 28-53. https://doi:10.1093/poq/nfab009.\n\nGraham and Coppock (2021) critique a widely used method for measuring attitude change in surveys. Social scientists or survey researchers are often interested in how new information may or may not change attitudes. One way to test this involves using what Graham and Coppock call a change format question. These questions often take the following structure:\n\n\n\n\n\n\nExample 1: President Obama issued an executive order banning the CIA and other government organizations from torturing detainees.\nHow does this change your support for banning the CIA and other government organizations from torturing detainees? Less supportive, no difference, more supportive\n\n\n\n\n\n\n\n\n\nExample 2: President Trump issues an executive order that reduced restrictions on coal ash disposal.\nHow does this change your support for strict regulations on the disposal of coal ash, the pollutant left over after power plants burn coal? Less supportive, no difference, more supportive\n\n\n\nThis strategy essentially asks respondents to evaluate the causal effect of new information on their attitudes. Graham and Coppock argue that this strategy produces inflated estimates of attitude change. As an alternative, they propose a counterfactual format. This proposed question format has the following structure:\n\n\n\n\n\n\nPart 1: President Obama issued an executive order banning the CIA and other government organizations from torturing detainees.\nDo you support or oppose banning the CIA and other government organizations from torturing detainees? Oppose, Support\nPart 2: Imagine that you did not know that President Obama issued an executive order banning the CIA and other government organizations from torturing detainees.\nHow could you have answered the question: Do you support or oppose banning the CIA and other government organizations from torturing detainees? Oppose, support\n\n\n\nThis alternative method involves two steps: first respondents are reminded of the new information and asked to report their attitude as in the standard survey question. Second, respondents are then asked to imagine how they would have responded had they not known the new information.\n\nProblem 2(a)\nCritically evaluate these two question formats. What are some possible issues with the change question? How does the counterfactual format improve on these issues? Are there any downsides or remaining problems with the counterfactual format?\n\n\nProblem 2(b)\nFor this question we will use the attitude_df data frame. This data includes the following variables:\n\nParty: Respondent party identification\nFormat : The question format used to measure attitude change (Change or Counterfactual)\ntreat: Treatment indicator for the Counterfactual format\nYC: Combined outcome variable for both question formats\nY: Outcome variable for the first stage of the Counterfactual format\ntau_i_tilde: Individual level treatment effect of the Counterfactual format\n\nWe are going to compare the effectiveness of the two question formats in measuring attitude change. To do this, we will be using one of the experiments conducted by Graham and Coppock focused on the confirmation hearings of Supreme Court Justice Brett Kavanaugh. Respondents were told whether or not their Senator opposed Kavanaugh and then asked how that information changes the likelihood of supporting the Senator. To start, plot the distribution of responses in both the Change and the Counterfactual formats by Party ID. Figure 5 in the paper can be a useful guide for this plot.\n\n# Your code here\n\n\n\nProblem 2(c)\nNow we are going to take advantage of how the counterfactual format is designed to compare differences in the estimates of attitude change by Party ID. Subjects shown the counterfactual format are randomly assigned to a treatment and control group. Here is the question wording for each group:\n\n\n\n\n\n\nControl\nSenator [full name], a [Democrat / Republican] from [respondent’s state], [is running for/ will be up for] re-election in [2018 / 2020/ 2022].\nWill you support [last name] or [her / his] [Republican / Democratic] opponent?\nDefinitely oppose [last name], Probably oppose, Lean toward opposing, Lean toward supporting, Probably support, Definitely support [last name]\n(New Page) ——\n[Last name] voted against Brett Kavanaugh’s nomination to the Supreme Court. Before the vote, three women accused Kavanaugh of sexual assault.\nIf you had known this information, how would you have answered the question:\nWill you support [last name] or [her / his] [Democratic / Republican] opponent?\nDefinitely oppose [last name], Probably oppose, Lean toward opposing, Lean toward supporting, Probably support, Definitely support [last name]\n\n\n\n\n\n\n\n\n\nTreatment\nSenator [full name], a [Democrat / Republican] from [respondent’s state], [is running for/ will be up for] re-election in [2018 / 2020/ 2022].\n[Last name] voted against Brett Kavanaugh’s nomination to the Supreme Court. Before the vote, three women accused Kavanaugh of sexual assault.\nWill you support [last name] or [her / his] [Democratic / Republican] opponent?\nDefinitely oppose [last name], Probably oppose, Lean toward opposing, Lean toward supporting, Probably support, Definitely support [last name]\n(New Page) ——\nImagine you did not know that [last name] voted [for / against] Kavanaugh’s confirmation to the Supreme Court after allegation of sexual assault.\nHow would you have answered the question:\nWill you support [last name] or [her / his] [Democratic / Republican] opponent?\nDefinitely oppose [last name], Probably oppose, Lean toward opposing, Lean toward supporting, Probably support, Definitely support [last name]\n\n\n\nHere is a diagram of the research design:\n\n\n\n\n\n\n\n\n\n\n\nflowchart TD\n  A[Start Survey] --&gt; B[Control]\n  B --&gt; C[Do you support a challenger to your Senator?] \n  C --&gt; D[Information about Kavanaugh vote]\n  D --&gt; E[How would you have answered this question &lt;br/&gt; if you had know this information?]\n  \n  A --&gt; F[Treatment]\n  F --&gt; G[Information about Kavanaugh vote]\n  G --&gt; H[Do you support a challenger to your Senator?] \n  H --&gt; I[Imagine you did not know that information, how &lt;br/&gt; would you have answered the question?]\n\n\n\n\n\n\n\n\n\nIn the control condition, respondents are first asked to report whether they support a challenger to their Senator (\\(Y_i(0)\\)). Next, they are presented information about how their Senator opposed Kavanaugh as well as about the allegations against Kavanaugh. They were then asked how they would have answered the initial question if they had known this information (\\(\\tilde{Y_i(1)}\\)). We call this outcome \\(\\tilde{Y_i(1)}\\) because we are asking respondents to guess at their own potential outcome under treatment. Remember, we can never truly observe both potential outcomes. This design provides a best guess.\nIn the treatment condition, respondents are presented the information about the Kavanuagh vote and are asked whether they support a challenger to their Senator (\\(Y_i(1)\\)). Next, respondents are asked to imagine they had not known about their Senators opposition and the allegations and asked how they would have answered the initial question (\\(\\tilde{Y_i(0)}\\)). Again, this is \\(\\tilde{Y_i(0)}\\) because we are asking respondents to guess at their own potential outcome under control.\nAssuming respondent’s guesses about their counterfactual attitudes are correct, then \\(\\tilde{Y_i(1)} = Y_i(1)\\) and \\(\\tilde{Y_i(0)} = Y_i(0)\\). Denoting \\(D\\) as the treatment indicator, we can calculate individual level treatment effects:\n\\[(\\tilde{\\tau_i}|D=0) = E[\\tilde{Y_i(1)} - Y_i(0)] \\] \\[(\\tilde{\\tau_i}|D=1) = E[Y_i(1) - \\tilde{Y_i(0)}]\\]\nWe can then use these individual level treatment effects to calculate the average treatment effect:\n\\[ATE_{CF} = \\frac{\\sum^N_i\\tilde{\\tau_i}}{N}\\]\nTo start, use attitude_df to calculate the difference in means for the first stage of the Counterfactual format for each party. This calculation ignores the additional information from the counterfactual guesses. In other words, here you are calculating the average difference in in support for a Senate challenger based on whether they saw information on support for Kavanaugh. To calculate this, use the variable Y in the data frame. Report the point estimates with 95% confidence intervals calculated using a bootstrap.\n\n# Your code here\n\nNow calculate the average treatment effect for each party using tau_i_tilde as the outcome variable. This calculation takes into account the full experimental design and counterfactual guesses. Report the point estimates with a 95% confidence intervals calculated using a bootstrap.\n\n# Your code here\n\nNext, calculate the difference between these two estimates. In other words, you are calculating the difference between the first-stage difference-in-means and the counterfactual average treatment effect. Report the point estimate and a 95% confidence interval calculated using a bootstrap.\n\n# Your code here\n\n\n\nProblem 2(d)\nPlot all three point estimates with 95% confidence intervals in a single plot. Interpret the results of your plot. Be sure to interpret both the point estimates and confidence intervals. Are the two estimates different? What does the difference between the estimates tell us? What do the results say about the validity of the two different question formats? Are you persuaded by Graham and Coppock’s proposed question format?\n\n# Your code here"
  },
  {
    "objectID": "psets/pset3.html#problem-3",
    "href": "psets/pset3.html#problem-3",
    "title": "Problem Set 3",
    "section": "Problem 3",
    "text": "Problem 3\nPropose a research question that would benefit from the use of one of the measurement strategies we learned in class. This can range from the racial resentment scale to a list experiment or an IAT. Explain why the measurement strategy is appropriate and preferable to alternatives. How does it connect to the concept you are interested in measuring? What are some possible trade-offs of using when this measurement strategy?"
  },
  {
    "objectID": "psets/pset3.html#problem-4-ungraded",
    "href": "psets/pset3.html#problem-4-ungraded",
    "title": "Problem Set 3",
    "section": "Problem 4 (Ungraded)",
    "text": "Problem 4 (Ungraded)\nWe are almost halfway through the semester! That means we need to start thinking about the final class project. To start brainstorming ideas, please provide two topics that you would be interesting in studying that can be studied in the context of a survey of Americans."
  },
  {
    "objectID": "materials/week_4.html",
    "href": "materials/week_4.html",
    "title": "Week 4: Partisanship and Ideology",
    "section": "",
    "text": "Barber and Pope (2019): Perusall link, direct link\n\nOptional Reading: Trump is a real world political science experiment\n\nGreen and Gerber, pgs 51-71: Perusall link"
  },
  {
    "objectID": "materials/week_4.html#readings",
    "href": "materials/week_4.html#readings",
    "title": "Week 4: Partisanship and Ideology",
    "section": "",
    "text": "Barber and Pope (2019): Perusall link, direct link\n\nOptional Reading: Trump is a real world political science experiment\n\nGreen and Gerber, pgs 51-71: Perusall link"
  },
  {
    "objectID": "materials/week_4.html#slides",
    "href": "materials/week_4.html#slides",
    "title": "Week 4: Partisanship and Ideology",
    "section": "Slides",
    "text": "Slides\n\nLecture 4 (2/27): Estimation of Causal Effects and Data Manipulation in R\nLecture 5 (2/29): Partisanship and Ideology"
  },
  {
    "objectID": "materials/week_4.html#assignments",
    "href": "materials/week_4.html#assignments",
    "title": "Week 4: Partisanship and Ideology",
    "section": "Assignments",
    "text": "Assignments\n\nProblem Set 1: qmd link\nTutorial 2"
  },
  {
    "objectID": "materials/week_7.html",
    "href": "materials/week_7.html",
    "title": "Week 7",
    "section": "",
    "text": "Garbiras-Díaz and Montenegro (2016): link\nKing, Pan, and Roberts (2014): link\nGreen and Gerber, pgs 80-85"
  },
  {
    "objectID": "materials/week_7.html#readings",
    "href": "materials/week_7.html#readings",
    "title": "Week 7",
    "section": "",
    "text": "Garbiras-Díaz and Montenegro (2016): link\nKing, Pan, and Roberts (2014): link\nGreen and Gerber, pgs 80-85"
  },
  {
    "objectID": "materials/week_7.html#slides",
    "href": "materials/week_7.html#slides",
    "title": "Week 7",
    "section": "Slides",
    "text": "Slides\n\nLecture 9 (3/14): Electoral Malfeasance\nLecture 10 (3/19): Covariates in Experimental Design\nLecture 11 (3/21): Authoritarian Politics"
  },
  {
    "objectID": "materials/week_7.html#assignments",
    "href": "materials/week_7.html#assignments",
    "title": "Week 7",
    "section": "Assignments",
    "text": "Assignments\n\nReading Quiz\nProblem Set 3: qmd link, html version\nTutorial 3: Pivoting and Logical Functions"
  },
  {
    "objectID": "materials/week_2.html",
    "href": "materials/week_2.html",
    "title": "Week 2: Intergroup Prejudice",
    "section": "",
    "text": "Mousa (2020): Perusall link, direct link\n\nOptional: Scope Conditions Podcast Episode - The Promise and Limits of Intergroup Contact, with Salma Mousa, link\n\nGreen and Gerber (2012), pgs. 30-45: Perusall link\nRDS: Chapter 1, Chapter 3"
  },
  {
    "objectID": "materials/week_2.html#readings",
    "href": "materials/week_2.html#readings",
    "title": "Week 2: Intergroup Prejudice",
    "section": "",
    "text": "Mousa (2020): Perusall link, direct link\n\nOptional: Scope Conditions Podcast Episode - The Promise and Limits of Intergroup Contact, with Salma Mousa, link\n\nGreen and Gerber (2012), pgs. 30-45: Perusall link\nRDS: Chapter 1, Chapter 3"
  },
  {
    "objectID": "materials/week_2.html#assignments",
    "href": "materials/week_2.html#assignments",
    "title": "Week 2: Intergroup Prejudice",
    "section": "Assignments",
    "text": "Assignments\n\nReading Quiz 1\nTutorial 1\nProblem Set 1: qmd link"
  },
  {
    "objectID": "materials/week_1.html",
    "href": "materials/week_1.html",
    "title": "Week 1: Course Introduction",
    "section": "",
    "text": "RDS Chapter 2\nGerber and Green, pgs. 1-30"
  },
  {
    "objectID": "materials/week_1.html#readings",
    "href": "materials/week_1.html#readings",
    "title": "Week 1: Course Introduction",
    "section": "",
    "text": "RDS Chapter 2\nGerber and Green, pgs. 1-30"
  },
  {
    "objectID": "materials/week_1.html#slides",
    "href": "materials/week_1.html#slides",
    "title": "Week 1: Course Introduction",
    "section": "Slides",
    "text": "Slides\n\n2/6: Course Introduction\n2/8: Casuality and Introduction to R"
  },
  {
    "objectID": "materials/week_1.html#class-excercises",
    "href": "materials/week_1.html#class-excercises",
    "title": "Week 1: Course Introduction",
    "section": "Class Excercises",
    "text": "Class Excercises\n\n2/8: Facebook Study\n\nR Script\nQuarto File"
  },
  {
    "objectID": "materials/week_1.html#resources",
    "href": "materials/week_1.html#resources",
    "title": "Week 1: Course Introduction",
    "section": "Resources",
    "text": "Resources\n\nInstalling R and Rstudio"
  },
  {
    "objectID": "materials/week_1.html#assignments",
    "href": "materials/week_1.html#assignments",
    "title": "Week 1: Course Introduction",
    "section": "Assignments",
    "text": "Assignments\n\nTutorial 1"
  },
  {
    "objectID": "materials/week_9.html",
    "href": "materials/week_9.html",
    "title": "Week 8",
    "section": "",
    "text": "Lecture 13 (4/9): Linear Models and Experiments\nLecture 14 (4/11): Surveys in Politics"
  },
  {
    "objectID": "materials/week_9.html#slides",
    "href": "materials/week_9.html#slides",
    "title": "Week 8",
    "section": "",
    "text": "Lecture 13 (4/9): Linear Models and Experiments\nLecture 14 (4/11): Surveys in Politics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data and Politics",
    "section": "",
    "text": "Welcome to the course website of 17.831 Data and Politics. This course is taught by F. Daniel Hidalgo at MIT in the Spring of 2024."
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Data and Politics",
    "section": "Instructor",
    "text": "Instructor\n\n F. Daniel Hidalgo\n E53-402\n dhidalgo@mit.edu"
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Data and Politics",
    "section": "Course Details",
    "text": "Course Details\n\n Tuesdays and Thursdays\n 9:30-11:00am\n 56-154"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Data and Politics",
    "section": "Contact",
    "text": "Contact\n\n Office Hours\n Piazza\n Canvas"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "F. Daniel Hidalgo\n E53-402\n dhidalgo@mit.edu\n Office Hours\n\n\n\n\n Tuesdays and Thursdays\n 9:30-11:00am\n 56-154\n Piazza"
  },
  {
    "objectID": "syllabus.html#course-objectives",
    "href": "syllabus.html#course-objectives",
    "title": "Syllabus",
    "section": "Course Objectives",
    "text": "Course Objectives\nMany of the most pressing social problems have political causes and consequences. Rather than just passively observing these problems, social scientists have developed a range of tools that involve interventions and data collection to understand and address these problems. This course will focus on two essential data-intensive tools for understanding social dynamics: experiments and surveys. Experiments allow us to understand the causal effects of policies and interventions, while surveys allow us to measure difficult-to-observe attitudes and behaviors in a population. This course will provide an introduction to the design and analysis of experiments and surveys through the lens of innovative research in political science and public policy. The course will focus on various substantive topics, including discriminatory attitudes, political participation, combatting voter fraud, and misinformation. Students will analyze actual data and design and field their survey experiment on a chosen topic.\nBy the end of this course, students will be able to:\n\nDescribe how experimental and survey methods can be used to understand pressing social problems.\nDesign surveys and experiments that are applicable to a variety of social settings.\nUse statistical principles to evaluate the quality of survey and experimental designs.\nApply statistical models to experimental and survey data.\nAnalyze data using modern statistical computing tools, in particular the statistical programming language R.\n\n\nExpectations\nIn this course, you will be expected to:\n\nComplete six problem sets.\nComplete regular reading quizzes.\nComplete eight weekly tutorials.\nParticipate in in-person and online class discussions.\nDesign and implement a survey experiment with a diverse sample.\n\n\n\nPrerequisites\nNo prerequisites will be assumed."
  },
  {
    "objectID": "syllabus.html#course-structure",
    "href": "syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nThe basic cadence of the course will be as follows, though there may be small differences depending on the week:\n\nMonday: Complete reading, watch course lectures, and complete reading quiz.\nTuesday: Class meets.\nWednesday: Complete coding tutorial, submit assignments (if due)\nThursday: Class meets; assignments are posted\n\n\nClass Lectures\nClass lectures will be a mix of traditional lectures, in-class activities, and group discussions. In addition to in-class lectures, I may occasionally post a recorded lecture. During lecture, we will often be working with data and code, so please bring a computer to class, if possible.\n\n\nTutorials\nWe will assign short weekly coding tutorials that will assess your knowledge of the class materials and prepare you for the in-class activities. Tutorials will primarily be graded based on completion and not whether the answers are correct. Tutorials will generally be due on Wednesday by 11:59pm ET.\n\n\nProblem Sets\nCompetence at the design and analysis of experiments and surveys requires practice with real world datasets and the design of simulations. For the first 2/3 of the course, I will assign problem sets that will give you the opportunity to practice the methods you learn in the course. The problem sets will often involve the creation of a simulation and/or the analysis of data from an assigned reading. In the second half of the course, substantial parts of the problem set will be devoted to the design of the class project.\nI will assign six problem sets throughout the semester. They will be due on Thursdays by 11:59pm ET. I encourage students to work in groups, but each student must submit their own assignment.\n\n\n\n\n\n\nLowest Homework Grade is Dropped\n\n\n\nWhen calculating the overall homework grade, I will drop the lowest homework grade. This is to account for unexpected events that may prevent you from completing an assignment on time.\n\n\n\n\nOnline Forum\nWe will use Piazza for class discussions. If you are having trouble with a question on a problem set or on a reading, please post your question using Piazza. I strongly encourage students to assist in answering questions as they come up. Except under unusual circumstances, it is better to post on Piazza than email me as everyone can benefit from the posted responses. I will monitor Piazza and try to answer within 24 hours. The site is: https://piazza.com/mit/spring2024/17831/home\n\n\nGrading\nThe final grade in the course will be based on the following components:\n\n\n\nCategory\nPercent of Final Grade\n\n\n\n\nCoding Tutorials\n5%\n\n\nReading Quizzes\n5%\n\n\nProblem Sets\n50%\n\n\nClass Participation\n25%\n\n\nClass Project Writeup\n15%\n\n\n\nClass participation is based on participation in class discussions, presentations, and activities, as well as participation in Piazza discussions."
  },
  {
    "objectID": "syllabus.html#class-project",
    "href": "syllabus.html#class-project",
    "title": "Syllabus",
    "section": "Class Project",
    "text": "Class Project\nFor the final project, we will collectively design and implement an experiment embedded in a short survey. In the second half of the semester, we will devote time each week to design the survey and experiment. The goal of this project is to give students experience crafting a research design and collecting real data on a question of interest. The data will be collected on US adults through a crowd-sourcing platform. While we will collectively design the survey and experiment, each student will be responsible for pre-registering their analysis, analyzing the data and writing up the results on their own.\nStudents in the class will:\n\nPropose a research question.\nDesign an intervention suitable for a survey experiment.\nWrite a questionnaire.\nDesign a sampling plan and analysis strategy sufficient for answering their research question.\nPre-register their study.\nAnalyze and write up the results of the study."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nLate Policy\nFor problem sets submitted late, we will deduct 10% of the grade for each day late. Problem sets will not be accepted more than three days after the due date. This penalty will be waived in the case of a documented medical or family emergency.\n\n\nOffice Hours and Getting Help\nI hold regular weekly office hours on Friday afternoons. Please sign up for in-person or zoom office hours at the following link: https://fantastical.app/dhidalgo/office-hours.\nIf you run into problems that you can’t solve on your own, please use the class website on Piazza to post questions. I strongly encourage students to assist in answering questions as they come up. Unless absolutely necessary, it is better to post on Piazza than email me as everyone can benefit from the posted responses. I will monitor Piazza and try to answer within 24 hours.\n\n\nAI Tools\nThe use of generative AI tools such as ChatGPT is allowed for your assignments in this class. However, a central goal of the class is to help you become independent and critical thinkers, so we discourage you from the extensive use of generative AI tools for writing code or answers to problem sets.\nIf you do use AI-generated content in your assignments, you must clearly indicate what work is yours and what part is AI-generated through proper attribution. We also ask you provide a short one-paragraph summary at the beginning of the assignment on how you used AI tools."
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Syllabus",
    "section": "Course Materials",
    "text": "Course Materials\n\nReadings\nAlmost all readings for the course are available online and linked from the course website in the schedule page or in each week’s materials page page.\nThe one exception is that you should purchase the following book:\n\n\n\n\n\n\nRequired Purchase\n\n\n\nGerber, Alan S., and Donald P. Green. Field Experiments: Design, Analysis, and Interpretation. New York London: W. W. Norton & Company, 2012.\n\n\n\n\nComputing\nWe will use R for all of the data analysis in this course. R is a free, open-source statistical programming language that is widely used in the social sciences. We will use the RStudio integrated development environment (IDE) to write and execute R code. RStudio is also free and open-source.\nYou should install R on your own computer, but to forestall any installation problems, we will provide the option to use the Posit Cloud service for the first few weeks of the course. This service allows you to run R and RStudio in your web browser. This cloud service can be resource constrained, however, so it is strongly recommended that you install R and RStudio on your own computer as soon as possible."
  },
  {
    "objectID": "syllabus.html#acknowledgements",
    "href": "syllabus.html#acknowledgements",
    "title": "Syllabus",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nPartly inspired by courses offered by Graeme Blair, Brendan Nyan, Matt Blackwell, and Andrew Heiss. Many thanks to them for sharing their materials and syllabi."
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#models-and-experiments",
    "href": "lectures/13-lm_experiments/lm_experiments.html#models-and-experiments",
    "title": "Linear Regression and Experiments",
    "section": "Models and Experiments",
    "text": "Models and Experiments\n\nOne of the benefits of randomized experiments is their simplicity:\n\nWe can estimate causal effects using simple statistics like the difference-in-means that are easily communicated.\nPermutation tests give us a way to communicate uncertainty with very few assumptions.\n\nBut we can also use more complex models to estimate causal effects because:\n\nThey can help us increase precision by accounting for more sources of variation.\nThey can be used to examine heterogeneity\nThey can be used to generate predictions\n\nRunning example: Effect of Voter Mobilization Messages in Spanish Media on Hispanic Turnout"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-binary-covariate",
    "href": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-binary-covariate",
    "title": "Linear Regression and Experiments",
    "section": "Linear Regression with a Binary Covariate",
    "text": "Linear Regression with a Binary Covariate\nTo translate the difference-in-means into a regression model, we can use a linear regression with a binary covariate:\n\\[\\texttt{hisp_to_2006}_i = \\alpha + \\beta_1 \\texttt{treatment} + \\epsilon_i\\]\n\nWhen independent variable is binary (like the treatment variable):\n\nIntercept \\(\\alpha\\) is average value of the outcome when \\(\\texttt{treatment} = 0\\).\nCoefficient \\(\\beta_1\\) is the difference in the average outcome when \\(\\texttt{treatment} = 1\\) compared to when \\(\\texttt{treatment} = 0\\); i.e., the treatment effect."
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-binary-covariate-1",
    "href": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-binary-covariate-1",
    "title": "Linear Regression and Experiments",
    "section": "Linear Regression with a Binary Covariate",
    "text": "Linear Regression with a Binary Covariate\n\nlibrary(broom)\n\nlm_hisp &lt;- lm(hisp_to_2006 ~ treatment, data = exp_data)\ntidy(lm_hisp)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    32.1       2.07     15.5  5.65e-22\n2 treatment       7.01      3.94      1.78 8.04e- 2\n\ngroup_by(exp_data, treatment) %&gt;%\n  summarize(mean_hisp = mean(hisp_to_2006))\n\n# A tibble: 2 × 2\n  treatment mean_hisp\n      &lt;dbl&gt;     &lt;dbl&gt;\n1         0      32.1\n2         1      39.2"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-categorical-variables",
    "href": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-categorical-variables",
    "title": "Linear Regression and Experiments",
    "section": "Linear Regression with a Categorical Variables",
    "text": "Linear Regression with a Categorical Variables\n\nIn this experiment, the treatment was randomized within 3 blocks.\nAs we learned earlier, one needs to “analyze as ye randomize”, which means that we need to account for the blocking in our analysis.\nWe can do this by including the block as a categorical variable in the regression model:\n\nTo include a categorical variable in a regression model, we create a set of binary variables that indicate the level of the categorical variable.\n\n\n\n\n\n\nUnit\nBlock\nHigh\nMedium\nLow\n\n\n\n\n1\nHigh\n1\n0\n0\n\n\n2\nMedium\n0\n1\n0\n\n\n3\nLow\n0\n0\n1"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-categorical-variables-1",
    "href": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-categorical-variables-1",
    "title": "Linear Regression and Experiments",
    "section": "Linear Regression with a Categorical Variables",
    "text": "Linear Regression with a Categorical Variables\nThen we include all but one of these binary variables in the regression model: \\[ \\texttt{hisp_to_2006}_i = \\alpha + \\beta_1 \\texttt{treatment} + \\beta_2 \\texttt{block}_{\\texttt{1}} + \\beta_3 \\texttt{block}_{\\texttt{2}} + \\epsilon_i\\]\n\nThe intercept \\(\\alpha\\) is the average value of the outcome when \\(\\texttt{treatment} = 0\\) and \\(\\texttt{block} = \\texttt{Low}\\).\nThe coefficient \\(\\beta_1\\) is the difference in the average outcome when \\(\\texttt{treatment} = 1\\) compared to when \\(\\texttt{treatment} = 0\\).\nThe coefficients \\(\\beta_2\\) and \\(\\beta_3\\) are the differences in the average outcome when \\(\\texttt{block} = \\texttt{High}\\) and \\(\\texttt{block} = \\texttt{Medium}\\) compared to when \\(\\texttt{block} = \\texttt{Low}\\)."
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-categorical-variables-2",
    "href": "lectures/13-lm_experiments/lm_experiments.html#linear-regression-with-a-categorical-variables-2",
    "title": "Linear Regression and Experiments",
    "section": "Linear Regression with a Categorical Variables",
    "text": "Linear Regression with a Categorical Variables\n\nlm_hisp_block &lt;- lm(hisp_to_2006 ~ treatment + block, data = exp_data)\ntidy(lm_hisp_block)\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)   32.5        4.60     7.06  0.00000000333\n2 treatment      6.26       4.06     1.54  0.129        \n3 blockLow       4.15       6.67     0.622 0.536        \n4 blockMedium   -0.957      4.98    -0.192 0.848"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#inference-with-the-bootstrap",
    "href": "lectures/13-lm_experiments/lm_experiments.html#inference-with-the-bootstrap",
    "title": "Linear Regression and Experiments",
    "section": "Inference with the Bootstrap",
    "text": "Inference with the Bootstrap\n\nWe can use the bootstrap to estimate generate confidence intervals for coefficient estimates.\nAs with the difference-in-means test, we simply resample the data with replacement and estimate the model for each resample.\nWe can then use the distribution of the coefficient estimates to generate confidence intervals."
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#population-regression",
    "href": "lectures/13-lm_experiments/lm_experiments.html#population-regression",
    "title": "Linear Regression and Experiments",
    "section": "Population Regression",
    "text": "Population Regression"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#randomly-sample-from-the-data",
    "href": "lectures/13-lm_experiments/lm_experiments.html#randomly-sample-from-the-data",
    "title": "Linear Regression and Experiments",
    "section": "Randomly Sample from the Data",
    "text": "Randomly Sample from the Data"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#randomly-sample-from-the-data-1",
    "href": "lectures/13-lm_experiments/lm_experiments.html#randomly-sample-from-the-data-1",
    "title": "Linear Regression and Experiments",
    "section": "Randomly Sample from the Data",
    "text": "Randomly Sample from the Data"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#randomly-sample-from-the-data-2",
    "href": "lectures/13-lm_experiments/lm_experiments.html#randomly-sample-from-the-data-2",
    "title": "Linear Regression and Experiments",
    "section": "Randomly Sample from the Data",
    "text": "Randomly Sample from the Data"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#bootstrap-distribution",
    "href": "lectures/13-lm_experiments/lm_experiments.html#bootstrap-distribution",
    "title": "Linear Regression and Experiments",
    "section": "Bootstrap Distribution",
    "text": "Bootstrap Distribution"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#confidence-intervals-for-treatment-effect",
    "href": "lectures/13-lm_experiments/lm_experiments.html#confidence-intervals-for-treatment-effect",
    "title": "Linear Regression and Experiments",
    "section": "Confidence Intervals for Treatment Effect",
    "text": "Confidence Intervals for Treatment Effect\n\nbs_lm &lt;- function(data) {\n  lm(hisp_to_2006 ~ treatment + block, \n     data = sample_n(data, \n                     size = nrow(data), \n                     replace = TRUE)) |&gt;\n    tidy() |&gt;\n    filter(term == \"treatment\") |&gt;\n    pull(estimate)\n}\n\nbs_lm_ci &lt;- map(1:1000, ~bs_lm(exp_data)) |&gt;\n  unlist()\n\n## Plot 95% confidence interval\nggplot() +\n  geom_histogram(aes(x = bs_lm_ci), bins = 30, alpha = 0.5) +\n  geom_vline(xintercept = c(quantile(bs_lm_ci, .025),\n                            quantile(bs_lm_ci, .975)),\n             color = \"red\")"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#confidence-intervals-for-treatment-effect-output",
    "href": "lectures/13-lm_experiments/lm_experiments.html#confidence-intervals-for-treatment-effect-output",
    "title": "Linear Regression and Experiments",
    "section": "Confidence Intervals for Treatment Effect",
    "text": "Confidence Intervals for Treatment Effect"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#increasing-precision",
    "href": "lectures/13-lm_experiments/lm_experiments.html#increasing-precision",
    "title": "Linear Regression and Experiments",
    "section": "Increasing Precision",
    "text": "Increasing Precision\n\nWe used a linear model to estimate the treatment effect, but the confidence interval is quite wide.\nHow can we use predictive modeling to increase the precision of our estimate?\n\nWe can use predictive pre-treatment covariates to remove unexplained variation in the outcome.\nThis will help us estimate the treatment effect more precisely by removing variation not related to the treatment.\n\n\n\nModel (ignoring block variables for now) with pre-treatment covariate:\n\\[ \\texttt{hisp_to_2006}_i = \\alpha + \\beta_1 \\texttt{treatment}  + \\beta_2 \\texttt{hisp_to_2002} + \\epsilon \\]"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#adjusting-for-pre-treatment-covariates",
    "href": "lectures/13-lm_experiments/lm_experiments.html#adjusting-for-pre-treatment-covariates",
    "title": "Linear Regression and Experiments",
    "section": "“Adjusting” for Pre-Treatment Covariates",
    "text": "“Adjusting” for Pre-Treatment Covariates\n\\[ \\texttt{hisp_to_2006}_i = \\alpha + \\beta_1 \\texttt{treatment}  + \\beta_2 \\texttt{hisp_to_2002} + \\epsilon \\]\n\nlm(hisp_to_2006 ~ treatment + block, data = exp_data)  |&gt;\n  tidy() |&gt;\n  filter(term == \"treatment\") \n\n# A tibble: 1 × 5\n  term      estimate std.error statistic p.value\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 treatment     6.26      4.06      1.54   0.129\n\nlm(hisp_to_2006 ~ treatment + block + hisp_to_2002, data = exp_data)  |&gt;\n  tidy() |&gt;\n  filter(term == \"treatment\") \n\n# A tibble: 1 × 5\n  term      estimate std.error statistic p.value\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 treatment     4.67      1.95      2.39  0.0203"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#adjusting-for-pre-treatment-covariates-1",
    "href": "lectures/13-lm_experiments/lm_experiments.html#adjusting-for-pre-treatment-covariates-1",
    "title": "Linear Regression and Experiments",
    "section": "Adjusting for Pre-Treatment Covariates",
    "text": "Adjusting for Pre-Treatment Covariates\n\nTwo models:\n\nShort model: \\(Y_i = \\alpha + \\beta_1 X_i + \\epsilon_i\\)\nLong model: \\(Y_i = \\alpha + \\beta_1 X_i + \\beta_2 Z_i + \\epsilon_i\\)\n\nHow \\(\\hat \\beta_1\\) in the long model differ from \\(\\hat \\beta_1\\) in the short model?\n\n\\(\\hat \\beta_1\\) in the long model is the effect of \\(X_i\\) on \\(Y_i\\) after adjusting for \\(Z_i\\).\n\nMathematically, what does it mean to “adjust” for \\(Z_i\\)? Start with two models:\n\n\n\\(X_i  = \\gamma_0 + \\gamma_1 Z_i + u_i\\) (regression of \\(X_i\\) on \\(Z_i\\))\n\\(Y_i = \\delta_0 + \\delta_1 X_i + v_i\\) (regression of \\(Y_i\\) on \\(X_i\\))"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#partialling-out",
    "href": "lectures/13-lm_experiments/lm_experiments.html#partialling-out",
    "title": "Linear Regression and Experiments",
    "section": "Partialling Out",
    "text": "Partialling Out\n\n\\(X_i  = \\gamma_0 + \\gamma_1 Z_i + u_i\\) (regression of \\(X_i\\) on \\(Z_i\\))\n\\(Y_i = \\delta_0 + \\delta_1 X_i + v_i\\) (regression of \\(Y_i\\) on \\(X_i\\))\n\n\nTo adjust for \\(Z_i\\) when estimating the effect of \\(X_i\\) on \\(Y_i\\):\n\nGet the residuals from model 1: \\(\\hat u_i = X_i - \\hat \\gamma_0 - \\hat \\gamma_1 Z_i\\) (\\(\\hat u_i\\) is the part of \\(X_i\\) that is not explained by \\(Z_i\\))\nGet the residuals from model 2: \\(\\hat v_i = Y_i - \\hat \\delta_0 - \\hat \\delta_1 X_i\\) (\\(\\hat v_i\\) is the part of \\(Y_i\\) that is not explained by \\(X_i\\))\nRegress \\(\\hat v_i\\) on \\(\\hat u_i\\) to get the effect of \\(X_i\\) on \\(Y_i\\) after adjusting for \\(Z_i\\)."
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-experiments",
    "href": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-experiments",
    "title": "Linear Regression and Experiments",
    "section": "Partialling Out in Experiments",
    "text": "Partialling Out in Experiments\n\n\\(X_i  = \\gamma_0 + \\gamma_1 Z_i + u_i\\) (regression of \\(X_i\\) on \\(Z_i\\))\n\\(Y_i = \\delta_0 + \\delta_1 X_i + v_i\\) (regression of \\(Y_i\\) on \\(X_i\\))\n\n\nIn experiments, \\(X_i\\) is the treatment, \\(Z_i\\) are pre-treatment covariates, and \\(Y_i\\) is the outcome.\nWhat should \\(\\gamma_1\\) be in the regression of \\(X_i\\) on \\(Z_i\\)?\n\n\\(\\gamma_1\\) should be zero because \\(Z_i\\) should not be related to the treatment in an experiment.\nSo in most cases, variation in \\(u_i\\) is the same as variation in \\(X_i\\).\n\n\\(v_i\\) however should be less variable than \\(Y_i\\) because it removes the part of \\(Y_i\\) that is not related to \\(X_i\\)."
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-practice",
    "href": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-practice",
    "title": "Linear Regression and Experiments",
    "section": "Partialling Out in Practice",
    "text": "Partialling Out in Practice\n\nresiduals_yz &lt;- lm(hisp_to_2006 ~ hisp_to_2002, data = exp_data) |&gt;\n  residuals()\ndemeaned_y &lt;- exp_data$hisp_to_2006 - mean(exp_data$hisp_to_2006)\n\nbind_rows(tibble(Y = demeaned_y, \n       Type = \"Unadjusted Y\"),\n          tibble(Y = residuals_yz,\n                 Type = \"Adjusted Y\")) |&gt;\n  ggplot(aes(x = Y, fill = Type)) +\n  geom_density(alpha = .5) +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-practice-output",
    "href": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-practice-output",
    "title": "Linear Regression and Experiments",
    "section": "Partialling Out in Practice",
    "text": "Partialling Out in Practice"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-practice-1",
    "href": "lectures/13-lm_experiments/lm_experiments.html#partialling-out-in-practice-1",
    "title": "Linear Regression and Experiments",
    "section": "Partialling Out in Practice",
    "text": "Partialling Out in Practice\n\nyx_resid &lt;- lm(hisp_to_2006 ~ hisp_to_2002, data = exp_data) |&gt;\n  residuals()\nxz_resid &lt;- lm(treatment ~ hisp_to_2002, data = exp_data) |&gt;\n  residuals()\n\nlm(yx_resid ~ xz_resid) |&gt;\n  tidy() |&gt;\n  filter(term == \"xz_resid\") |&gt;\n  pull(estimate)\n\n[1] 4.957391\n\nmod &lt;- lm(hisp_to_2006 ~ treatment + hisp_to_2002, data = exp_data)\ntidy(mod) |&gt;\n  filter(term == \"treatment\") |&gt;\n  pull(estimate)\n\n[1] 4.957391"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#confidence-intervals",
    "href": "lectures/13-lm_experiments/lm_experiments.html#confidence-intervals",
    "title": "Linear Regression and Experiments",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nbs_lm_adj &lt;- function(data) {\n  lm(hisp_to_2006 ~ treatment + block + hisp_to_2002,\n     data = sample_n(data, \n                     size = nrow(data), \n                     replace = TRUE)) |&gt;\n    tidy() |&gt;\n    filter(term == \"treatment\") |&gt;\n    pull(estimate)\n}\n\nbs_lm_adj_ci &lt;- map(1:1000, ~bs_lm_adj(exp_data)) |&gt;\n  unlist()\n\n##Unadjusted Confidence Intervals\nquantile(bs_lm_ci, c(.025, .975))\n\n     2.5%     97.5% \n-1.401392 13.482128 \n\n## Adjusted Confidence Intervals\nquantile(bs_lm_adj_ci, c(.025, .975))\n\n     2.5%     97.5% \n0.4214788 9.0160956"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment",
    "href": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment",
    "title": "Linear Regression and Experiments",
    "section": "Alternative Perspective on Covariate Adjustment",
    "text": "Alternative Perspective on Covariate Adjustment"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-1",
    "href": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-1",
    "title": "Linear Regression and Experiments",
    "section": "Alternative Perspective on Covariate Adjustment",
    "text": "Alternative Perspective on Covariate Adjustment"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-2",
    "href": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-2",
    "title": "Linear Regression and Experiments",
    "section": "Alternative Perspective on Covariate Adjustment",
    "text": "Alternative Perspective on Covariate Adjustment"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-3",
    "href": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-3",
    "title": "Linear Regression and Experiments",
    "section": "Alternative Perspective on Covariate Adjustment",
    "text": "Alternative Perspective on Covariate Adjustment"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-4",
    "href": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-4",
    "title": "Linear Regression and Experiments",
    "section": "Alternative Perspective on Covariate Adjustment",
    "text": "Alternative Perspective on Covariate Adjustment"
  },
  {
    "objectID": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-5",
    "href": "lectures/13-lm_experiments/lm_experiments.html#alternative-perspective-on-covariate-adjustment-5",
    "title": "Linear Regression and Experiments",
    "section": "Alternative Perspective on Covariate Adjustment",
    "text": "Alternative Perspective on Covariate Adjustment"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#censorship-and-authoritarian-control",
    "href": "lectures/11-censorship/censorship.html#censorship-and-authoritarian-control",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Censorship and Authoritarian Control",
    "text": "Censorship and Authoritarian Control\n\nWhat is the goal of censorship?\n\nStop criticism\nStop collective action\nChange public opinion\n\nMany predicted that internet would make censorship impossible.\n\nBut it has not.\nWhy not?"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#censorship-patterns",
    "href": "lectures/11-censorship/censorship.html#censorship-patterns",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Censorship Patterns",
    "text": "Censorship Patterns"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#censorship-of-positive-comments",
    "href": "lectures/11-censorship/censorship.html#censorship-of-positive-comments",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Censorship of Positive Comments",
    "text": "Censorship of Positive Comments"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#chinese-censorship-decision-tree",
    "href": "lectures/11-censorship/censorship.html#chinese-censorship-decision-tree",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Chinese Censorship Decision Tree",
    "text": "Chinese Censorship Decision Tree"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#experimental-design",
    "href": "lectures/11-censorship/censorship.html#experimental-design",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Experimental Design",
    "text": "Experimental Design\n\n\n\n\n\nTop 100 social media sites in China\n\n2 accounts on each site\n\nWrite 1,200 unique social media posts\n\nCollective action vs not Collective action\nPro vs anti-government\n\nMeasure censorship"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#collective-action-events",
    "href": "lectures/11-censorship/censorship.html#collective-action-events",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Collective Action Events",
    "text": "Collective Action Events\n\nTibetan Self-immolation:\n\n\nPro-government posts attribute the tragedy of her death on the Dalai Lama who is instigating these tragedies.\nAnti-government posts attribube her death to government policies.\n\n\nProtest in Panxu village over illegal land seizure:\n\n\nPro-government posts say that this sort of protest and violence is wrong and that the villagers are greedy and want money.\nAnti-government posts say the local officials are unfair to the villagers."
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#other-events",
    "href": "lectures/11-censorship/censorship.html#other-events",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Other Events",
    "text": "Other Events\n\nCorruption Policy: new policy that bribes over 10,000 Chinese yuan will be subject to criminal investigation and penalties\n\n\nPro-government posts support this policy because it will reduce corruption\nAnti-government posts believe this policy is punishing those who give bribes but the real fault lies with officials who accept bribes and not those who are forced by the system to give bribes in order to get things done.\n\n\nRental tax: several cities in China are piloting taxes for renting housing\n\n\nPro-government posts support the rental tax because it is income that should be taxed, just as income from salaries and wages are taxed.\nAnti-government posts criticize the tax saying it will increase already high rental taxes as landlords will push the tax onto renters."
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#randomization",
    "href": "lectures/11-censorship/censorship.html#randomization",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Randomization",
    "text": "Randomization\nBlocked on combination of 3 variables:\n\nKeywords\nIndividual writer\nLength\n\n\nRandomized:\n\nCollective Action vs Not\nPro-government vs anti-government"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#criticism-of-government-and-censorship",
    "href": "lectures/11-censorship/censorship.html#criticism-of-government-and-censorship",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Criticism of Government and Censorship",
    "text": "Criticism of Government and Censorship"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#collective-action-and-censorship",
    "href": "lectures/11-censorship/censorship.html#collective-action-and-censorship",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Collective Action and Censorship",
    "text": "Collective Action and Censorship"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#chen-pan-and-xu-2015",
    "href": "lectures/11-censorship/censorship.html#chen-pan-and-xu-2015",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Chen, Pan, and Xu (2015)",
    "text": "Chen, Pan, and Xu (2015)\nQuestion: What makes officials in an authoritarian regime more responsive?\nRandomize appeals for help getting access to welfare program on county government help forums\nControl group:\n\nMy wife and I have lost our jobs, and we have been unable to find work for a long time. Our economic situation is very difficult, and we cannot make ends meet. We have to support my elderly mother who is ill and for whom we have to buy medicine. We also have our son who is in school and has school fees and living fees that are difficult to bear. I have tried to apply for Dibao through my residential committee, but they say I am not eligible."
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#chen-pan-and-xu-2015-1",
    "href": "lectures/11-censorship/censorship.html#chen-pan-and-xu-2015-1",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Chen, Pan, and Xu (2015)",
    "text": "Chen, Pan, and Xu (2015)\nTreatment Conditions:\n\nCollective Action: “People around me are in a similar situation, they face difficulties, and they also can’t get Dibao. If you can’t help, we’ll try to figure out what we can do together about this situation.”\nTattling: “If this problem cannot be addressed, I’ll have to report it to upper-level government officials.”\nLoyalty: “I’m a long-standing CCP member, I’ve always followed the leadership of the Party.”"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#chen-et-al-results",
    "href": "lectures/11-censorship/censorship.html#chen-et-al-results",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Chen et al Results",
    "text": "Chen et al Results"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#chen-and-yang-2019",
    "href": "lectures/11-censorship/censorship.html#chen-and-yang-2019",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Chen and Yang (2019)",
    "text": "Chen and Yang (2019)\nQuestions:\n\nWhat is the effect of censorship on knowledge and political attitudes?\nIs their demand for uncensored content?\n\n\nExperimental Design:\n\nSample: 1800 Beijing university students\nRandomize\n\nfree VPN access\nEncouragement and incentives to visit foreign news websites\n\nMeasure:\n\nwebsite visits, continued use of VPN after incentive ends\nknowledge and attitudes"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#experimental-design-1",
    "href": "lectures/11-censorship/censorship.html#experimental-design-1",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Experimental Design",
    "text": "Experimental Design"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#usage-of-ny-times-chinese-version",
    "href": "lectures/11-censorship/censorship.html#usage-of-ny-times-chinese-version",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Usage of NY Times (Chinese Version)",
    "text": "Usage of NY Times (Chinese Version)"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#demand-for-uncensored-content",
    "href": "lectures/11-censorship/censorship.html#demand-for-uncensored-content",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Demand for Uncensored Content",
    "text": "Demand for Uncensored Content"
  },
  {
    "objectID": "lectures/11-censorship/censorship.html#effects-on-attitudes",
    "href": "lectures/11-censorship/censorship.html#effects-on-attitudes",
    "title": "Censorship in Authoritarian Regimes",
    "section": "Effects on Attitudes",
    "text": "Effects on Attitudes"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#the-survey-life-cycle",
    "href": "lectures/14-surveys/surveys.html#the-survey-life-cycle",
    "title": "Surveys in Politics",
    "section": "The Survey Life Cycle",
    "text": "The Survey Life Cycle\n\nGroves et al. (2009)"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#sources-of-error-in-surveys",
    "href": "lectures/14-surveys/surveys.html#sources-of-error-in-surveys",
    "title": "Surveys in Politics",
    "section": "Sources of Error in Surveys",
    "text": "Sources of Error in Surveys"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#sources-of-error-in-surveys-1",
    "href": "lectures/14-surveys/surveys.html#sources-of-error-in-surveys-1",
    "title": "Surveys in Politics",
    "section": "Sources of Error in Surveys",
    "text": "Sources of Error in Surveys"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#measurement-error-1",
    "href": "lectures/14-surveys/surveys.html#measurement-error-1",
    "title": "Surveys in Politics",
    "section": "Measurement Error",
    "text": "Measurement Error\nKey Point: survey responses are subject to considerable error\n\nFor example, think about the process of answering the following two questions:\n\n\n\nOn average, during the last 6 months, that is, since ______, how often have YOU gone shopping? For example, at drug, clothing, grocery, hardware, and convenience stores?\n\n\nNow turning to business conditions in the country as a whole, do you think that the next 12 months we’ll have good times financially, or bad times, or what?"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#case-study-education",
    "href": "lectures/14-surveys/surveys.html#case-study-education",
    "title": "Surveys in Politics",
    "section": "Case study: Education",
    "text": "Case study: Education\nLet’s think about a very simple and straightforward survey question:\n\nWhat is the highest level of education you have completed? (1) No HS (2) High school graduate (3) Some college (4) 2-year (5) 4-year (6) Post-grad\n\nOne might expect low error rates on something like this, but let’s examine how people answer this question two years apart:\n\ncces &lt;- read_csv(\"cces_1012_panel.csv.gz\", show_col_types = FALSE)\ntable(cces$educ_10, cces$educ_12)\n\n                      \n                       2-year 4-year High school graduate No HS Post-grad\n  2-year                 1350    115                    8     0         5\n  4-year                  235   5204                    6     2       198\n  High school graduate     24     10                 3503    51         1\n  No HS                     1      0                   42   184         2\n  Post-grad                 1    113                    6     1      2334\n  Some college            444    184                  248     6        10\n                      \n                       Some college\n  2-year                        150\n  4-year                         90\n  High school graduate          223\n  No HS                          20\n  Post-grad                      10\n  Some college                 4219"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#problems-with-survey-questions",
    "href": "lectures/14-surveys/surveys.html#problems-with-survey-questions",
    "title": "Surveys in Politics",
    "section": "Problems with Survey Questions",
    "text": "Problems with Survey Questions\n\n\n\nUnclear questions or excessive complexity\nForgetting:\nFlawed estimation (over and under-reporting)\nProblems in formatting an answer (open ended, close ended with ordered response scales, categorical responses)\nDeliberate misreporting, i.e. partisan cheerleading"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#partisan-cheerleading",
    "href": "lectures/14-surveys/surveys.html#partisan-cheerleading",
    "title": "Surveys in Politics",
    "section": "Partisan Cheerleading",
    "text": "Partisan Cheerleading"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#non-citizen-voting",
    "href": "lectures/14-surveys/surveys.html#non-citizen-voting",
    "title": "Surveys in Politics",
    "section": "Non-Citizen Voting?",
    "text": "Non-Citizen Voting?\n\nPaper by Richman, Chattha, and Earnest (2014) use 2008 and 2010 Cooperative Congressional Election Studies (CCES) survey to study the prevalence of non-citizen voting.\nCCES have large samples: 32k in 2008 and 55k in 2010.\nIncludes question about citizenship and turnout, which is checked against the voter file in most states.\nClaims that 11% of non-citizens voted\nUsing these estimates and accounting for sampling error, Richman et al estimate that in 2010 between 38,000 and 2.8 million non-citizens voted."
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#non-citizen-voting-1",
    "href": "lectures/14-surveys/surveys.html#non-citizen-voting-1",
    "title": "Surveys in Politics",
    "section": "Non-Citizen Voting?",
    "text": "Non-Citizen Voting?"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#non-citizen-voting-2",
    "href": "lectures/14-surveys/surveys.html#non-citizen-voting-2",
    "title": "Surveys in Politics",
    "section": "Non-Citizen Voting?",
    "text": "Non-Citizen Voting?\n\nfilter(cces, immstat_12 == \"Immigrant non-citizen\") |&gt; \n  count(VV_general_10)\n\n# A tibble: 4 × 2\n  VV_general_10                   n\n  &lt;chr&gt;                       &lt;int&gt;\n1 Absentee voter                  1\n2 Confirmed Non-voter            42\n3 In person or unknown method     2\n4 Unmatched                      92"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#non-citizen-voting-3",
    "href": "lectures/14-surveys/surveys.html#non-citizen-voting-3",
    "title": "Surveys in Politics",
    "section": "Non-citizen voting?",
    "text": "Non-citizen voting?\n\n\nfilter(cces, immstat_10 == \"Immigrant non-citizen\") |&gt; \n  count(immstat_12)\n\n# A tibble: 5 × 2\n  immstat_12                n\n  &lt;chr&gt;                 &lt;int&gt;\n1 First generation          2\n2 Immigrant Citizen        32\n3 Immigrant non-citizen    85\n4 Third generation          2\n5 &lt;NA&gt;                      1\n\nfilter(cces, immstat_10 == \"Immigrant non-citizen\" & immstat_12 == \"Immigrant non-citizen\") |&gt; \n  count(VV_general_10)\n\n# A tibble: 2 × 2\n  VV_general_10           n\n  &lt;chr&gt;               &lt;int&gt;\n1 Confirmed Non-voter    39\n2 Unmatched              46"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#voter-knowledge",
    "href": "lectures/14-surveys/surveys.html#voter-knowledge",
    "title": "Surveys in Politics",
    "section": "Voter Knowledge",
    "text": "Voter Knowledge\n\nA central contribution of polling was to uncover how little the public knows about politics and government.\nExamples:\n\n40% knows which party controls congress.\n52% of voters know that a state has two senators.\n1/3 of people will express opinions on imaginary issues:\n\n“Some people say that the 1975 Public Affairs Act should be repealed”\n\n34% knows the identity of the Supreme Court Chef Justice\n58% know Roe v Wade is about abortion"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#sample-frames",
    "href": "lectures/14-surveys/surveys.html#sample-frames",
    "title": "Surveys in Politics",
    "section": "Sample Frames",
    "text": "Sample Frames\n\n\nSampling Frames in use Today:\n\nNo Sample frame, i.e. random digit dialing\n\nCell phones make this substantially more expensive\n\nVoter files\n\nAvailable most of the country from government or vendors\n\nInternet samples\n\nRecruited and opt-in\n\n\n\nQuestion: What is your target population?"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#coverage-bias",
    "href": "lectures/14-surveys/surveys.html#coverage-bias",
    "title": "Surveys in Politics",
    "section": "Coverage Bias",
    "text": "Coverage Bias\n\nIgnoring all sources of error except mismatch between frame and target population, coverage error is:\n\n\n\\[\\bar Y_c - \\bar Y = \\frac{U}{N} (\\bar Y_C- \\bar Y_U)\\]\n\n\\(\\bar Y\\): mean of the target population\n\\(\\bar Y_c\\): mean of the population covered by the sampling frame\n\\(\\bar Y_U\\): mean of the target population not covered by the sampling frame\n\\(U\\): total number of eligible members not in the sampling frame\n\\(N\\): total number of members in the target population"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#sampling-likely-voters",
    "href": "lectures/14-surveys/surveys.html#sampling-likely-voters",
    "title": "Surveys in Politics",
    "section": "Sampling Likely Voters",
    "text": "Sampling Likely Voters\n\nFor campaigns, the target population is often people who will show up on election day, i.e. likely voters.\nCan ask whether people intend to vote, as well as past voting behavior to predict future turnout but people lie\n\n\n\nIn talking to people about elections, we often find that a lot of people were not able to vote because they weren’t registered, they were sick, or they just didn’t have time. Which of the following statements best describes you?\n\n\nOver-reporting of voting is typically 8% to 14%"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#sampling-likely-voters-1",
    "href": "lectures/14-surveys/surveys.html#sampling-likely-voters-1",
    "title": "Surveys in Politics",
    "section": "Sampling Likely Voters",
    "text": "Sampling Likely Voters\nAlternative question to increase accuracy:\n\n\nIn talking to people about elections, we often find that a lot of people were not able to vote because they weren’t registered, they were sick, or they just didn’t have time. By looking at public records kept by election officials, we can get an accurate report of who actually voted in November, and in previous elections. Of course, these public records do not say who you voted for. Part of our study will involve checking these records against the survey reports. Which of the following statements best describes you?\n\nAmong those receiving the typical question, 11.8% over-report. Among those receiving the alternative question, 8% over-report"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#registration-based-sampling",
    "href": "lectures/14-surveys/surveys.html#registration-based-sampling",
    "title": "Surveys in Politics",
    "section": "Registration Based Sampling",
    "text": "Registration Based Sampling\n\nPast turnout is a very strong predictor of future turnout.\nAs a result, campaigns increasingly use voter registration rolls (supplemented with commercial databases) to conduct surveys.\n\nIntended turnout + past turnout + already registered is a much better predictor than intended turnout alone.\n\nSome media outlets now use registration-based sampling instead of random digit dialing.\n\nBUT some populations unrepresented on voter lists.\nLeads to biased view of American public opinion. How biased?"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#cambridge-voter-file",
    "href": "lectures/14-surveys/surveys.html#cambridge-voter-file",
    "title": "Surveys in Politics",
    "section": "Cambridge Voter File",
    "text": "Cambridge Voter File\n\nvoterfile_camb &lt;- read_csv(\"cambridge_voter_history16_18.csv.gz\", show_col_types = FALSE)\n\nfilter(voterfile_camb, turnout_090418 == 1) |&gt;\n  filter(last_name == \"HIDALGO\") |&gt;\n  select(last_name, first_name, date_of_birth, party_affiliation)\n\n# A tibble: 2 × 4\n  last_name first_name date_of_birth party_affiliation\n  &lt;chr&gt;     &lt;chr&gt;      &lt;date&gt;        &lt;chr&gt;            \n1 HIDALGO   OLGA       1930-04-13    D                \n2 HIDALGO   FERNANDO   1980-01-12    D                \n\nfilter(voterfile_camb, turnout_110618 == 1) |&gt;\n  filter(last_name == \"HIDALGO\") |&gt;\n  select(last_name, first_name, date_of_birth, party_affiliation)\n\n# A tibble: 5 × 4\n  last_name first_name date_of_birth party_affiliation\n  &lt;chr&gt;     &lt;chr&gt;      &lt;date&gt;        &lt;chr&gt;            \n1 HIDALGO   DAVID      1994-10-11    D                \n2 HIDALGO   OLGA       1930-04-13    D                \n3 HIDALGO   JOSE       1988-09-19    D                \n4 HIDALGO   CARMEN     1970-07-16    D                \n5 HIDALGO   FERNANDO   1980-01-12    D"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#age-and-turnout",
    "href": "lectures/14-surveys/surveys.html#age-and-turnout",
    "title": "Surveys in Politics",
    "section": "Age and Turnout",
    "text": "Age and Turnout"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#rdd-vs-registration-based-sampling",
    "href": "lectures/14-surveys/surveys.html#rdd-vs-registration-based-sampling",
    "title": "Surveys in Politics",
    "section": "RDD vs Registration Based Sampling",
    "text": "RDD vs Registration Based Sampling"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#diversity-in-sampling-frames",
    "href": "lectures/14-surveys/surveys.html#diversity-in-sampling-frames",
    "title": "Surveys in Politics",
    "section": "Diversity in Sampling Frames",
    "text": "Diversity in Sampling Frames"
  },
  {
    "objectID": "lectures/14-surveys/surveys.html#citations",
    "href": "lectures/14-surveys/surveys.html#citations",
    "title": "Surveys in Politics",
    "section": "Citations",
    "text": "Citations\n\n\n\n\n\n\n\n\nGroves, Robert M., Fowler Jr J Floyd, Mick P. Couper, James M. Lepkowski, Eleanor Singer, and Roger Tourangeau. 2009. Survey Methodology. 2 edition. Hoboken, N.J: Wiley."
  },
  {
    "objectID": "lectures/06-inference/inference.html#hypothesis-testing",
    "href": "lectures/06-inference/inference.html#hypothesis-testing",
    "title": "Inference in Experiments",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\n\n\nWe have discussed estimation of ATEs and how the difference-in-means is over repeated randomizations an unbiased estimator of the ATE.\nBut any particular estimate may be close or far from the true ATE.\nHow do we know if our finding is unlikely to have occurred by chance?\n\n\n\n\n\nH/T xkcd"
  },
  {
    "objectID": "lectures/06-inference/inference.html#logic-of-hypothesis-testing",
    "href": "lectures/06-inference/inference.html#logic-of-hypothesis-testing",
    "title": "Inference in Experiments",
    "section": "Logic of Hypothesis Testing",
    "text": "Logic of Hypothesis Testing\n\nWe start with an imagined world in which the treatment has a particular effect: the null hypothesis (\\(H_0\\))\nWe ask: under our maintained assumptions, how likely is it that we would observe the data we have if the null hypothesis were true?\n\nImportant: It is not the probability that any partifcular hypothesis is true, but the probability of observing the data we have if the null hypothesis were true.\n\nIf the probability is low, we reject the null hypothesis in favor of the alternative hypothesis (\\(H_1\\)). 😎\nIf the probability is high, we fail to reject the null hypothesis. 😢\n\nWe do not accept the null hypothesis, we just fail to reject it."
  },
  {
    "objectID": "lectures/06-inference/inference.html#the-sharp-null",
    "href": "lectures/06-inference/inference.html#the-sharp-null",
    "title": "Inference in Experiments",
    "section": "The Sharp Null",
    "text": "The Sharp Null\nIn experiments, we might be interested in the sharp null hypothesis:\n\n\n\n\n\n\n\n\nSharp Null Hypotheis of No Effect\n\n\nThe treatment effect is 0 for all units: \\(Y_i(1)=Y_i(0)\\) for all \\(i\\).\n\n\n\n\nKey idea: in the world where the sharp null hypothesis is true, we observe all the potential outcomes!\n\n\nThe Real World\n\n\n\n\\(i\\)\n\\(D_i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n1\n?\n1\n\n\n2\n0\n-1\n?\n\n\n3\n1\n?\n0\n\n\n\n\nThe Sharp Null World\n\n\n\n\\(i\\)\n\\(D_i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n1\n1\n1\n\n\n2\n0\n-1\n-1\n\n\n3\n1\n0\n0"
  },
  {
    "objectID": "lectures/06-inference/inference.html#sampling-distribution-under-the-sharp-null",
    "href": "lectures/06-inference/inference.html#sampling-distribution-under-the-sharp-null",
    "title": "Inference in Experiments",
    "section": "Sampling Distribution Under the Sharp Null",
    "text": "Sampling Distribution Under the Sharp Null\n\nTo conduct a hypothesis test, we need to know the distribution of our estimator (the difference-in-means) under the sharp null hypothesis.\nWe can do this by:\n\nCalculate the actual test statistic (i.e. difference-in-means) in our sample.\nPermute the treatment assignment the same way you originally assigned treatment and calculate the test statistic.\nRepeat step 2 many times.\nCompare the actual test-statistic to the distribution of differences-in-means under the sharp null.\n\n\n\n\n\n\n\n\n\n\nPermutation Test p-value\n\n\nThe p-value is the proportion of test-statistics from sampling distribution under the null that are as extreme or more extreme than the actual test-statistic."
  },
  {
    "objectID": "lectures/06-inference/inference.html#barber-and-pope-data",
    "href": "lectures/06-inference/inference.html#barber-and-pope-data",
    "title": "Inference in Experiments",
    "section": "Barber and Pope Data",
    "text": "Barber and Pope Data\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#sample",
    "href": "lectures/06-inference/inference.html#sample",
    "title": "Inference in Experiments",
    "section": "sample",
    "text": "sample\nTo sample from a vector, we can use the sample function, where size is the number of samples, and replace is whether we want to sample with replacement.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nTo permute an entire vector, you can use sample where size is the length of the treatment vector.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#test-statistic",
    "href": "lectures/06-inference/inference.html#test-statistic",
    "title": "Inference in Experiments",
    "section": "Test Statistic",
    "text": "Test Statistic\nTo create the sampling distribution under the sharp null, we need to permute and then calculate the difference-in-means.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#create-a-function",
    "href": "lectures/06-inference/inference.html#create-a-function",
    "title": "Inference in Experiments",
    "section": "Create a function",
    "text": "Create a function\n\n\n\nWe can create a function to permute and calculate the difference-in-means.\nIn general, if we need to do something more than once, we should create a function.\nThis will make our code more readable and easier to debug.\n\n\n\nfunc_name &lt;- function(arg1, arg2, ...) {\n        # Do something\n        return(something)\n}\n\n\nLet’s wrap the code we just wrote into a function.\nWe use pull to extract the value from the tibble.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#iterate",
    "href": "lectures/06-inference/inference.html#iterate",
    "title": "Inference in Experiments",
    "section": "Iterate",
    "text": "Iterate\nWe can now use the function to iterate over many permutations.\nA useful function for this is the replicate function, which repeats a function a number of times.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe now have a distribution of differences-in-means under the sharp null hypothesis."
  },
  {
    "objectID": "lectures/06-inference/inference.html#visualize-the-distribution",
    "href": "lectures/06-inference/inference.html#visualize-the-distribution",
    "title": "Inference in Experiments",
    "section": "Visualize the Distribution",
    "text": "Visualize the Distribution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#compare-to-the-actual-test-statistic",
    "href": "lectures/06-inference/inference.html#compare-to-the-actual-test-statistic",
    "title": "Inference in Experiments",
    "section": "Compare to the Actual Test Statistic",
    "text": "Compare to the Actual Test Statistic\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#calculate-the-p-value",
    "href": "lectures/06-inference/inference.html#calculate-the-p-value",
    "title": "Inference in Experiments",
    "section": "Calculate the p-value",
    "text": "Calculate the p-value\nCalculate the proportion of the sampling distribution that is as extreme or more extreme than the actual test statistic.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn this case, the p-value is small as there are few values in the sampling distribution that are as extreme or more extreme than the actual test statistic."
  },
  {
    "objectID": "lectures/06-inference/inference.html#rejecting-the-null",
    "href": "lectures/06-inference/inference.html#rejecting-the-null",
    "title": "Inference in Experiments",
    "section": "Rejecting the Null",
    "text": "Rejecting the Null\n\nTests usually end with a decision to reject the null or not.\nChoose a threshold below which we reject the null.\n\nTest level : the threshold for a test\nDecision rule: if the p-value is less than , reject the null.\nOtherwise: fail to reject the null.\n\nCommon thresholds:\n\n\\(p\\geq .1\\) (not statistically significant)\n\\(p &lt; .05\\) (statistically significant)\n\\(p &lt; .01\\) (highly statistically significant)"
  },
  {
    "objectID": "lectures/06-inference/inference.html#testing-errors",
    "href": "lectures/06-inference/inference.html#testing-errors",
    "title": "Inference in Experiments",
    "section": "Testing errors",
    "text": "Testing errors\n\nA \\(p\\)-value of .05 says that data as extreme or more extreme than the actual test statistic would occur 5% of the time if the null hypothesis were true.\nTest errors:\n\n\n\n\n\n\n\\(H_0\\) True\n\\(H_0\\) False\n\n\n\n\nRetain \\(H_0\\)\n😀\nType II Error: 😞\n\n\nReject \\(H_0\\)\nType I Error: 😱\n🥳\n\n\n\n\n\n\nType 1 error is usually considered worse than Type II error.\n\n“Convicting” an innocent null hypothesis\n\nType 2 error is less serious\n\n“Failing to convict” a guilty null hypothesis"
  },
  {
    "objectID": "lectures/06-inference/inference.html#more-on-iteration-1",
    "href": "lectures/06-inference/inference.html#more-on-iteration-1",
    "title": "Inference in Experiments",
    "section": "More on Iteration",
    "text": "More on Iteration\n\nWe used the replicate function to iterate over the permutations.\nA useful package for iteration is the purrr package (part of the tidyverse).\nThe map function is a generalization of replicate that can be used to iterate over many things.\n\nAlso has built in progress bars\nMore flexible than replicate"
  },
  {
    "objectID": "lectures/06-inference/inference.html#lists",
    "href": "lectures/06-inference/inference.html#lists",
    "title": "Inference in Experiments",
    "section": "Lists",
    "text": "Lists\n\nLists are a very flexible data structure in R.\n\nThey can hold any type of data, including other lists.\nCan access elements by position:\n\nlist[1] returns the first element of the list (which is a list)\nlist[[1]] returns the content of first element of the list (not the list itself)\nlist[[1]][[1]] returns the first element of the first element of the list.\n\n\n\n\n\n\n\nIndexing Lists"
  },
  {
    "objectID": "lectures/06-inference/inference.html#checking-covariate-balance-with-map",
    "href": "lectures/06-inference/inference.html#checking-covariate-balance-with-map",
    "title": "Inference in Experiments",
    "section": "Checking Covariate Balance with map",
    "text": "Checking Covariate Balance with map\nNow let’s do a version of the permutation test using map.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#covariate-balance",
    "href": "lectures/06-inference/inference.html#covariate-balance",
    "title": "Inference in Experiments",
    "section": "Covariate Balance",
    "text": "Covariate Balance\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/06-inference/inference.html#plot",
    "href": "lectures/06-inference/inference.html#plot",
    "title": "Inference in Experiments",
    "section": "Plot",
    "text": "Plot\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#texan-democratic-primary",
    "href": "lectures/09-fraud/fraud.html#texan-democratic-primary",
    "title": "Electoral Malfeasance",
    "section": "1948 Texan Democratic Primary",
    "text": "1948 Texan Democratic Primary\n\n\n\n\n\nLyndon B. Johnson (LBJ) vs. Coke Stevenson\nOn election day, Stevenson was ahead\nSix days later, LBJ was ahead\nLBJ won by 87 votes\nLast 202 votes counted (Box 13) in Precinct 13 of Jim Wells County:\n\n200 votes for LBJ\n2 votes for Stevenson\n\nVoter Register: last 200 voters in Alphabetical Order"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#box-13",
    "href": "lectures/09-fraud/fraud.html#box-13",
    "title": "Electoral Malfeasance",
    "section": "Box 13",
    "text": "Box 13"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#george-parr",
    "href": "lectures/09-fraud/fraud.html#george-parr",
    "title": "Electoral Malfeasance",
    "section": "George Parr",
    "text": "George Parr\n\n\n\n\nBoss of the Parr Machine (El Patrón)\nOrdered addition of 200 votes\n\n\nElection judge:\n\nWe had the law to ourselves there. It was a lawless son-of-a-bitch. We had iron control. If a man was opposed to us, we’d put him out of business. Parr was the godfather. He had life or death control… We could tell any election judge: ‘Give us 80 per cent of the vote, the other guy 20 per cent.’ We had it made in every election"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#clientelism",
    "href": "lectures/09-fraud/fraud.html#clientelism",
    "title": "Electoral Malfeasance",
    "section": "Clientelism",
    "text": "Clientelism\n\n\n\n\n\ngraph TD\n  Patron --&gt; Broker1[Broker]\n  Patron --&gt;  Broker2[Broker]\n  Broker1 --&gt;  Client1[Client]\n  Broker1 --&gt;  Client2[Client]\n  Broker1 --&gt; Client4[Client]\n  Broker2 --&gt;  Client3[Client]\n  Broker2 --&gt;  Client5[Client]"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#clientelism-vs-redistribution",
    "href": "lectures/09-fraud/fraud.html#clientelism-vs-redistribution",
    "title": "Electoral Malfeasance",
    "section": "Clientelism vs Redistribution",
    "text": "Clientelism vs Redistribution"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#list-experiment-in-colombia",
    "href": "lectures/09-fraud/fraud.html#list-experiment-in-colombia",
    "title": "Electoral Malfeasance",
    "section": "List Experiment in Colombia",
    "text": "List Experiment in Colombia\n\nI will read a list of five (5) things people have in mind when deciding who to vote for. I want you to tell me how many of these five things you have taken into account when voting for a candidate. Do not tell me WHICH, ONLY HOW MANY.” Then they are handed a card with the following options\n\n\nThe information about the candidate on the radio or television,\nWhat you read about his or her government plan,\nThe benefits, gifts, or jobs the candidate offered you in exchange for your vote\nThe conversations you had with your friends about the candidate,\nThe candidate’s party."
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#list-experiment-results",
    "href": "lectures/09-fraud/fraud.html#list-experiment-results",
    "title": "Electoral Malfeasance",
    "section": "List Experiment Results",
    "text": "List Experiment Results\n\n\n\n\n\n\n\n\n\n\nResponse value\nControl group Frequency\nControl group Proportion (%)\nTreatment group Frequency\nTreatment group Proportion (%)\n\n\n\n\n0\n168\n6.6\n129\n4.5\n\n\n1\n1,185\n46.2\n1,221\n42.8\n\n\n2\n874\n34.1\n980\n34.3\n\n\n3\n212\n8.3\n343\n12.0\n\n\n4\n125\n4.9\n139\n4.9\n\n\n5\n\n\n44\n1.5\n\n\nAverage\n1.59\n\n1.75"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#irregularities",
    "href": "lectures/09-fraud/fraud.html#irregularities",
    "title": "Electoral Malfeasance",
    "section": "Irregularities",
    "text": "Irregularities"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#facebook-ads",
    "href": "lectures/09-fraud/fraud.html#facebook-ads",
    "title": "Electoral Malfeasance",
    "section": "Facebook Ads",
    "text": "Facebook Ads"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#experimental-design",
    "href": "lectures/09-fraud/fraud.html#experimental-design",
    "title": "Electoral Malfeasance",
    "section": "Experimental Design",
    "text": "Experimental Design"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#factorial-design",
    "href": "lectures/09-fraud/fraud.html#factorial-design",
    "title": "Electoral Malfeasance",
    "section": "Factorial Design",
    "text": "Factorial Design\n\nExample of a factorial design\nTwo factors (treatments):\n\nType of ad\nLetter or no letter\n\n\n\n\n\n\n\n\n\n\n\n\nLetter\nNo Letter\n\n\n\n\nInformation\nLetter & Information\nNo Letter & Information\n\n\nCall-to-Action\nLetter & Call-to-Action\nNo Letter & Call-to-Action\n\n\nInfo & Call-to-Action\nLetter & Info & Call-to-Action\nNo Letter & Info & Call-to-Action"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#stratification",
    "href": "lectures/09-fraud/fraud.html#stratification",
    "title": "Electoral Malfeasance",
    "section": "Stratification",
    "text": "Stratification\n\nTo increase the balance on potential confounders across treatment conditions, we conducted a stratified randomization. We defined strata by the intersection of bins partitioning the sample in three ways: (i) by the fiftieth and eighty-fifth percentiles of the population over the age of 18, (ii) by the twentieth and eightieth percentiles of voter turnout in the first round of presidential elections in 2018, and (iii) by whether the municipalities filed reports through the MOE’s website around the congressional elections of 2018 above or below the median"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#clustering",
    "href": "lectures/09-fraud/fraud.html#clustering",
    "title": "Electoral Malfeasance",
    "section": "Clustering",
    "text": "Clustering\n\nLevel of randomization: municipalities\nDependent variables:\n\nReports of irregularities (698 municipalities)\nDeviations from Benford’s Law (698 municipalities)\nCandidates’ vote share (2,989 candidates)\n\nWhat is the sample size?"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#effect-on-reports",
    "href": "lectures/09-fraud/fraud.html#effect-on-reports",
    "title": "Electoral Malfeasance",
    "section": "Effect on Reports",
    "text": "Effect on Reports"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#effect-on-irregularities",
    "href": "lectures/09-fraud/fraud.html#effect-on-irregularities",
    "title": "Electoral Malfeasance",
    "section": "Effect on Irregularities",
    "text": "Effect on Irregularities"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#effects-on-candidates-vote-share",
    "href": "lectures/09-fraud/fraud.html#effects-on-candidates-vote-share",
    "title": "Electoral Malfeasance",
    "section": "Effects on Candidates’ Vote Share",
    "text": "Effects on Candidates’ Vote Share"
  },
  {
    "objectID": "lectures/09-fraud/fraud.html#cost-effectiveness",
    "href": "lectures/09-fraud/fraud.html#cost-effectiveness",
    "title": "Electoral Malfeasance",
    "section": "Cost Effectiveness",
    "text": "Cost Effectiveness\n\nTotal FB campaign: $10,870\nTotal cost of $15 per municipality\nReduced vote share of “corrupt” candidates by 2.5 percentage points\nAverage votes in each municipality is 13,352\nNumber of votes changed on average: (13,352 x 2.5% ) \\(\\approx\\) 330\nEvery $1 spent reduced about 21 votes for “corrupt” candidates"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#elites-vs-citizens",
    "href": "lectures/05-partisanship/partisanship.html#elites-vs-citizens",
    "title": "Partisanship and Ideology",
    "section": "Elites vs Citizens",
    "text": "Elites vs Citizens\n\n\nPolitical elites:\n\nKnow and care a lot about politics\nOperate in institional settings with clear incentives\nCan be modeled as rational actors with consistent preferences who optimize their behavior to achieve their goals\n\n\nOrdinary Citizens:\n\nDo not know or care about politics\nMuch of their political behavior occurs in unstructured contexts in which their actions are not individually consequential and their goals/incentives are unclear.\nTheir opinions and behavior are often best analyzed using psychological rather than rationalist models."
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#what-have-we-learned-from-survey-data",
    "href": "lectures/05-partisanship/partisanship.html#what-have-we-learned-from-survey-data",
    "title": "Partisanship and Ideology",
    "section": "What Have We Learned from Survey Data?",
    "text": "What Have We Learned from Survey Data?\nRelative to political elites, citizens’ attitudes are:\n\nIgnorant: Citizens lack basic information about politics.\nUnstable: Citizens’ attitudes are often inconsistent and unstable.\nUnconstrained: Citizens are much less ideological or consistent"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#how-voters-talk",
    "href": "lectures/05-partisanship/partisanship.html#how-voters-talk",
    "title": "Partisanship and Ideology",
    "section": "How Voters Talk",
    "text": "How Voters Talk\n\n“When we first did that big trade agreement I thought it was a good idea, but now I’m getting a little more conservative about it,” said Phyllis Arthur, a 74-year-old Republican from Walnut Creek, Calif. “I think we’re being overwhelmed by the goods coming in. That’s practically all that’s available in the stores.”1\n\n\nVoters will also answer almost any question you ask them: link\n\nNY Times"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#inconsistent-opinions-but-stable-partisanship",
    "href": "lectures/05-partisanship/partisanship.html#inconsistent-opinions-but-stable-partisanship",
    "title": "Partisanship and Ideology",
    "section": "Inconsistent Opinions, but Stable Partisanship?",
    "text": "Inconsistent Opinions, but Stable Partisanship?\n\nDespite this inconsistency, voters actual votes are quite predictable.\nThe vast majority of Americans to vote consistent with their party identification, which is itself quite stable over time."
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#state-trends",
    "href": "lectures/05-partisanship/partisanship.html#state-trends",
    "title": "Partisanship and Ideology",
    "section": "State Trends",
    "text": "State Trends"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#partisanship-and-ideology-1",
    "href": "lectures/05-partisanship/partisanship.html#partisanship-and-ideology-1",
    "title": "Partisanship and Ideology",
    "section": "Partisanship and Ideology",
    "text": "Partisanship and Ideology\n\n\nWhile partisanship is mostly stable, the correlation between partisanship and ideology has increased, especially among elites."
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#ideological-sorting",
    "href": "lectures/05-partisanship/partisanship.html#ideological-sorting",
    "title": "Partisanship and Ideology",
    "section": "Ideological Sorting",
    "text": "Ideological Sorting\n\n\nIdeological sorting among citizens has also increased, but not as much as among elites."
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#ideological-sorting-1",
    "href": "lectures/05-partisanship/partisanship.html#ideological-sorting-1",
    "title": "Partisanship and Ideology",
    "section": "Ideological Sorting",
    "text": "Ideological Sorting"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#what-comes-first",
    "href": "lectures/05-partisanship/partisanship.html#what-comes-first",
    "title": "Partisanship and Ideology",
    "section": "What Comes First?",
    "text": "What Comes First?\nIncreasing correlation beteen partisanship and ideology among elites and citizens. Why?\n\n\nCitizens polarize and then elites follow\nElites polarize and then citizens follow\n\n\n\nBarber and Pope (2018) is designed to inform this debate by using a party leaders’ shifting stances."
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#survey-experiment",
    "href": "lectures/05-partisanship/partisanship.html#survey-experiment",
    "title": "Partisanship and Ideology",
    "section": "Survey Experiment",
    "text": "Survey Experiment\n\n\nRandomized treatment embedded in a 2017 survey\nTreatment arms:\n\nControl group (500 respondents)\nLiberal Trump (200 respondents)\nConservative Trump (200 respondents)\n\n\n\n\n\nPlease indicate whether or not you support or oppose the statement.\n\n\n\nDonald Trump has said that he supports this policy. How about you?\n\nDonald Trump has said that he opposes this policy. How about you?\n\nDo you support or oppose increasing the minimum wage to over $10 an hour?"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#ate-estimates",
    "href": "lectures/05-partisanship/partisanship.html#ate-estimates",
    "title": "Partisanship and Ideology",
    "section": "ATE Estimates",
    "text": "ATE Estimates"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#ate-estimates-by-political-knowledge",
    "href": "lectures/05-partisanship/partisanship.html#ate-estimates-by-political-knowledge",
    "title": "Partisanship and Ideology",
    "section": "ATE Estimates by Political Knowledge",
    "text": "ATE Estimates by Political Knowledge"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#ate-estimates-by-self-reported-ideology",
    "href": "lectures/05-partisanship/partisanship.html#ate-estimates-by-self-reported-ideology",
    "title": "Partisanship and Ideology",
    "section": "ATE Estimates by Self-Reported Ideology",
    "text": "ATE Estimates by Self-Reported Ideology"
  },
  {
    "objectID": "lectures/05-partisanship/partisanship.html#ideological-distribution-by-condition",
    "href": "lectures/05-partisanship/partisanship.html#ideological-distribution-by-condition",
    "title": "Partisanship and Ideology",
    "section": "Ideological Distribution by Condition",
    "text": "Ideological Distribution by Condition"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#overview-of-experimental-design",
    "href": "lectures/07-survey-measurement/survey_measurement.html#overview-of-experimental-design",
    "title": "Survey Measurement",
    "section": "Overview of Experimental Design",
    "text": "Overview of Experimental Design\n\n\n\nExamines the effect of “deep canvassing” on attitudes\n\nFocused on open-ended conversations\nPerspective taking\n\nPanel design\nOutcome: survey measures of attitudes"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#deep-canvassing",
    "href": "lectures/07-survey-measurement/survey_measurement.html#deep-canvassing",
    "title": "Survey Measurement",
    "section": "Deep Canvassing",
    "text": "Deep Canvassing"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#results-on-support-for-law",
    "href": "lectures/07-survey-measurement/survey_measurement.html#results-on-support-for-law",
    "title": "Survey Measurement",
    "section": "Results on Support for Law",
    "text": "Results on Support for Law"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#outcome-measures",
    "href": "lectures/07-survey-measurement/survey_measurement.html#outcome-measures",
    "title": "Survey Measurement",
    "section": "Outcome Measures",
    "text": "Outcome Measures\nPrimary outcome: a battery of survey measures designed to measure transgender stigma:\n\nMiami-Dade county recently passed a law that prohibits discrimination in housing, employment and public accommodations based on gender identity and expression, a category that includes transgender men and women. Do you favor or oppose this new law?\n\n\n\nSome people say it’s important to protect transgender people from discrimination in housing and employment. Other people have concerns about society becoming too accepting of transgender people, and do not want transgender people included in our non-discrimination law. What do you think? Do you agree or disagree that Miami law should protect transgender people from discrimination?"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#feeling-thermometer",
    "href": "lectures/07-survey-measurement/survey_measurement.html#feeling-thermometer",
    "title": "Survey Measurement",
    "section": "Feeling Thermometer",
    "text": "Feeling Thermometer\n\nUsing a scale from zero to 100, please tell us your personal feelings toward each of the following groups. As you do this task, think of an imaginary thermometer. The warmer or more favorable you feel toward the group, the higher the number you should give it. The colder or less favorable you feel, the lower the number. If you feel neither warm nor cold toward the group, rate it 50."
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#more-outcome-measures",
    "href": "lectures/07-survey-measurement/survey_measurement.html#more-outcome-measures",
    "title": "Survey Measurement",
    "section": "More Outcome Measures",
    "text": "More Outcome Measures\n\nA man who identifies as a woman is psychologically abnormal\n\n\n\nIt is morally wrong for a man to present himself as a woman in public\n\n\n\n\nSaying you are a gender that is different than the one you were born with is morally wrong\n\n\n\n\nI would support a friend choosing to have a sex change"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#respondent-knowledge",
    "href": "lectures/07-survey-measurement/survey_measurement.html#respondent-knowledge",
    "title": "Survey Measurement",
    "section": "Respondent Knowledge",
    "text": "Respondent Knowledge\n\nAs we registered in a preanalysis plan before conducting the 6-week survey, we suspected that many placebo group subjects did not know what the term “transgender” meant (potentially being more familiar with other, derogatory terms for this group), making them unable to connect any antitransgender attitudes with this question about the law.\n\n\n\nWe therefore included a definition of the term “transgender” in the survey questions about the law, starting with the 6-week survey, clearly defining the term and highlighting transgender people’s inclusion in the law."
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#opposition-video",
    "href": "lectures/07-survey-measurement/survey_measurement.html#opposition-video",
    "title": "Survey Measurement",
    "section": "Opposition Video",
    "text": "Opposition Video"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#combining-measures",
    "href": "lectures/07-survey-measurement/survey_measurement.html#combining-measures",
    "title": "Survey Measurement",
    "section": "Combining Measures",
    "text": "Combining Measures\n\nBroockman and Kalla combine these measures into indices.\nWhy combine multiple measures instead of looking at individual measures?\n\nReduces measurement error\nReduces sampling error\nReduces the number of tests we need to run\n\nUse dimension reduction techniques to combine measures into indices.\nWhy not combine?\n\nDifferent items may be measuring different concepts\nEstimates less interpretable"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#measurement-error",
    "href": "lectures/07-survey-measurement/survey_measurement.html#measurement-error",
    "title": "Survey Measurement",
    "section": "Measurement Error",
    "text": "Measurement Error\n\nMeasurement error can be due to many types of biases:\n\nSocial desirability bias\nExperimental demand effects\nModeracy, extreme response, and response order biases\n\nImportant to consider these biases when designing and analyzing surveys\nNeed to pretest survey questions and carefully analyze response patterns"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#social-desirability-bias-1",
    "href": "lectures/07-survey-measurement/survey_measurement.html#social-desirability-bias-1",
    "title": "Survey Measurement",
    "section": "Social Desirability Bias",
    "text": "Social Desirability Bias\n\n\n\n\n\nWe are often interested in sensitive topics, such as racial attitudes, sexual behavior, or political preferences\nRespondents may answer questions in a way to avoid embarrassment or to appear more favorable to the interviewer\nStructural features of surveys can reduce social desirability bias\n\nAnonymity\nSelf-administered surveys"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#less-explicit-measures-racial-resentment",
    "href": "lectures/07-survey-measurement/survey_measurement.html#less-explicit-measures-racial-resentment",
    "title": "Survey Measurement",
    "section": "Less Explicit Measures: Racial Resentment",
    "text": "Less Explicit Measures: Racial Resentment\nDo you agree strongly, somewhat, neither agree, nor disagree, somewhat disagree, or strongly disagree with the following statement?\n\nIrish, Italians, Jewish and many other minorities overcame prejudice and worked their way up. Blacks should do the same without any special favors.\nGenerations of slavery and discrimination have created conditions that make it difficult for Blacks to work their way out of the lower class.\nOver the past few years, Blacks have gotten less than they deserve\nIt’s really a matter of some people not trying hard enough; if Blacks would only try harder, they could be just as well off as whites."
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#racial-resentment-scale",
    "href": "lectures/07-survey-measurement/survey_measurement.html#racial-resentment-scale",
    "title": "Survey Measurement",
    "section": "Racial Resentment Scale",
    "text": "Racial Resentment Scale"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#implicit-association-test",
    "href": "lectures/07-survey-measurement/survey_measurement.html#implicit-association-test",
    "title": "Survey Measurement",
    "section": "Implicit Association Test",
    "text": "Implicit Association Test\n\nIAT Link"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#behavioral-measures",
    "href": "lectures/07-survey-measurement/survey_measurement.html#behavioral-measures",
    "title": "Survey Measurement",
    "section": "Behavioral Measures",
    "text": "Behavioral Measures\nUltimatum Game:"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#using-randomization",
    "href": "lectures/07-survey-measurement/survey_measurement.html#using-randomization",
    "title": "Survey Measurement",
    "section": "Using Randomization",
    "text": "Using Randomization\n\nOn your screen, you will see a virtual dice. Click on it to roll the dice. If the number on the dice is 1, 2, 3, or 4, please respond whether Statement A is true or false for you. Otherwise, please respond whether Statement B is true or false for you. Only you can see the number on the dice.\n\n\n\nA I have used an illegal drug in the past month.\nB I have not used an illegal drug in the past month.\nTRUE or FALSE"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#estimation-in-randomized-response",
    "href": "lectures/07-survey-measurement/survey_measurement.html#estimation-in-randomized-response",
    "title": "Survey Measurement",
    "section": "Estimation in Randomized Response",
    "text": "Estimation in Randomized Response\nLet \\(Z_i\\) be the latent (i.e. true) binary response to the sensitive question and \\(p\\) be the probability that the respondent is supposed to tell the truth.\n\nWe can write:\n\\[ \\Pr(Y_i = 1) = p \\Pr(Z_i=1) + (1-p) \\Pr(Z_i=0) \\]\n\n\nSolving for \\(\\Pr(Z_i=1)\\) we get:\n\\[ \\Pr(Z_i=1) = \\frac{1}{2p-1} \\{ \\Pr(Y_i=1) + p -1\\} \\]\nAs long as \\(p \\neq 1/2\\), we can estimate \\(\\Pr(Z_i=1)\\) using the observed proportion of “yes” responses in the randomized response survey.\n\n\nCost is less precision than direct questioning."
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#example-abortion-referendum-in-ms",
    "href": "lectures/07-survey-measurement/survey_measurement.html#example-abortion-referendum-in-ms",
    "title": "Survey Measurement",
    "section": "Example: Abortion Referendum in MS",
    "text": "Example: Abortion Referendum in MS"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#list-experiment-in-ms",
    "href": "lectures/07-survey-measurement/survey_measurement.html#list-experiment-in-ms",
    "title": "Survey Measurement",
    "section": "List Experiment in MS",
    "text": "List Experiment in MS\nHere is a list of four things that some people have done and some people have not. Please listen to them and then tell me HOW MANY of them you have done in the past two years. Do not tell me which you have and have not done. Just tell me how many:\n\n– Discussed politics with family or friends;\n– Cast a ballot for Governor Phil Bryant;\n– Paid dues to a union;\n– Given money to a Tea Party candidate or organization.\n– Voted ‘YES’ on the ‘Personhood’ Initiative on the November 2011 Mississippi"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#estimation-in-list-experiments",
    "href": "lectures/07-survey-measurement/survey_measurement.html#estimation-in-list-experiments",
    "title": "Survey Measurement",
    "section": "Estimation in List Experiments",
    "text": "Estimation in List Experiments\nLet \\(Y_i(0) = \\sum_{j=1}^J Z_{ij}\\) and \\(Y_i(1) =  \\sum_{j=1}^{J+1} Z_{ij}\\) be the number of items in the list that the respondent say they have done in the control and treatment groups, respectively.\nAssuming random assignment and respondents answer truthfully, then we can estimate proportion of respondents who have done the sensitive activity as:\n\n\\[\\textrm{ATE} = \\frac{1}{N_1} \\sum_{i=1}^{N_1} Y_i(1) - \\frac{1}{N_0} \\sum_{i=1}^{N_0} Y_i(0)\\]\n(this is the simple difference-in-means estimator)"
  },
  {
    "objectID": "lectures/07-survey-measurement/survey_measurement.html#comparison-of-direct-and-indirect-estimates",
    "href": "lectures/07-survey-measurement/survey_measurement.html#comparison-of-direct-and-indirect-estimates",
    "title": "Survey Measurement",
    "section": "Comparison of Direct and Indirect Estimates",
    "text": "Comparison of Direct and Indirect Estimates"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Setting Up R and RStudio for the class"
  },
  {
    "objectID": "resources.html#computation",
    "href": "resources.html#computation",
    "title": "Resources",
    "section": "",
    "text": "Setting Up R and RStudio for the class"
  }
]